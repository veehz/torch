{"version":3,"file":"torch.browser.umd.js","sources":["../../src/util.ts","../../src/operations/base.ts","../../src/operations/registry.ts","../../src/tensor.ts","../../src/broadcasting.ts","../../src/operations/functional.ts","../../src/operations/ops.gen.ts","../../src/creation/utils.ts","../../src/creation/rand.ts","../../src/creation/initializers.ts","../../src/creation/ranges.ts","../../src/nn/ops.gen.ts","../../src/nn/module.ts","../../src/nn/loss.ts","../../src/nn/functional.ts","../../src/optim/base.ts","../../src/optim/optimizers.ts"],"sourcesContent":["let globalId = 0;\n\nexport const getNextId = () => {\n  return globalId++;\n};\n\nexport const eventBus = new EventTarget();\nexport const events = {\n  TENSOR_BEFORE_BACKWARD: 'tensor.beforeBackward',\n  TENSOR_AFTER_BACKWARD: 'tensor.afterBackward',\n  OPERATION_BEFORE_FORWARD: 'operation.beforeForward',\n  OPERATION_AFTER_FORWARD: 'operation.afterForward',\n  OPERATION_BEFORE_BACKWARD: 'operation.beforeBackward',\n  OPERATION_AFTER_BACKWARD: 'operation.afterBackward',\n  OPERATION_BEFORE_ACCUMULATE_GRAD: 'operation.beforeAccumulateGrad',\n  OPERATION_AFTER_ACCUMULATE_GRAD: 'operation.afterAccumulateGrad',\n}","import { Tensor } from '../tensor';\nimport { eventBus, getNextId, events } from '../util';\n\nfunction resultRequiresGrad(...args: (Tensor | number | number[])[]): boolean {\n  for (const arg of args) {\n    if (arg instanceof Tensor && arg.requires_grad) {\n      return true;\n    }\n  }\n  return false;\n}\n\nabstract class Operation {\n  public id: number = getNextId();\n  public next_functions: Operation[] = [];\n  public saved_tensors: Tensor[] = [];\n  public _retained_tensors: Tensor[] = [];\n\n  protected abstract _forward(...args: (Tensor | number | number[])[]): Tensor;\n  protected abstract _backward(dz: Tensor): void;\n\n  forward(...args: (Tensor | number | number[])[]): Tensor {\n    const requires_grad = resultRequiresGrad(...args);\n    eventBus.dispatchEvent(new CustomEvent(events.OPERATION_BEFORE_FORWARD, {\n      detail: {\n        operation: this,\n        requires_grad,\n        args\n      }\n    }));\n    const result = this._forward(...args);\n    eventBus.dispatchEvent(new CustomEvent(events.OPERATION_AFTER_FORWARD, {\n      detail: {\n        operation: this,\n        requires_grad,\n        args,\n        result\n      }\n    }));\n    return result;\n  }\n\n  backward(dz: Tensor): void {\n    eventBus.dispatchEvent(new CustomEvent(events.OPERATION_BEFORE_BACKWARD, { detail: { operation: this, dz } }));\n    for (const x of this._retained_tensors) {\n      if (!x.grad) {\n        x.grad = new Tensor(new Array(x.dataLength()).fill(0));\n      }\n      x.grad = x.grad.add(dz);\n    }\n    this._backward(dz);\n    eventBus.dispatchEvent(new CustomEvent(events.OPERATION_AFTER_BACKWARD, { detail: { operation: this, dz } }));\n  }\n}\n\nclass NullOp extends Operation {\n  protected _forward(...args: (Tensor | number | number[])[]): Tensor {\n    throw new Error('NullOp should not be called');\n  }\n  protected _backward(dz: Tensor): void {\n    return;\n  }\n}\n\nexport const nullOp = new NullOp();\n\nabstract class UnaryOperation extends Operation {\n  protected abstract _forward(a: Tensor): Tensor;\n  protected abstract _backward(dz: Tensor): void;\n}\n\nabstract class BinaryOperation extends Operation {\n  protected abstract _forward(a: Tensor, b: Tensor): Tensor;\n  protected abstract _backward(dz: Tensor): void;\n}\n\nexport type OperationConstructor = new () => Operation;\nexport type UnaryOperationConstructor = new () => UnaryOperation;\nexport type BinaryOperationConstructor = new () => BinaryOperation;\n\nexport { Operation, UnaryOperation, BinaryOperation };\n\nexport class AccumulateGrad extends UnaryOperation {\n  public variable: Tensor;\n\n  protected _forward(variable: Tensor): Tensor {\n    this.variable = variable;\n    return variable;\n  }\n\n  protected _backward(dz: Tensor): void {\n    if (!this.variable.grad) {\n      this.variable.grad = new Tensor(new Array(this.variable.dataLength()).fill(0));\n    }\n    eventBus.dispatchEvent(new CustomEvent(events.OPERATION_BEFORE_ACCUMULATE_GRAD, { detail: { operation: this, dz } }));\n    this.variable.grad = this.variable.grad.add(dz);\n    eventBus.dispatchEvent(new CustomEvent(events.OPERATION_AFTER_ACCUMULATE_GRAD, { detail: { operation: this, dz } }));\n  }\n}\n","import { Operation, OperationConstructor } from './base';\n\n// Only allow registering concrete, constructible Operation classes\nconst operations = new Map<string, OperationConstructor>();\nconst operations_cache = new Map<string, Operation>();\n\nexport function registerOperation(name: string, func: OperationConstructor) {\n  operations.set(name, func);\n}\n\nexport function getOperation(name: string): OperationConstructor {\n  const func = operations.get(name);\n  if (!func) {\n    throw new Error(`Operation '${name}' is not registered.`);\n  }\n  return func;\n}\n\nexport function getOperationCache(name: string): Operation {\n  const operation = operations_cache.get(name);\n  if (!operation) {\n    operations_cache.set(name, new (getOperation(name))());\n    return operations_cache.get(name)!;\n  }\n  return operation;\n}","import { _get_original_index } from './broadcasting';\nimport { AccumulateGrad, Operation } from './operations/base';\nimport { getOperation, getOperationCache } from './operations/registry';\nimport { getNextId, eventBus, events } from './util';\n\n/*\n * TODO:\n * - Add support for Textures to be stored in Tensors\n */\n\ntype TypedArray =\n  | Int8Array\n  | Uint8Array\n  | Uint8ClampedArray\n  | Int16Array\n  | Uint16Array\n  | Int32Array\n  | Uint32Array\n  | Float32Array\n  | Float64Array;\n\nexport type NestedNumberArray = number | TypedArray | NestedNumberArray[];\n\nfunction _get_shape(data: NestedNumberArray): number[] {\n  if (ArrayBuffer.isView(data)) {\n    return [data.length];\n  }\n\n  const shape = [];\n  while (Array.isArray(data)) {\n    shape.push(data.length);\n    data = data[0];\n  }\n  return shape;\n}\n\nfunction _flatten(data: NestedNumberArray): number[] {\n  if (Array.isArray(data)) {\n    return data.flatMap(item => _flatten(item));\n  } else if (ArrayBuffer.isView(data)) {\n    return Array.from(data);\n  } else {\n    return [data];\n  }\n}\n\nexport class Tensor {\n  public id: number = getNextId();\n  data: number[];\n  _shape: number[];\n  grad_fn: Operation | null = null;\n  public grad: Tensor | null = null;\n\n  requires_grad: boolean;\n\n  constructor(\n    data: NestedNumberArray,\n    options: { requires_grad?: boolean } = {},\n    internal_options: { operation?: Operation; shape?: number[] } = {}\n  ) {\n    this.data = _flatten(data);\n    this.requires_grad = options.requires_grad ?? false;\n\n    this._shape = internal_options.shape ?? _get_shape(data);\n    this.grad_fn = internal_options.operation ?? null;\n\n    if (this.requires_grad && !this.grad_fn) {\n      const acc = new AccumulateGrad();\n      acc.variable = this;\n      this.grad_fn = acc;\n    }\n  }\n\n  // TODO: Somehow having a shape of [] will have a weird error:\n  // TypeError: Cannot read properties of undefined (reading 'length')\n  // when running kernel (something to do with constants?)\n  // so a little hack to return [1] when the shape is []\n  get shape(): number[] {\n    return this._shape.length === 0 ? [1] : this._shape;\n    // return this._shape;\n  }\n\n  toArray_(): void {\n    return;\n  }\n\n  toArray(): number[] {\n    return this.data;\n  }\n\n  dataLength(): number {\n    return this.data.length;\n  }\n\n  set shape(shape: number[]) {\n    this._shape = shape;\n  }\n\n  private _executeUnaryOp(opName: string): Tensor {\n    const operation = this.requires_grad ? new (getOperation(opName))() : getOperationCache(opName);\n    return operation.forward(this);\n  }\n\n  private _executeBinaryOp(opName: string, other: Tensor | number): Tensor {\n    if (typeof other == 'number') {\n      other = new Tensor(other);\n    }\n    const operation = this.requires_grad || other.requires_grad ? new (getOperation(opName))() : getOperationCache(opName);\n    return operation.forward(this, other);\n  }\n\n  private _executeOpRaw(opName: string, ...args: any[]): Tensor {\n    const operation = new (getOperation(opName))();\n    return operation.forward(this, ...args);\n  }\n\n  item(): number {\n    if (this.dataLength() !== 1) {\n      throw new Error('Tensor.item() is only valid for scalars');\n    }\n    return this.toArray()[0];\n  }\n\n  detach(): Tensor {\n    return new Tensor(this.data, { requires_grad: false }, { shape: this.shape });\n  }\n\n  detach_(): void {\n    this.requires_grad = false;\n    this.grad = null;\n    this.grad_fn = null;\n  }\n\n  zero_(): void {\n    this.data = Array(this.dataLength()).fill(0);\n  }\n\n  private is_retain_grad: boolean = false;\n  retain_grad(): void {\n    // leaf node -> no-op\n    if (this.grad_fn instanceof AccumulateGrad) return;\n    if (this.is_retain_grad) return;\n    this.is_retain_grad = true;\n\n    this.grad_fn._retained_tensors.push(this);\n  }\n\n  backward(grad?: Tensor | null): void {\n    if (!this.requires_grad) {\n      // If this tensor does not require gradients, stop propagation.\n      // TODO: check pytorch behaviour\n      return;\n    }\n\n    if (!grad) {\n      if (this.dataLength() !== 1) {\n        throw new Error('Gradient is required for non-scalar tensors');\n      }\n      grad = new Tensor(1);\n    } else {\n      grad.toArray_();\n    }\n\n    if (this.grad_fn) {\n      eventBus.dispatchEvent(new CustomEvent(events.TENSOR_BEFORE_BACKWARD, { detail: { tensor: this } }));\n      this.grad_fn.backward(grad);\n      eventBus.dispatchEvent(new CustomEvent(events.TENSOR_AFTER_BACKWARD, { detail: { tensor: this } }));\n    }\n  }\n\n  // operations\n\n  // binary pointwise\n\n  add(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('add', other);\n  }\n\n  sub(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('sub', other);\n  }\n\n  mul(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('mul', other);\n  }\n\n  div(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('div', other);\n  }\n\n  pow(other: Tensor | number): Tensor {\n    if (typeof other == 'number' && other % 1 === 0) {\n      return this._executeOpRaw('powint', other);\n    }\n    return this._executeBinaryOp('pow', other);\n  }\n\n  fmod(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('fmod', other);\n  }\n\n  maximum(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('maximum', other);\n  }\n\n  minimum(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('minimum', other);\n  }\n\n  // unary pointwise\n\n  log(): Tensor {\n    return this._executeUnaryOp('log');\n  }\n\n  sqrt(): Tensor {\n    return this._executeUnaryOp('sqrt');\n  }\n\n  exp(): Tensor {\n    return this._executeUnaryOp('exp');\n  }\n\n  square(): Tensor {\n    return this._executeUnaryOp('square');\n  }\n\n  abs(): Tensor {\n    return this._executeUnaryOp('abs');\n  }\n\n  sign(): Tensor {\n    return this._executeUnaryOp('sign');\n  }\n\n  neg(): Tensor {\n    return this._executeUnaryOp('neg');\n  }\n\n  reciprocal(): Tensor {\n    return this._executeUnaryOp('reciprocal');\n  }\n\n  reshape(shape: number[]): Tensor {\n    return this._executeOpRaw('reshape', shape);\n  }\n\n  unsqueeze(dim: number): Tensor {\n    return this._executeOpRaw('unsqueeze', dim);\n  }\n\n  // trigonometric\n\n  sin(): Tensor {\n    return this._executeUnaryOp('sin');\n  }\n\n  cos(): Tensor {\n    return this._executeUnaryOp('cos');\n  }\n\n  tan(): Tensor {\n    return this._executeUnaryOp('tan');\n  }\n\n  // reduction\n\n  sum(): Tensor {\n    return this._executeUnaryOp('sum');\n  }\n\n  mean(): Tensor {\n    return this._executeUnaryOp('mean');\n  }\n\n  // linalg\n\n  transpose(dim0: number, dim1: number): Tensor {\n    return this._executeOpRaw('transpose', dim0, dim1);\n  }\n\n  matmul(other: Tensor): Tensor {\n    return this._executeBinaryOp('matmul', other);\n  }\n\n  // comparison\n\n  lt(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('lt', other);\n  }\n\n  gt(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('gt', other);\n  }\n\n  le(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('le', other);\n  }\n\n  ge(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('ge', other);\n  }\n\n  eq(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('eq', other);\n  }\n\n  ne(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('ne', other);\n  }\n}\n","// https://docs.pytorch.org/docs/stable/notes/broadcasting.html\nexport function _broadcast_shape(a_shape: number[], b_shape: number[]): number[] {\n  const result_length = Math.max(a_shape.length, b_shape.length);\n  const padded_a_shape = [...Array(result_length - a_shape.length).fill(1), ...a_shape];\n  const padded_b_shape = [...Array(result_length - b_shape.length).fill(1), ...b_shape];\n\n  const result_shape: number[] = [];\n\n  for (let i = 0; i < result_length; i++) {\n    if (\n      padded_a_shape[i] !== padded_b_shape[i] &&\n      padded_a_shape[i] !== 1 &&\n      padded_b_shape[i] !== 1\n    ) {\n      throw new Error(`Shape mismatch: ${a_shape} and ${b_shape}`);\n    }\n\n    result_shape.push(Math.max(padded_a_shape[i], padded_b_shape[i]));\n  }\n\n  return result_shape;\n}\n\nexport function _pad_shape(shape: number[], broadcast_shape: number[]): number[] {\n  if (shape.length >= broadcast_shape.length) {\n    return shape;\n  }\n\n  return [...Array(broadcast_shape.length - shape.length).fill(1), ...shape];\n}\n\nexport function _get_original_index(\n  original_shape: number[],\n  new_shape: number[],\n  index: number\n): number {\n  let original_index = 0;\n  let cur_stride = 1;\n  let temp_index = index;\n\n  for (let i = original_shape.length - 1; i >= 0; i--) {\n    if (original_shape[i] > 1) {\n      const dim_index = temp_index % new_shape[i];\n      original_index = original_index + dim_index * cur_stride;\n    }\n    cur_stride *= original_shape[i];\n    temp_index = Math.floor(temp_index / new_shape[i]);\n  }\n  return original_index;\n}\n\nexport function _get_original_index_kernel(\n  original_shape: number[],\n  new_shape: number[],\n  index: number\n): number {\n  let original_index = 0;\n  let cur_stride = 1;\n  let temp_index = index;\n\n  for (let i = this.constants.shape_length - 1; i >= 0; i--) {\n    if (original_shape[i] > 1) {\n      const dim_index = temp_index % new_shape[i];\n      original_index = original_index + dim_index * cur_stride;\n    }\n    cur_stride = cur_stride * original_shape[i];\n    temp_index = Math.floor(temp_index / new_shape[i]);\n  }\n  return original_index;\n}\n\nexport function _get_original_index_from_transposed_index(\n  original_shape: number[],\n  dim0: number,\n  dim1: number,\n  transposed_index: number\n): number {\n  let original_index = 0;\n  let cur_stride = 1;\n  let temp_index = transposed_index;\n\n  let dim0_index = 0;\n  let dim1_index = 0;\n\n  for (let i = this.constants.shape_length - 1; i >= 0; i--) {\n    const dim_index = temp_index % original_shape[i];\n    if (i == dim0) {\n      dim0_index = dim_index;\n    }\n    if (i == dim1) {\n      dim1_index = dim_index;\n    }\n    temp_index = Math.floor(temp_index / original_shape[i]);\n  }\n\n  temp_index = transposed_index;\n\n  for (let j = this.constants.shape_length - 1; j >= 0; j--) {\n    const dim_index = temp_index % original_shape[j];\n    if (j == dim0) {\n      original_index = original_index + dim1_index * cur_stride;\n    } else if (j == dim1) {\n      original_index = original_index + dim0_index * cur_stride;\n    } else {\n      original_index = original_index + dim_index * cur_stride;\n    }\n    cur_stride = cur_stride * original_shape[j];\n    temp_index = Math.floor(temp_index / original_shape[j]);\n  }\n\n  return original_index;\n\n  // return transposed_index;\n}\n","import { Tensor } from '../tensor';\nimport { getOperation } from './registry';\n\nfunction generate_function(opname: string) {\n  return (...args: (Tensor | number)[]) => {\n    const operation = new (getOperation(opname))();\n    return operation.forward(...args);\n  };\n}\n\nfunction generate_unary_function(opname: string) {\n  return (a: Tensor | number) => {\n    if (typeof a == 'number') {\n      a = new Tensor(a);\n    }\n\n    const operation = new (getOperation(opname))();\n    return operation.forward(a);\n  };\n}\n\nfunction generate_binary_function(opname: string) {\n  return (a: Tensor | number, b: Tensor | number) => {\n    if (typeof a == 'number') {\n      a = new Tensor(a);\n    }\n\n    if (typeof b == 'number') {\n      b = new Tensor(b);\n    }\n\n    const operation = new (getOperation(opname))();\n    return operation.forward(a, b);\n  };\n}\n\n// debug operations\n\nexport const __left_index__ = generate_binary_function('__left_index__');\nexport const __right_index__ = generate_binary_function('__right_index__');\n\n// binary pointwise\n\nexport const add = generate_binary_function('add');\nexport const sub = generate_binary_function('sub');\nexport const mul = generate_binary_function('mul');\nexport const div = generate_binary_function('div');\nexport const pow = generate_binary_function('pow');\nexport const fmod = generate_binary_function('fmod');\nexport const maximum = generate_binary_function('maximum');\nexport const minimum = generate_binary_function('minimum');\n\n// unary pointwise\n\nexport const log = generate_unary_function('log');\nexport const sqrt = generate_unary_function('sqrt');\nexport const exp = generate_unary_function('exp');\nexport const square = generate_unary_function('square');\nexport const abs = generate_unary_function('abs');\nexport const sign = generate_unary_function('sign');\nexport const neg = generate_unary_function('neg');\nexport const reciprocal = generate_unary_function('reciprocal');\nexport const reshape = generate_function('reshape');\nexport const unsqueeze = generate_function('unsqueeze');\n\n// trigonometric\n\nexport const sin = generate_unary_function('sin');\nexport const cos = generate_unary_function('cos');\nexport const tan = generate_unary_function('tan');\n\n// reduction\n\nexport const sum = generate_unary_function('sum');\nexport const mean = generate_unary_function('mean');\n\n// linalg\n\nexport const transpose = generate_function('transpose');\nexport const matmul = generate_binary_function('matmul');\n\n// comparison\n\nexport const lt = generate_binary_function('lt');\nexport const gt = generate_binary_function('gt');\nexport const le = generate_binary_function('le');\nexport const ge = generate_binary_function('ge');\nexport const eq = generate_binary_function('eq');\nexport const ne = generate_binary_function('ne');","// This file is generated by scripts/generate_script.py from src/operations/ops.ts.j2\nimport { Tensor } from '../tensor';\nimport {\n  _broadcast_shape,\n  _get_original_index_from_transposed_index,\n  _get_original_index,\n  _get_original_index_kernel,\n  _pad_shape\n} from '../broadcasting';\nimport { Operation, BinaryOperation, UnaryOperation, nullOp, AccumulateGrad } from './base';\nimport * as functional from './functional';\nimport { registerOperation } from './registry';\n\n// debug operations\n\nconst ___left_index___kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = a_index;\n  }\n  return res;\n};\n\nfunction ___left_index___tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = ___left_index___kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"__Left_index__\", \"__left_index__\", backward_operations)\nexport class __Left_index__ extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return ___left_index___tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('__left_index__', __Left_index__);\n\nconst ___right_index___kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = b_index;\n  }\n  return res;\n};\n\nfunction ___right_index___tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = ___right_index___kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"__Right_index__\", \"__right_index__\", backward_operations)\nexport class __Right_index__ extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return ___right_index___tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('__right_index__', __Right_index__);\n\n// binary pointwise\n\nconst _add_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = a[a_index] + b[b_index];\n  }\n  return res;\n};\n\nfunction _add_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _add_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Add\", \"add\", backward_operations)\nexport class Add extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _add_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz);\n    bFn.backward(dz);\n  }\n}\nregisterOperation('add', Add);\n\nconst _sub_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = a[a_index] - b[b_index];\n  }\n  return res;\n};\n\nfunction _sub_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _sub_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Sub\", \"sub\", backward_operations)\nexport class Sub extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _sub_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz);\n    bFn.backward(dz.mul(new Tensor(-1)));\n  }\n}\nregisterOperation('sub', Sub);\n\nconst _mul_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = a[a_index] * b[b_index];\n  }\n  return res;\n};\n\nfunction _mul_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _mul_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Mul\", \"mul\", backward_operations)\nexport class Mul extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _mul_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(b));\n    bFn.backward(dz.mul(a));\n  }\n}\nregisterOperation('mul', Mul);\n\nconst _div_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = a[a_index] / b[b_index];\n  }\n  return res;\n};\n\nfunction _div_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _div_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Div\", \"div\", backward_operations)\nexport class Div extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _div_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.div(b));\n    bFn.backward(dz.mul(a).mul(new Tensor(-1)).div(b).div(b));\n  }\n}\nregisterOperation('div', Div);\n\nconst _pow_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = Math.pow(a[a_index], b[b_index]);\n  }\n  return res;\n};\n\nfunction _pow_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _pow_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Pow\", \"pow\", backward_operations)\nexport class Pow extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _pow_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(b).mul(a.pow(b.sub(new Tensor(1)))));\n    bFn.backward(dz.mul(a.pow(b)).mul(a.log()));\n  }\n}\nregisterOperation('pow', Pow);\n\nconst _fmod_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = a[a_index] % b[b_index];\n  }\n  return res;\n};\n\nfunction _fmod_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _fmod_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Fmod\", \"fmod\", backward_operations)\nexport class Fmod extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _fmod_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz);\n  }\n}\nregisterOperation('fmod', Fmod);\n\nconst _maximum_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = Math.max(a[a_index], b[b_index]);\n  }\n  return res;\n};\n\nfunction _maximum_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _maximum_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Maximum\", \"maximum\", backward_operations)\nexport class Maximum extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _maximum_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.ge(b)));\n    bFn.backward(dz.mul(b.gt(a)));\n  }\n}\nregisterOperation('maximum', Maximum);\n\nconst _minimum_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = Math.min(a[a_index], b[b_index]);\n  }\n  return res;\n};\n\nfunction _minimum_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _minimum_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Minimum\", \"minimum\", backward_operations)\nexport class Minimum extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _minimum_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.le(b)));\n    bFn.backward(dz.mul(b.lt(a)));\n  }\n}\nregisterOperation('minimum', Minimum);\n\n\nfunction _powint_tensor(a: Tensor, n: number, operation: Operation | null = null): Tensor {\n  const data = new Array(a.dataLength());\n  for (let i = 0; i < data.length; i++) {\n    data[i] = Math.pow(a.data[i], n);\n  }\n  return new Tensor(\n    data,\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\nexport class PowInt extends Operation {\n  private n: number;\n  protected _forward(a: Tensor, n: number): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n      this.n = n;\n    }\n\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _powint_tensor(a, n, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const n = this.n;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(n).mul(a.pow(n - 1)));\n  }\n}\nregisterOperation('powint', PowInt);\n\n// unary pointwise\n\n// function generated from unary_op_base(\"log\", \"Math.log(a[x])\")\n\nconst _log_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.log(a[x]);\n  }\n  return res;\n};\n\nfunction _log_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _log_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Log\", \"log\", backward_operations)\nexport class Log extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _log_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(new Tensor(1).div(a));\n  }\n}\nregisterOperation('log', Log);\n\n// function generated from unary_op_base(\"sqrt\", \"Math.sqrt(a[x])\")\n\nconst _sqrt_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.sqrt(a[x]);\n  }\n  return res;\n};\n\nfunction _sqrt_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _sqrt_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Sqrt\", \"sqrt\", backward_operations)\nexport class Sqrt extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _sqrt_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(new Tensor(1).div(a.sqrt()).div(2));\n  }\n}\nregisterOperation('sqrt', Sqrt);\n\n// function generated from unary_op_base(\"exp\", \"Math.exp(a[x])\")\n\nconst _exp_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.exp(a[x]);\n  }\n  return res;\n};\n\nfunction _exp_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _exp_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Exp\", \"exp\", backward_operations)\nexport class Exp extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _exp_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.exp()));\n  }\n}\nregisterOperation('exp', Exp);\n\n// function generated from unary_op_base(\"square\", \"a[x] * a[x]\")\n\nconst _square_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = a[x] * a[x];\n  }\n  return res;\n};\n\nfunction _square_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _square_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Square\", \"square\", backward_operations)\nexport class Square extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _square_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a).mul(new Tensor(2)));\n  }\n}\nregisterOperation('square', Square);\n\n// function generated from unary_op_base(\"abs\", \"Math.abs(a[x])\")\n\nconst _abs_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.abs(a[x]);\n  }\n  return res;\n};\n\nfunction _abs_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _abs_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Abs\", \"abs\", backward_operations)\nexport class Abs extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _abs_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(functional.sign(a)));\n  }\n}\nregisterOperation('abs', Abs);\n\n// function generated from unary_op_base(\"sign\", \"Math.sign(a[x])\")\n\nconst _sign_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.sign(a[x]);\n  }\n  return res;\n};\n\nfunction _sign_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _sign_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Sign\", \"sign\", backward_operations)\nexport class Sign extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _sign_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('sign', Sign);\n\n// function generated from unary_op_base(\"neg\", \"-a[x]\")\n\nconst _neg_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = -a[x];\n  }\n  return res;\n};\n\nfunction _neg_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _neg_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Neg\", \"neg\", backward_operations)\nexport class Neg extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _neg_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(new Tensor(-1)));\n  }\n}\nregisterOperation('neg', Neg);\n\n// function generated from unary_op_base(\"reciprocal\", \"1 / a[x]\")\n\nconst _reciprocal_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = 1 / a[x];\n  }\n  return res;\n};\n\nfunction _reciprocal_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _reciprocal_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Reciprocal\", \"reciprocal\", backward_operations)\nexport class Reciprocal extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _reciprocal_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.pow(-2)));\n  }\n}\nregisterOperation('reciprocal', Reciprocal);\n\nexport class Reshape extends Operation {\n  protected _forward(a: Tensor, shape: number[]) {\n    const previous_length = a.dataLength();\n    const target_length = shape.reduce((acc, val) => acc * val, 1);\n\n    if (previous_length !== target_length) {\n      throw new Error('Shape mismatch: ' + a.shape + ' and ' + shape);\n    }\n\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    if (a.grad_fn) {\n      this.next_functions.push(a.grad_fn);\n    } else if (a.requires_grad) {\n      const acc = new AccumulateGrad();\n      acc.variable = a;\n      this.next_functions.push(acc);\n    } else {\n      this.next_functions.push(nullOp);\n    }\n\n    return new Tensor(\n      a.data,\n      { requires_grad: a.requires_grad },\n      { operation: a.requires_grad ? this : null, shape }\n    );\n  }\n  protected _backward(dz: Tensor) {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.reshape(a.shape));\n  }\n}\nregisterOperation('reshape', Reshape);\n\nexport class Unsqueeze extends Operation {\n  protected _forward(a: Tensor, dim: number) {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    if (a.grad_fn) {\n      this.next_functions.push(a.grad_fn);\n    } else if (a.requires_grad) {\n      const acc = new AccumulateGrad();\n      acc.variable = a;\n      this.next_functions.push(acc);\n    } else {\n      this.next_functions.push(nullOp);\n    }\n\n    if (dim < 0) {\n      dim += a.shape.length + 1;\n    }\n\n    const shape = [...a.shape];\n    shape.splice(dim, 0, 1);\n\n    return new Tensor(\n      a.data,\n      { requires_grad: a.requires_grad },\n      { operation: a.requires_grad ? this : null, shape }\n    );\n  }\n  protected _backward(dz: Tensor) {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.reshape(a.shape));\n  }\n}\nregisterOperation('unsqueeze', Unsqueeze);\n\n// trigonometric\n\n// function generated from unary_op_base(\"sin\", \"Math.sin(a[x])\")\n\nconst _sin_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.sin(a[x]);\n  }\n  return res;\n};\n\nfunction _sin_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _sin_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Sin\", \"sin\", backward_operations)\nexport class Sin extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _sin_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.cos()));\n  }\n}\nregisterOperation('sin', Sin);\n\n// function generated from unary_op_base(\"cos\", \"Math.cos(a[x])\")\n\nconst _cos_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.cos(a[x]);\n  }\n  return res;\n};\n\nfunction _cos_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _cos_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Cos\", \"cos\", backward_operations)\nexport class Cos extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _cos_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.sin().neg()));\n  }\n}\nregisterOperation('cos', Cos);\n\n// function generated from unary_op_base(\"tan\", \"Math.tan(a[x])\")\n\nconst _tan_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.tan(a[x]);\n  }\n  return res;\n};\n\nfunction _tan_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _tan_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Tan\", \"tan\", backward_operations)\nexport class Tan extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _tan_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.cos().pow(-2)));\n  }\n}\nregisterOperation('tan', Tan);\n\n// reduction\n\nfunction _sum_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  return new Tensor(\n    a.toArray().reduce((acc, val) => acc + val, 0),\n    { requires_grad: a.requires_grad },\n    { operation: operation }\n  );\n}\n\n// class generated from unary_op_class(\"Sum\", \"sum\", backward_operations)\nexport class Sum extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _sum_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    const result = new Tensor(Array(a.dataLength()).fill(dz.item()));\n    aFn.backward(result);\n  }\n}\nregisterOperation('sum', Sum);\n\nfunction _mean_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  return new Tensor(\n    a.toArray().reduce((acc, val) => acc + val, 0) / a.dataLength(),\n    { requires_grad: a.requires_grad },\n    { operation: operation }\n  );\n}\n\n// class generated from unary_op_class(\"Mean\", \"mean\", backward_operations)\nexport class Mean extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _mean_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    const result = new Tensor(Array(a.dataLength()).fill(dz.item() / a.dataLength()));\n    aFn.backward(result);\n  }\n}\nregisterOperation('mean', Mean);\n\n// linalg\n\nfunction _transpose_tensor(\n  a: Tensor,\n  dim0: number,\n  dim1: number,\n  operation: Operation | null = null\n): Tensor {\n  const output_shape = [...a.shape];\n  [output_shape[dim0], output_shape[dim1]] = [output_shape[dim1], output_shape[dim0]];\n  const size = a.dataLength();\n  const data = new Array(size);\n\n  const a_strides = new Array(a.shape.length);\n  const out_strides = new Array(output_shape.length);\n  for (let i = a.shape.length - 1, s = 1; i >= 0; i--) {\n    a_strides[i] = s;\n    s *= a.shape[i];\n  }\n  for (let i = output_shape.length - 1, s = 1; i >= 0; i--) {\n    out_strides[i] = s;\n    s *= output_shape[i];\n  }\n\n  for(let i=0; i<size; i++) {\n    let idx = i;\n    let input_idx = 0;\n    for (let d = 0; d < output_shape.length; d++) {\n      const stride = out_strides[d];\n      const coord = Math.floor(idx / stride);\n      idx %= stride;\n\n      let input_d = d;\n      if (d === dim0) input_d = dim1;\n      else if (d === dim1) input_d = dim0;\n\n      input_idx += coord * a_strides[input_d];\n    }\n    data[i] = a.data[input_idx];\n  }\n\n  return new Tensor(\n    data,\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: output_shape }\n  );\n}\nexport class Transpose extends Operation {\n  private dim0: number;\n  private dim1: number;\n  protected _forward(a: Tensor, dim0: number, dim1: number): Tensor {\n    if (a.requires_grad) {\n        this.saved_tensors = [a];\n        this.dim0 = dim0;\n        this.dim1 = dim1;\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _transpose_tensor(a, dim0, dim1, this);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const dim0 = this.dim0;\n    const dim1 = this.dim1;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.transpose(dim0, dim1));\n  }\n}\nregisterOperation('transpose', Transpose);\n\nfunction _matmul_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  if (a.shape.length == 1 && b.shape.length == 1) {\n    return a.mul(b).sum();\n  }\n\n  const a_1d = a.shape.length == 1;\n  const b_1d = b.shape.length == 1;\n\n  const a_shape = a_1d ? [1, a.shape[0]] : a.shape;\n  const b_shape = b_1d ? [b.shape[0], 1] : b.shape;\n\n  if (a_shape[a_shape.length - 1] != b_shape[b_shape.length - 2]) {\n    throw new Error('Shape mismatch: ' + a.shape + ' and ' + b.shape);\n  }\n\n  const broadcast_shape = _broadcast_shape(a_shape.slice(0, -2), b_shape.slice(0, -2)).concat([\n    a_shape[a_shape.length - 2],\n    b_shape[b_shape.length - 1]\n  ]);\n\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n  const data = new Array(output_size).fill(0);\n\n  const padded_a_shape = _pad_shape(a_shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b_shape, broadcast_shape);\n\n  const dim_M = broadcast_shape[broadcast_shape.length - 2];\n  const dim_N = broadcast_shape[broadcast_shape.length - 1];\n  const dim_K = a_shape[a_shape.length - 1]; // or b_shape[b_shape.length - 2]\n\n  for (let i = 0; i < output_size; i++) {\n    const mn_idx = i % (dim_M * dim_N);\n    const m = Math.floor(mn_idx / dim_N);\n    const n = mn_idx % dim_N;\n\n    let base_a = _get_original_index(padded_a_shape, broadcast_shape, i - n);\n    let base_b = _get_original_index(padded_b_shape, broadcast_shape, i - m * dim_N);\n\n    let sum = 0;\n    for(let k=0; k < dim_K; k++) {\n      sum += a.data[base_a + k] * b.data[base_b + k * dim_N];\n    }\n    data[i] = sum;\n  }\n\n  let shape_after_removing_extra_dims = [...broadcast_shape];\n\n  if (a_1d) {\n    shape_after_removing_extra_dims = shape_after_removing_extra_dims\n      .slice(0, -2)\n      .concat([broadcast_shape[broadcast_shape.length - 1]]);\n  }\n\n  if (b_1d) {\n    shape_after_removing_extra_dims = shape_after_removing_extra_dims.slice(0, -1);\n  }\n\n  return new Tensor(\n    data,\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: shape_after_removing_extra_dims }\n  );\n}\n// class generated from binary_op_class(\"Matmul\", \"matmul\", backward_operations)\nexport class Matmul extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _matmul_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('matmul', Matmul);\n\n// comparison\n\nconst _lt_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = (a[a_index] < b[b_index]) ? 1 : 0;\n  }\n  return res;\n};\n\nfunction _lt_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _lt_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Lt\", \"lt\", backward_operations)\nexport class Lt extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _lt_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('lt', Lt);\n\nconst _gt_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = (a[a_index] > b[b_index]) ? 1 : 0;\n  }\n  return res;\n};\n\nfunction _gt_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _gt_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Gt\", \"gt\", backward_operations)\nexport class Gt extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _gt_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('gt', Gt);\n\nconst _le_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = (a[a_index] <= b[b_index]) ? 1 : 0;\n  }\n  return res;\n};\n\nfunction _le_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _le_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Le\", \"le\", backward_operations)\nexport class Le extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _le_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('le', Le);\n\nconst _ge_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = (a[a_index] >= b[b_index]) ? 1 : 0;\n  }\n  return res;\n};\n\nfunction _ge_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _ge_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Ge\", \"ge\", backward_operations)\nexport class Ge extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _ge_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('ge', Ge);\n\nconst _eq_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = (a[a_index] == b[b_index]) ? 1 : 0;\n  }\n  return res;\n};\n\nfunction _eq_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _eq_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Eq\", \"eq\", backward_operations)\nexport class Eq extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _eq_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('eq', Eq);\n\nconst _ne_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = (a[a_index] != b[b_index]) ? 1 : 0;\n  }\n  return res;\n};\n\nfunction _ne_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _ne_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Ne\", \"ne\", backward_operations)\nexport class Ne extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _ne_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('ne', Ne);","export function get_shape_from_args(args: number[] | number[][]): number[] {\n  if (Array.isArray(args[0])) {\n    return args[0];\n  }\n\n  return args as number[];\n}\n","import { Tensor } from '../tensor';\nimport { get_shape_from_args } from './utils';\n\n/* TODO: use the correct distributions */\n\nexport function randn(...args: number[] | number[][]): Tensor {\n  const shape = get_shape_from_args(args);\n  const tensor = new Tensor(Array(shape.reduce((a, b) => a * b, 1)).fill(Math.random()));\n  tensor.shape = shape;\n  return tensor;\n}\n\nexport function rand(...args: number[] | number[][]): Tensor {\n  const shape = get_shape_from_args(args);\n  const tensor = new Tensor(Array(shape.reduce((a, b) => a * b, 1)).fill(Math.random()));\n  tensor.shape = shape;\n  return tensor;\n}\n\nexport function randint(low: number, high: number, shape: number[]): Tensor {\n  const tensor = new Tensor(\n    Array(shape.reduce((a, b) => a * b, 1)).fill(Math.floor(Math.random() * (high - low) + low))\n  );\n  tensor.shape = shape;\n  return tensor;\n}\n","import { Tensor } from '../tensor';\nimport { get_shape_from_args } from './utils';\n\nexport function ones(...args: number[] | number[][]): Tensor {\n  const shape = get_shape_from_args(args);\n  const tensor = new Tensor(Array(shape.reduce((a, b) => a * b, 1)).fill(1));\n  tensor.shape = shape;\n  return tensor;\n}\n\nexport function zeros(...args: number[] | number[][]): Tensor {\n  const shape = get_shape_from_args(args);\n  const tensor = new Tensor(Array(shape.reduce((a, b) => a * b, 1)).fill(0));\n  tensor.shape = shape;\n  return tensor;\n}\n\nexport function ones_like(tensor: Tensor): Tensor {\n  return ones(tensor.shape);\n}\n\nexport function zeros_like(tensor: Tensor): Tensor {\n  return zeros(tensor.shape);\n}\n","import { Tensor } from '../tensor';\n\nexport function linspace(start: number, end: number, steps: number) {\n  const data = [];\n  const step = (end - start) / (steps - 1);\n  for (let i = 0; i < steps - 1; i++) {\n    data.push(start + i * step);\n  }\n  data.push(end);\n  return new Tensor(data);\n}\n\nexport function arange(start: number, end: number = undefined, step: number = 1) {\n  const data = [];\n  for (let i = start; i < end; i += step) {\n    data.push(i);\n  }\n  return new Tensor(data);\n}","// This file is generated by scripts/generate_script.py from src/nn/ops.ts.j2\nimport { Tensor } from '../tensor';\nimport {\n  _broadcast_shape,\n  _get_original_index_from_transposed_index,\n  _get_original_index_kernel,\n  _pad_shape\n} from '../broadcasting';\nimport { Operation, BinaryOperation, UnaryOperation, nullOp, AccumulateGrad } from '../operations/base';\nimport { registerOperation } from '../operations/registry';\n\n// function generated from unary_op_base(\"relu\", \"Math.max(a[x], 0)\")\n\nconst _relu_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.max(a[x], 0);\n  }\n  return res;\n};\n\nfunction _relu_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _relu_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Relu\", \"relu\", backward_operations)\nexport class Relu extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _relu_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.gt(0)));\n  }\n}\nregisterOperation('relu', Relu);\n\n// function generated from unary_op_base(\"sigmoid\", \"1 / (1 + Math.exp(-a[x]))\")\n\nconst _sigmoid_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = 1 / (1 + Math.exp(-a[x]));\n  }\n  return res;\n};\n\nfunction _sigmoid_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _sigmoid_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Sigmoid\", \"sigmoid\", backward_operations)\nexport class Sigmoid extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _sigmoid_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.exp().add(1).pow(-2).reciprocal().mul(a.exp()).mul(-1)));\n  }\n}\nregisterOperation('sigmoid', Sigmoid);","import { Tensor } from \"../tensor\";\nimport { NestedNumberArray } from \"../tensor\";\nimport { Operation } from \"../operations/base\";\nimport { rand } from \"../creation\";\nimport { functional } from \".\";\n\nexport class Parameter extends Tensor {\n  constructor(\n    data: NestedNumberArray | Tensor | Parameter,\n    // Default to requires_grad=true\n    options: { requires_grad?: boolean } = {\n        requires_grad: true,\n    },\n    internal_options: { operation?: Operation; shape?: number[] } = {}\n  ) {\n    if (data instanceof Tensor) {\n      super(data.data, { requires_grad: true }, { shape: data.shape });\n    } else if (data instanceof Parameter) {\n      super(data.data, { requires_grad: true }, { shape: data.shape });\n    } else {\n      super(data, options, internal_options);\n    }\n  }\n}\n\nexport abstract class Module {\n  private _modules: { [key: string]: Module };\n  private _parameters: { [key: string]: Parameter };\n\n  constructor() {\n    this._parameters = {};\n    this._modules = {};\n  }\n\n  private register_parameter(parameter_name: string, parameter: Parameter) {\n    this._parameters[parameter_name] = parameter;\n  }\n\n  private register_module(module_name: string, module: Module) {\n    this._modules[module_name] = module;\n  }\n\n  protected register(name: string, value: Parameter | Module) {\n    if (value instanceof Parameter) {\n      this.register_parameter(name, value);\n    } else {\n      this.register_module(name, value);\n    }\n  }\n\n  public abstract forward(...args: Tensor[]): Tensor;\n\n  public parameters(): Parameter[] {\n    let params: Parameter[] = Object.values(this._parameters);\n    for (const module of Object.values(this._modules)) {\n      params = params.concat(module.parameters());\n    }\n    return params;\n  }\n}\n\nexport class Linear extends Module {\n  private weight: Parameter;\n  private bias: Parameter;\n\n  constructor(in_features: number, out_features: number) {\n    super();\n    const k = Math.sqrt(1 / in_features);\n\n    this.weight = new Parameter(rand([out_features, in_features]).mul(2 * k).sub(k));\n    this.bias = new Parameter(rand([out_features]).mul(2 * k).sub(k));\n\n    this.register(\"weight\", this.weight);\n    this.register(\"bias\", this.bias);\n  }\n\n  forward(input: Tensor) {\n    return input.matmul(this.weight.transpose(0, 1)).add(this.bias);\n  }\n}\n\nexport class ReLU extends Module {\n  constructor() {\n    super();\n  }\n\n  forward(input: Tensor) {\n    return functional.relu(input);\n  }\n}\n\nexport class Sigmoid extends Module {\n  constructor() {\n    super();\n  }\n\n  forward(input: Tensor) {\n    return functional.sigmoid(input);\n  }\n}\n","import { Tensor } from \"../tensor\";\n\nabstract class Loss {\n  abstract forward(input: Tensor, target: Tensor): Tensor;\n}\n\nexport class MSELoss extends Loss {\n  constructor() {\n    super();\n  }\n\n  forward(input: Tensor, target: Tensor) {\n    return input.sub(target).pow(2).mean();\n  }\n}\n\nexport class L1Loss extends Loss {\n  constructor() {\n    super();\n  }\n\n  forward(input: Tensor, target: Tensor) {\n    return input.sub(target).abs().mean();\n  }\n}\n\nexport class BCELoss extends Loss {\n  private weight: Tensor | null;\n\n  constructor(weight: Tensor | null = null) {\n    super();\n    this.weight = weight;\n  }\n\n  forward(input: Tensor, target: Tensor) {\n    const left = target.mul(input.log());\n    const right = target.neg().add(1).mul(input.neg().add(1).log());\n    const loss = left.add(right).neg().mean();\n    if (this.weight) {\n      return loss.mul(this.weight);\n    }\n    return loss;\n  }\n}","import { Tensor } from \"../tensor\";\nimport { getOperation } from \"../operations/registry\";\n\nfunction generate_function(opname: string) {\n  return (...args: (Tensor | number)[]) => {\n    const operation = new (getOperation(opname))();\n    return operation.forward(...args);\n  };\n}\n\nfunction generate_unary_function(opname: string) {\n  return (a: Tensor | number) => {\n    if (typeof a == 'number') {\n      a = new Tensor(a);\n    }\n\n    const operation = new (getOperation(opname))();\n    return operation.forward(a);\n  };\n}\n\nfunction generate_binary_function(opname: string) {\n  return (a: Tensor | number, b: Tensor | number) => {\n    if (typeof a == 'number') {\n      a = new Tensor(a);\n    }\n\n    if (typeof b == 'number') {\n      b = new Tensor(b);\n    }\n\n    const operation = new (getOperation(opname))();\n    return operation.forward(a, b);\n  };\n}\n\nexport const relu = generate_unary_function('relu');\nexport const sigmoid = generate_unary_function('sigmoid');\n","import { Parameter } from \"../nn/module\";\n\nexport abstract class Optimizer {\n  params: Parameter[];\n  defaults: { [key: string]: any };\n\n  constructor(params: Parameter[], defaults: { [key: string]: any }) {\n    this.params = params;\n    this.defaults = defaults;\n  }\n\n  public zero_grad(): void {\n    for (const param of this.params) {\n      param.grad = null;\n    }\n  }\n\n  abstract step(): void;\n}\n","import { Optimizer } from \"./base\";\nimport { Parameter } from \"../nn/module\";\nimport { Tensor } from \"../tensor\";\nimport { zeros_like } from \"../creation\";\n\nexport class SGD extends Optimizer {\n  private state: Map<Parameter, { velocity: Tensor }> = new Map();\n  private lr: number;\n  private momentum: number;\n  private dampening: number;\n  private weight_decay: number;\n  private nesterov: boolean;\n  private maximize: boolean;\n\n  constructor(\n    params: Parameter[],\n    lr: number = 0.001,\n    momentum: number = 0.0,\n    dampening: number = 0.0,\n    weight_decay: number = 0.0,\n    nesterov: boolean = false,\n    maximize: boolean = false,\n  ) {\n    super(params, {});\n    this.lr = lr;\n    this.momentum = momentum;\n    this.dampening = dampening;\n    this.weight_decay = weight_decay;\n    this.nesterov = nesterov;\n    this.maximize = maximize;\n  }\n\n  step(): void {\n    for (const param of this.params) {\n      let g = this.maximize ? param.grad.mul(-1) : param.grad;\n      if (this.weight_decay !== 0) {\n        g = g.add(param.mul(this.weight_decay));\n      }\n\n      if (this.momentum !== 0) {\n        if (this.state.has(param)) {\n          let buf = this.state.get(param)!.velocity;\n          buf = buf.mul(this.momentum)\n          buf = buf.add(g.mul(1 - this.dampening));\n          this.state.set(param, { velocity: buf });\n        } else {\n          this.state.set(param, { velocity: g });\n        }\n\n        let buf = this.state.get(param)!.velocity;\n\n        if (this.nesterov) {\n          g = g.add(buf.mul(this.momentum));\n        } else {\n          g = buf;\n        }\n\n        this.state.set(param, { velocity: buf });\n      }\n\n      // potentially unsafe?\n      const newParam = param.sub(g.mul(this.lr));\n      param.data = newParam.data;\n    }\n  }\n}\n\nexport class Adam extends Optimizer {\n  private state: Map<Parameter, {\n    m: Tensor,\n    v: Tensor,\n    vmax: Tensor\n  }> = new Map();\n\n  private step_count: number = 0;\n  private lr: number;\n  private beta1: number;\n  private beta2: number;\n  private eps: number;\n  private weight_decay: number;\n  private amsgrad: boolean;\n  private maximize: boolean;\n\n  constructor(\n    params: Parameter[],\n    lr: number = 0.001,\n    betas: [number, number] = [0.9, 0.999],\n    eps: number = 1e-8,\n    weight_decay: number = 0.0,\n    amsgrad: boolean = false,\n    maximize: boolean = false,\n  ) {\n    super(params, {});\n    this.lr = lr;\n    this.beta1 = betas[0];\n    this.beta2 = betas[1];\n    this.eps = eps;\n    this.weight_decay = weight_decay;\n    this.amsgrad = amsgrad;\n    this.maximize = maximize;\n  }\n\n  step(): void {\n    this.step_count += 1;\n    for (const param of this.params) {\n      let grad = this.maximize ? param.grad.mul(-1) : param.grad;\n\n      if (this.weight_decay !== 0) {\n        grad = grad.add(param.mul(this.weight_decay));\n      }\n\n      // Initialize\n      if (!this.state.has(param)) {\n        this.state.set(param, {\n          m: zeros_like(param),\n          v: zeros_like(param),\n          vmax: zeros_like(param),\n        });\n      }\n\n      const state = this.state.get(param)!;\n\n      state.m = state.m.mul(this.beta1).add(grad.mul(1 - this.beta1));\n      state.v = state.v.mul(this.beta2).add(grad.mul(grad).mul(1 - this.beta2));\n\n      const biasCorrection1 = 1 - Math.pow(this.beta1, this.step_count);\n      const biasCorrection2 = 1 - Math.pow(this.beta2, this.step_count);\n\n      let vhat: Tensor;\n      const mhat = state.m.div(biasCorrection1);\n      if (this.amsgrad) {\n        state.vmax = state.vmax.maximum(state.v);\n        vhat = state.vmax.div(biasCorrection2);\n      } else {\n        vhat = state.v.div(biasCorrection2);\n      }\n\n      const update = mhat.div(vhat.sqrt().add(this.eps)).mul(this.lr);\n\n      const newParam = param.sub(update);\n      param.data = newParam.data;\n    }\n  }\n}"],"names":["index","generate_function","generate_unary_function","generate_binary_function","functional.sign","sum","Sigmoid","module","functional.relu","functional.sigmoid","buf"],"mappings":";;;;;;;AAAA,MAAI,WAAW;AAER,QAAM,YAAY,6BAAM;AAC7B,WAAO;AAAA,EACT,GAFyB;AAIlB,QAAM,WAAW,IAAI,YAAA;AACrB,QAAM,SAAS;AAAA,IACpB,wBAAwB;AAAA,IACxB,uBAAuB;AAAA,IACvB,0BAA0B;AAAA,IAC1B,yBAAyB;AAAA,IACzB,2BAA2B;AAAA,IAC3B,0BAA0B;AAAA,IAC1B,kCAAkC;AAAA,IAClC,iCAAiC;AAAA,EACnC;ACbA,WAAS,sBAAsB,MAA+C;AAC5E,eAAW,OAAO,MAAM;AACtB,UAAI,eAAe,UAAU,IAAI,eAAe;AAC9C,eAAO;AAAA,MACT;AAAA,IACF;AACA,WAAO;AAAA,EACT;AAPS;AAST,QAAe,aAAf,MAAe,WAAU;AAAA,IAChB,KAAa,UAAA;AAAA,IACb,iBAA8B,CAAA;AAAA,IAC9B,gBAA0B,CAAA;AAAA,IAC1B,oBAA8B,CAAA;AAAA,IAKrC,WAAW,MAA8C;AACvD,YAAM,gBAAgB,mBAAmB,GAAG,IAAI;AAChD,eAAS,cAAc,IAAI,YAAY,OAAO,0BAA0B;AAAA,QACtE,QAAQ;AAAA,UACN,WAAW;AAAA,UACX;AAAA,UACA;AAAA,QAAA;AAAA,MACF,CACD,CAAC;AACF,YAAM,SAAS,KAAK,SAAS,GAAG,IAAI;AACpC,eAAS,cAAc,IAAI,YAAY,OAAO,yBAAyB;AAAA,QACrE,QAAQ;AAAA,UACN,WAAW;AAAA,UACX;AAAA,UACA;AAAA,UACA;AAAA,QAAA;AAAA,MACF,CACD,CAAC;AACF,aAAO;AAAA,IACT;AAAA,IAEA,SAAS,IAAkB;AACzB,eAAS,cAAc,IAAI,YAAY,OAAO,2BAA2B,EAAE,QAAQ,EAAE,WAAW,MAAM,GAAA,EAAG,CAAG,CAAC;AAC7G,iBAAW,KAAK,KAAK,mBAAmB;AACtC,YAAI,CAAC,EAAE,MAAM;AACX,YAAE,OAAO,IAAI,OAAO,IAAI,MAAM,EAAE,YAAY,EAAE,KAAK,CAAC,CAAC;AAAA,QACvD;AACA,UAAE,OAAO,EAAE,KAAK,IAAI,EAAE;AAAA,MACxB;AACA,WAAK,UAAU,EAAE;AACjB,eAAS,cAAc,IAAI,YAAY,OAAO,0BAA0B,EAAE,QAAQ,EAAE,WAAW,MAAM,GAAA,EAAG,CAAG,CAAC;AAAA,IAC9G;AAAA,EACF;AAzCyB;AAAzB,MAAe,YAAf;AA2CA,QAAM,UAAN,MAAM,gBAAe,UAAU;AAAA,IACnB,YAAY,MAA8C;AAClE,YAAM,IAAI,MAAM,6BAA6B;AAAA,IAC/C;AAAA,IACU,UAAU,IAAkB;AACpC;AAAA,IACF;AAAA,EACF;AAP+B;AAA/B,MAAM,SAAN;AASO,QAAM,SAAS,IAAI,OAAA;AAE1B,QAAe,kBAAf,MAAe,wBAAuB,UAAU;AAAA,EAGhD;AAHgD;AAAhD,MAAe,iBAAf;AAKA,QAAe,mBAAf,MAAe,yBAAwB,UAAU;AAAA,EAGjD;AAHiD;AAAjD,MAAe,kBAAf;AAWO,QAAM,kBAAN,MAAM,wBAAuB,eAAe;AAAA,IAC1C;AAAA,IAEG,SAAS,UAA0B;AAC3C,WAAK,WAAW;AAChB,aAAO;AAAA,IACT;AAAA,IAEU,UAAU,IAAkB;AACpC,UAAI,CAAC,KAAK,SAAS,MAAM;AACvB,aAAK,SAAS,OAAO,IAAI,OAAO,IAAI,MAAM,KAAK,SAAS,WAAA,CAAY,EAAE,KAAK,CAAC,CAAC;AAAA,MAC/E;AACA,eAAS,cAAc,IAAI,YAAY,OAAO,kCAAkC,EAAE,QAAQ,EAAE,WAAW,MAAM,GAAA,EAAG,CAAG,CAAC;AACpH,WAAK,SAAS,OAAO,KAAK,SAAS,KAAK,IAAI,EAAE;AAC9C,eAAS,cAAc,IAAI,YAAY,OAAO,iCAAiC,EAAE,QAAQ,EAAE,WAAW,MAAM,GAAA,EAAG,CAAG,CAAC;AAAA,IACrH;AAAA,EACF;AAhBmD;AAA5C,MAAM,iBAAN;AC/EP,QAAM,iCAAiB,IAAA;AACvB,QAAM,uCAAuB,IAAA;AAEtB,WAAS,kBAAkB,MAAc,MAA4B;AAC1E,eAAW,IAAI,MAAM,IAAI;AAAA,EAC3B;AAFgB;AAIT,WAAS,aAAa,MAAoC;AAC/D,UAAM,OAAO,WAAW,IAAI,IAAI;AAChC,QAAI,CAAC,MAAM;AACT,YAAM,IAAI,MAAM,cAAc,IAAI,sBAAsB;AAAA,IAC1D;AACA,WAAO;AAAA,EACT;AANgB;AAQT,WAAS,kBAAkB,MAAyB;AACzD,UAAM,YAAY,iBAAiB,IAAI,IAAI;AAC3C,QAAI,CAAC,WAAW;AACd,uBAAiB,IAAI,MAAM,KAAK,aAAa,IAAI,IAAI;AACrD,aAAO,iBAAiB,IAAI,IAAI;AAAA,IAClC;AACA,WAAO;AAAA,EACT;AAPgB;ACKhB,WAAS,WAAW,MAAmC;AACrD,QAAI,YAAY,OAAO,IAAI,GAAG;AAC5B,aAAO,CAAC,KAAK,MAAM;AAAA,IACrB;AAEA,UAAM,QAAQ,CAAA;AACd,WAAO,MAAM,QAAQ,IAAI,GAAG;AAC1B,YAAM,KAAK,KAAK,MAAM;AACtB,aAAO,KAAK,CAAC;AAAA,IACf;AACA,WAAO;AAAA,EACT;AAXS;AAaT,WAAS,SAAS,MAAmC;AACnD,QAAI,MAAM,QAAQ,IAAI,GAAG;AACvB,aAAO,KAAK,QAAQ,CAAA,SAAQ,SAAS,IAAI,CAAC;AAAA,IAC5C,WAAW,YAAY,OAAO,IAAI,GAAG;AACnC,aAAO,MAAM,KAAK,IAAI;AAAA,IACxB,OAAO;AACL,aAAO,CAAC,IAAI;AAAA,IACd;AAAA,EACF;AARS;AAUF,QAAM,UAAN,MAAM,QAAO;AAAA,IACX,KAAa,UAAA;AAAA,IACpB;AAAA,IACA;AAAA,IACA,UAA4B;AAAA,IACrB,OAAsB;AAAA,IAE7B;AAAA,IAEA,YACE,MACA,UAAuC,CAAA,GACvC,mBAAgE,CAAA,GAChE;AACA,WAAK,OAAO,SAAS,IAAI;AACzB,WAAK,gBAAgB,QAAQ,iBAAiB;AAE9C,WAAK,SAAS,iBAAiB,SAAS,WAAW,IAAI;AACvD,WAAK,UAAU,iBAAiB,aAAa;AAE7C,UAAI,KAAK,iBAAiB,CAAC,KAAK,SAAS;AACvC,cAAM,MAAM,IAAI,eAAA;AAChB,YAAI,WAAW;AACf,aAAK,UAAU;AAAA,MACjB;AAAA,IACF;AAAA;AAAA;AAAA;AAAA;AAAA,IAMA,IAAI,QAAkB;AACpB,aAAO,KAAK,OAAO,WAAW,IAAI,CAAC,CAAC,IAAI,KAAK;AAAA,IAE/C;AAAA,IAEA,WAAiB;AACf;AAAA,IACF;AAAA,IAEA,UAAoB;AAClB,aAAO,KAAK;AAAA,IACd;AAAA,IAEA,aAAqB;AACnB,aAAO,KAAK,KAAK;AAAA,IACnB;AAAA,IAEA,IAAI,MAAM,OAAiB;AACzB,WAAK,SAAS;AAAA,IAChB;AAAA,IAEQ,gBAAgB,QAAwB;AAC9C,YAAM,YAAY,KAAK,gBAAgB,KAAK,aAAa,MAAM,GAAA,IAAO,kBAAkB,MAAM;AAC9F,aAAO,UAAU,QAAQ,IAAI;AAAA,IAC/B;AAAA,IAEQ,iBAAiB,QAAgB,OAAgC;AACvE,UAAI,OAAO,SAAS,UAAU;AAC5B,gBAAQ,IAAI,QAAO,KAAK;AAAA,MAC1B;AACA,YAAM,YAAY,KAAK,iBAAiB,MAAM,gBAAgB,KAAK,aAAa,MAAM,OAAO,kBAAkB,MAAM;AACrH,aAAO,UAAU,QAAQ,MAAM,KAAK;AAAA,IACtC;AAAA,IAEQ,cAAc,WAAmB,MAAqB;AAC5D,YAAM,YAAY,KAAK,aAAa,MAAM,GAAA;AAC1C,aAAO,UAAU,QAAQ,MAAM,GAAG,IAAI;AAAA,IACxC;AAAA,IAEA,OAAe;AACb,UAAI,KAAK,WAAA,MAAiB,GAAG;AAC3B,cAAM,IAAI,MAAM,yCAAyC;AAAA,MAC3D;AACA,aAAO,KAAK,QAAA,EAAU,CAAC;AAAA,IACzB;AAAA,IAEA,SAAiB;AACf,aAAO,IAAI,QAAO,KAAK,MAAM,EAAE,eAAe,MAAA,GAAS,EAAE,OAAO,KAAK,MAAA,CAAO;AAAA,IAC9E;AAAA,IAEA,UAAgB;AACd,WAAK,gBAAgB;AACrB,WAAK,OAAO;AACZ,WAAK,UAAU;AAAA,IACjB;AAAA,IAEA,QAAc;AACZ,WAAK,OAAO,MAAM,KAAK,YAAY,EAAE,KAAK,CAAC;AAAA,IAC7C;AAAA,IAEQ,iBAA0B;AAAA,IAClC,cAAoB;AAElB,UAAI,KAAK,mBAAmB,eAAgB;AAC5C,UAAI,KAAK,eAAgB;AACzB,WAAK,iBAAiB;AAEtB,WAAK,QAAQ,kBAAkB,KAAK,IAAI;AAAA,IAC1C;AAAA,IAEA,SAAS,MAA4B;AACnC,UAAI,CAAC,KAAK,eAAe;AAGvB;AAAA,MACF;AAEA,UAAI,CAAC,MAAM;AACT,YAAI,KAAK,WAAA,MAAiB,GAAG;AAC3B,gBAAM,IAAI,MAAM,6CAA6C;AAAA,QAC/D;AACA,eAAO,IAAI,QAAO,CAAC;AAAA,MACrB,OAAO;AACL,aAAK,SAAA;AAAA,MACP;AAEA,UAAI,KAAK,SAAS;AAChB,iBAAS,cAAc,IAAI,YAAY,OAAO,wBAAwB,EAAE,QAAQ,EAAE,QAAQ,KAAA,EAAK,CAAG,CAAC;AACnG,aAAK,QAAQ,SAAS,IAAI;AAC1B,iBAAS,cAAc,IAAI,YAAY,OAAO,uBAAuB,EAAE,QAAQ,EAAE,QAAQ,KAAA,EAAK,CAAG,CAAC;AAAA,MACpG;AAAA,IACF;AAAA;AAAA;AAAA,IAMA,IAAI,OAAgC;AAClC,aAAO,KAAK,iBAAiB,OAAO,KAAK;AAAA,IAC3C;AAAA,IAEA,IAAI,OAAgC;AAClC,aAAO,KAAK,iBAAiB,OAAO,KAAK;AAAA,IAC3C;AAAA,IAEA,IAAI,OAAgC;AAClC,aAAO,KAAK,iBAAiB,OAAO,KAAK;AAAA,IAC3C;AAAA,IAEA,IAAI,OAAgC;AAClC,aAAO,KAAK,iBAAiB,OAAO,KAAK;AAAA,IAC3C;AAAA,IAEA,IAAI,OAAgC;AAClC,UAAI,OAAO,SAAS,YAAY,QAAQ,MAAM,GAAG;AAC/C,eAAO,KAAK,cAAc,UAAU,KAAK;AAAA,MAC3C;AACA,aAAO,KAAK,iBAAiB,OAAO,KAAK;AAAA,IAC3C;AAAA,IAEA,KAAK,OAAgC;AACnC,aAAO,KAAK,iBAAiB,QAAQ,KAAK;AAAA,IAC5C;AAAA,IAEA,QAAQ,OAAgC;AACtC,aAAO,KAAK,iBAAiB,WAAW,KAAK;AAAA,IAC/C;AAAA,IAEA,QAAQ,OAAgC;AACtC,aAAO,KAAK,iBAAiB,WAAW,KAAK;AAAA,IAC/C;AAAA;AAAA,IAIA,MAAc;AACZ,aAAO,KAAK,gBAAgB,KAAK;AAAA,IACnC;AAAA,IAEA,OAAe;AACb,aAAO,KAAK,gBAAgB,MAAM;AAAA,IACpC;AAAA,IAEA,MAAc;AACZ,aAAO,KAAK,gBAAgB,KAAK;AAAA,IACnC;AAAA,IAEA,SAAiB;AACf,aAAO,KAAK,gBAAgB,QAAQ;AAAA,IACtC;AAAA,IAEA,MAAc;AACZ,aAAO,KAAK,gBAAgB,KAAK;AAAA,IACnC;AAAA,IAEA,OAAe;AACb,aAAO,KAAK,gBAAgB,MAAM;AAAA,IACpC;AAAA,IAEA,MAAc;AACZ,aAAO,KAAK,gBAAgB,KAAK;AAAA,IACnC;AAAA,IAEA,aAAqB;AACnB,aAAO,KAAK,gBAAgB,YAAY;AAAA,IAC1C;AAAA,IAEA,QAAQ,OAAyB;AAC/B,aAAO,KAAK,cAAc,WAAW,KAAK;AAAA,IAC5C;AAAA,IAEA,UAAU,KAAqB;AAC7B,aAAO,KAAK,cAAc,aAAa,GAAG;AAAA,IAC5C;AAAA;AAAA,IAIA,MAAc;AACZ,aAAO,KAAK,gBAAgB,KAAK;AAAA,IACnC;AAAA,IAEA,MAAc;AACZ,aAAO,KAAK,gBAAgB,KAAK;AAAA,IACnC;AAAA,IAEA,MAAc;AACZ,aAAO,KAAK,gBAAgB,KAAK;AAAA,IACnC;AAAA;AAAA,IAIA,MAAc;AACZ,aAAO,KAAK,gBAAgB,KAAK;AAAA,IACnC;AAAA,IAEA,OAAe;AACb,aAAO,KAAK,gBAAgB,MAAM;AAAA,IACpC;AAAA;AAAA,IAIA,UAAU,MAAc,MAAsB;AAC5C,aAAO,KAAK,cAAc,aAAa,MAAM,IAAI;AAAA,IACnD;AAAA,IAEA,OAAO,OAAuB;AAC5B,aAAO,KAAK,iBAAiB,UAAU,KAAK;AAAA,IAC9C;AAAA;AAAA,IAIA,GAAG,OAAgC;AACjC,aAAO,KAAK,iBAAiB,MAAM,KAAK;AAAA,IAC1C;AAAA,IAEA,GAAG,OAAgC;AACjC,aAAO,KAAK,iBAAiB,MAAM,KAAK;AAAA,IAC1C;AAAA,IAEA,GAAG,OAAgC;AACjC,aAAO,KAAK,iBAAiB,MAAM,KAAK;AAAA,IAC1C;AAAA,IAEA,GAAG,OAAgC;AACjC,aAAO,KAAK,iBAAiB,MAAM,KAAK;AAAA,IAC1C;AAAA,IAEA,GAAG,OAAgC;AACjC,aAAO,KAAK,iBAAiB,MAAM,KAAK;AAAA,IAC1C;AAAA,IAEA,GAAG,OAAgC;AACjC,aAAO,KAAK,iBAAiB,MAAM,KAAK;AAAA,IAC1C;AAAA,EACF;AAxQoB;AAAb,MAAM,SAAN;AC7CA,WAAS,iBAAiB,SAAmB,SAA6B;AAC/E,UAAM,gBAAgB,KAAK,IAAI,QAAQ,QAAQ,QAAQ,MAAM;AAC7D,UAAM,iBAAiB,CAAC,GAAG,MAAM,gBAAgB,QAAQ,MAAM,EAAE,KAAK,CAAC,GAAG,GAAG,OAAO;AACpF,UAAM,iBAAiB,CAAC,GAAG,MAAM,gBAAgB,QAAQ,MAAM,EAAE,KAAK,CAAC,GAAG,GAAG,OAAO;AAEpF,UAAM,eAAyB,CAAA;AAE/B,aAAS,IAAI,GAAG,IAAI,eAAe,KAAK;AACtC,UACE,eAAe,CAAC,MAAM,eAAe,CAAC,KACtC,eAAe,CAAC,MAAM,KACtB,eAAe,CAAC,MAAM,GACtB;AACA,cAAM,IAAI,MAAM,mBAAmB,OAAO,QAAQ,OAAO,EAAE;AAAA,MAC7D;AAEA,mBAAa,KAAK,KAAK,IAAI,eAAe,CAAC,GAAG,eAAe,CAAC,CAAC,CAAC;AAAA,IAClE;AAEA,WAAO;AAAA,EACT;AApBgB;AAsBT,WAAS,WAAW,OAAiB,iBAAqC;AAC/E,QAAI,MAAM,UAAU,gBAAgB,QAAQ;AAC1C,aAAO;AAAA,IACT;AAEA,WAAO,CAAC,GAAG,MAAM,gBAAgB,SAAS,MAAM,MAAM,EAAE,KAAK,CAAC,GAAG,GAAG,KAAK;AAAA,EAC3E;AANgB;AAQT,WAAS,oBACd,gBACA,WACAA,QACQ;AACR,QAAI,iBAAiB;AACrB,QAAI,aAAa;AACjB,QAAI,aAAaA;AAEjB,aAAS,IAAI,eAAe,SAAS,GAAG,KAAK,GAAG,KAAK;AACnD,UAAI,eAAe,CAAC,IAAI,GAAG;AACzB,cAAM,YAAY,aAAa,UAAU,CAAC;AAC1C,yBAAiB,iBAAiB,YAAY;AAAA,MAChD;AACA,oBAAc,eAAe,CAAC;AAC9B,mBAAa,KAAK,MAAM,aAAa,UAAU,CAAC,CAAC;AAAA,IACnD;AACA,WAAO;AAAA,EACT;AAlBgB;AAoBT,WAAS,2BACd,gBACA,WACAA,QACQ;AACR,QAAI,iBAAiB;AACrB,QAAI,aAAa;AACjB,QAAI,aAAaA;AAEjB,aAAS,IAAI,KAAK,UAAU,eAAe,GAAG,KAAK,GAAG,KAAK;AACzD,UAAI,eAAe,CAAC,IAAI,GAAG;AACzB,cAAM,YAAY,aAAa,UAAU,CAAC;AAC1C,yBAAiB,iBAAiB,YAAY;AAAA,MAChD;AACA,mBAAa,aAAa,eAAe,CAAC;AAC1C,mBAAa,KAAK,MAAM,aAAa,UAAU,CAAC,CAAC;AAAA,IACnD;AACA,WAAO;AAAA,EACT;AAlBgB;AAoBT,WAAS,0CACd,gBACA,MACA,MACA,kBACQ;AACR,QAAI,iBAAiB;AACrB,QAAI,aAAa;AACjB,QAAI,aAAa;AAEjB,QAAI,aAAa;AACjB,QAAI,aAAa;AAEjB,aAAS,IAAI,KAAK,UAAU,eAAe,GAAG,KAAK,GAAG,KAAK;AACzD,YAAM,YAAY,aAAa,eAAe,CAAC;AAC/C,UAAI,KAAK,MAAM;AACb,qBAAa;AAAA,MACf;AACA,UAAI,KAAK,MAAM;AACb,qBAAa;AAAA,MACf;AACA,mBAAa,KAAK,MAAM,aAAa,eAAe,CAAC,CAAC;AAAA,IACxD;AAEA,iBAAa;AAEb,aAAS,IAAI,KAAK,UAAU,eAAe,GAAG,KAAK,GAAG,KAAK;AACzD,YAAM,YAAY,aAAa,eAAe,CAAC;AAC/C,UAAI,KAAK,MAAM;AACb,yBAAiB,iBAAiB,aAAa;AAAA,MACjD,WAAW,KAAK,MAAM;AACpB,yBAAiB,iBAAiB,aAAa;AAAA,MACjD,OAAO;AACL,yBAAiB,iBAAiB,YAAY;AAAA,MAChD;AACA,mBAAa,aAAa,eAAe,CAAC;AAC1C,mBAAa,KAAK,MAAM,aAAa,eAAe,CAAC,CAAC;AAAA,IACxD;AAEA,WAAO;AAAA,EAGT;AA1CgB;ACpEhB,WAASC,oBAAkB,QAAgB;AACzC,WAAO,IAAI,SAA8B;AACvC,YAAM,YAAY,KAAK,aAAa,MAAM,GAAA;AAC1C,aAAO,UAAU,QAAQ,GAAG,IAAI;AAAA,IAClC;AAAA,EACF;AALSA;AAOT,WAASC,0BAAwB,QAAgB;AAC/C,WAAO,CAAC,MAAuB;AAC7B,UAAI,OAAO,KAAK,UAAU;AACxB,YAAI,IAAI,OAAO,CAAC;AAAA,MAClB;AAEA,YAAM,YAAY,KAAK,aAAa,MAAM,GAAA;AAC1C,aAAO,UAAU,QAAQ,CAAC;AAAA,IAC5B;AAAA,EACF;AATSA;AAWT,WAASC,2BAAyB,QAAgB;AAChD,WAAO,CAAC,GAAoB,MAAuB;AACjD,UAAI,OAAO,KAAK,UAAU;AACxB,YAAI,IAAI,OAAO,CAAC;AAAA,MAClB;AAEA,UAAI,OAAO,KAAK,UAAU;AACxB,YAAI,IAAI,OAAO,CAAC;AAAA,MAClB;AAEA,YAAM,YAAY,KAAK,aAAa,MAAM,GAAA;AAC1C,aAAO,UAAU,QAAQ,GAAG,CAAC;AAAA,IAC/B;AAAA,EACF;AAbSA;AAiBF,QAAM,iBAAiBA,2BAAyB,gBAAgB;AAChE,QAAM,kBAAkBA,2BAAyB,iBAAiB;AAIlE,QAAM,MAAMA,2BAAyB,KAAK;AAC1C,QAAM,MAAMA,2BAAyB,KAAK;AAC1C,QAAM,MAAMA,2BAAyB,KAAK;AAC1C,QAAM,MAAMA,2BAAyB,KAAK;AAC1C,QAAM,MAAMA,2BAAyB,KAAK;AAC1C,QAAM,OAAOA,2BAAyB,MAAM;AAC5C,QAAM,UAAUA,2BAAyB,SAAS;AAClD,QAAM,UAAUA,2BAAyB,SAAS;AAIlD,QAAM,MAAMD,0BAAwB,KAAK;AACzC,QAAM,OAAOA,0BAAwB,MAAM;AAC3C,QAAM,MAAMA,0BAAwB,KAAK;AACzC,QAAM,SAASA,0BAAwB,QAAQ;AAC/C,QAAM,MAAMA,0BAAwB,KAAK;AACzC,QAAM,OAAOA,0BAAwB,MAAM;AAC3C,QAAM,MAAMA,0BAAwB,KAAK;AACzC,QAAM,aAAaA,0BAAwB,YAAY;AACvD,QAAM,UAAUD,oBAAkB,SAAS;AAC3C,QAAM,YAAYA,oBAAkB,WAAW;AAI/C,QAAM,MAAMC,0BAAwB,KAAK;AACzC,QAAM,MAAMA,0BAAwB,KAAK;AACzC,QAAM,MAAMA,0BAAwB,KAAK;AAIzC,QAAM,MAAMA,0BAAwB,KAAK;AACzC,QAAM,OAAOA,0BAAwB,MAAM;AAI3C,QAAM,YAAYD,oBAAkB,WAAW;AAC/C,QAAM,SAASE,2BAAyB,QAAQ;AAIhD,QAAM,KAAKA,2BAAyB,IAAI;AACxC,QAAM,KAAKA,2BAAyB,IAAI;AACxC,QAAM,KAAKA,2BAAyB,IAAI;AACxC,QAAM,KAAKA,2BAAyB,IAAI;AACxC,QAAM,KAAKA,2BAAyB,IAAI;AACxC,QAAM,KAAKA,2BAAyB,IAAI;ACzE/C,QAAM,yBAAyB,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACjI,UAAM,MAAM,MAAM,WAAW;AAC7B,aAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAI,CAAC,IAAI;AAAA,IACX;AACA,WAAO;AAAA,EACT,GAR+B;AAU/B,WAAS,uBAAuB,GAAW,GAAW,YAA8B,MAAc;AAChG,UAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,UAAM,SAAS;AACf,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,MACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,IAAgB;AAAA,EAEnD;AAbS;AAeF,QAAM,kBAAN,MAAM,wBAAuB,gBAAgB;AAAA,IACxC,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,uBAAuB,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IACtF;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,IAI1B;AAAA,EACF;AAhBoD;AAA7C,MAAM,iBAAN;AAiBP,oBAAkB,kBAAkB,cAAc;AAElD,QAAM,0BAA0B,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AAClI,UAAM,MAAM,MAAM,WAAW;AAC7B,aAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAI,CAAC,IAAI;AAAA,IACX;AACA,WAAO;AAAA,EACT,GARgC;AAUhC,WAAS,wBAAwB,GAAW,GAAW,YAA8B,MAAc;AACjG,UAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,UAAM,SAAS;AACf,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,MACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,IAAgB;AAAA,EAEnD;AAbS;AAeF,QAAM,mBAAN,MAAM,yBAAwB,gBAAgB;AAAA,IACzC,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,wBAAwB,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IACvF;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,IAI1B;AAAA,EACF;AAhBqD;AAA9C,MAAM,kBAAN;AAiBP,oBAAkB,mBAAmB,eAAe;AAIpD,QAAM,cAAc,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACtH,UAAM,MAAM,MAAM,WAAW;AAC7B,aAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAI,CAAC,IAAI,EAAE,OAAO,IAAI,EAAE,OAAO;AAAA,IACjC;AACA,WAAO;AAAA,EACT,GARoB;AAUpB,WAAS,YAAY,GAAW,GAAW,YAA8B,MAAc;AACrF,UAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,UAAM,SAAS;AACf,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,MACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,IAAgB;AAAA,EAEnD;AAbS;AAeF,QAAM,OAAN,MAAM,aAAY,gBAAgB;AAAA,IAC7B,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,YAAY,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC3E;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAGxB,UAAI,SAAS,EAAE;AACf,UAAI,SAAS,EAAE;AAAA,IACjB;AAAA,EACF;AAjByC;AAAlC,MAAM,MAAN;AAkBP,oBAAkB,OAAO,GAAG;AAE5B,QAAM,cAAc,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACtH,UAAM,MAAM,MAAM,WAAW;AAC7B,aAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAI,CAAC,IAAI,EAAE,OAAO,IAAI,EAAE,OAAO;AAAA,IACjC;AACA,WAAO;AAAA,EACT,GARoB;AAUpB,WAAS,YAAY,GAAW,GAAW,YAA8B,MAAc;AACrF,UAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,UAAM,SAAS;AACf,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,MACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,IAAgB;AAAA,EAEnD;AAbS;AAeF,QAAM,OAAN,MAAM,aAAY,gBAAgB;AAAA,IAC7B,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,YAAY,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC3E;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAGxB,UAAI,SAAS,EAAE;AACf,UAAI,SAAS,GAAG,IAAI,IAAI,OAAO,EAAE,CAAC,CAAC;AAAA,IACrC;AAAA,EACF;AAjByC;AAAlC,MAAM,MAAN;AAkBP,oBAAkB,OAAO,GAAG;AAE5B,QAAM,cAAc,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACtH,UAAM,MAAM,MAAM,WAAW;AAC7B,aAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAI,CAAC,IAAI,EAAE,OAAO,IAAI,EAAE,OAAO;AAAA,IACjC;AACA,WAAO;AAAA,EACT,GARoB;AAUpB,WAAS,YAAY,GAAW,GAAW,YAA8B,MAAc;AACrF,UAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,UAAM,SAAS;AACf,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,MACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,IAAgB;AAAA,EAEnD;AAbS;AAeF,QAAM,OAAN,MAAM,aAAY,gBAAgB;AAAA,IAC7B,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,YAAY,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC3E;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAGxB,UAAI,SAAS,GAAG,IAAI,CAAC,CAAC;AACtB,UAAI,SAAS,GAAG,IAAI,CAAC,CAAC;AAAA,IACxB;AAAA,EACF;AAjByC;AAAlC,MAAM,MAAN;AAkBP,oBAAkB,OAAO,GAAG;AAE5B,QAAM,cAAc,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACtH,UAAM,MAAM,MAAM,WAAW;AAC7B,aAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAI,CAAC,IAAI,EAAE,OAAO,IAAI,EAAE,OAAO;AAAA,IACjC;AACA,WAAO;AAAA,EACT,GARoB;AAUpB,WAAS,YAAY,GAAW,GAAW,YAA8B,MAAc;AACrF,UAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,UAAM,SAAS;AACf,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,MACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,IAAgB;AAAA,EAEnD;AAbS;AAeF,QAAM,OAAN,MAAM,aAAY,gBAAgB;AAAA,IAC7B,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,YAAY,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC3E;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAGxB,UAAI,SAAS,GAAG,IAAI,CAAC,CAAC;AACtB,UAAI,SAAS,GAAG,IAAI,CAAC,EAAE,IAAI,IAAI,OAAO,EAAE,CAAC,EAAE,IAAI,CAAC,EAAE,IAAI,CAAC,CAAC;AAAA,IAC1D;AAAA,EACF;AAjByC;AAAlC,MAAM,MAAN;AAkBP,oBAAkB,OAAO,GAAG;AAE5B,QAAM,cAAc,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACtH,UAAM,MAAM,MAAM,WAAW;AAC7B,aAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAI,CAAC,IAAI,KAAK,IAAI,EAAE,OAAO,GAAG,EAAE,OAAO,CAAC;AAAA,IAC1C;AACA,WAAO;AAAA,EACT,GARoB;AAUpB,WAAS,YAAY,GAAW,GAAW,YAA8B,MAAc;AACrF,UAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,UAAM,SAAS;AACf,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,MACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,IAAgB;AAAA,EAEnD;AAbS;AAeF,QAAM,OAAN,MAAM,aAAY,gBAAgB;AAAA,IAC7B,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,YAAY,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC3E;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAGxB,UAAI,SAAS,GAAG,IAAI,CAAC,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,IAAI,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;AACvD,UAAI,SAAS,GAAG,IAAI,EAAE,IAAI,CAAC,CAAC,EAAE,IAAI,EAAE,IAAA,CAAK,CAAC;AAAA,IAC5C;AAAA,EACF;AAjByC;AAAlC,MAAM,MAAN;AAkBP,oBAAkB,OAAO,GAAG;AAE5B,QAAM,eAAe,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACvH,UAAM,MAAM,MAAM,WAAW;AAC7B,aAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAI,CAAC,IAAI,EAAE,OAAO,IAAI,EAAE,OAAO;AAAA,IACjC;AACA,WAAO;AAAA,EACT,GARqB;AAUrB,WAAS,aAAa,GAAW,GAAW,YAA8B,MAAc;AACtF,UAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,UAAM,SAAS;AACf,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,MACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,IAAgB;AAAA,EAEnD;AAbS;AAeF,QAAM,QAAN,MAAM,cAAa,gBAAgB;AAAA,IAC9B,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,aAAa,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC5E;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAGxB,UAAI,SAAS,EAAE;AAAA,IACjB;AAAA,EACF;AAhB0C;AAAnC,MAAM,OAAN;AAiBP,oBAAkB,QAAQ,IAAI;AAE9B,QAAM,kBAAkB,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AAC1H,UAAM,MAAM,MAAM,WAAW;AAC7B,aAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAI,CAAC,IAAI,KAAK,IAAI,EAAE,OAAO,GAAG,EAAE,OAAO,CAAC;AAAA,IAC1C;AACA,WAAO;AAAA,EACT,GARwB;AAUxB,WAAS,gBAAgB,GAAW,GAAW,YAA8B,MAAc;AACzF,UAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,UAAM,SAAS;AACf,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,MACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,IAAgB;AAAA,EAEnD;AAbS;AAeF,QAAM,WAAN,MAAM,iBAAgB,gBAAgB;AAAA,IACjC,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,gBAAgB,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC/E;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAGxB,UAAI,SAAS,GAAG,IAAI,EAAE,GAAG,CAAC,CAAC,CAAC;AAC5B,UAAI,SAAS,GAAG,IAAI,EAAE,GAAG,CAAC,CAAC,CAAC;AAAA,IAC9B;AAAA,EACF;AAjB6C;AAAtC,MAAM,UAAN;AAkBP,oBAAkB,WAAW,OAAO;AAEpC,QAAM,kBAAkB,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AAC1H,UAAM,MAAM,MAAM,WAAW;AAC7B,aAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAI,CAAC,IAAI,KAAK,IAAI,EAAE,OAAO,GAAG,EAAE,OAAO,CAAC;AAAA,IAC1C;AACA,WAAO;AAAA,EACT,GARwB;AAUxB,WAAS,gBAAgB,GAAW,GAAW,YAA8B,MAAc;AACzF,UAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,UAAM,SAAS;AACf,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,MACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,IAAgB;AAAA,EAEnD;AAbS;AAeF,QAAM,WAAN,MAAM,iBAAgB,gBAAgB;AAAA,IACjC,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,gBAAgB,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC/E;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAGxB,UAAI,SAAS,GAAG,IAAI,EAAE,GAAG,CAAC,CAAC,CAAC;AAC5B,UAAI,SAAS,GAAG,IAAI,EAAE,GAAG,CAAC,CAAC,CAAC;AAAA,IAC9B;AAAA,EACF;AAjB6C;AAAtC,MAAM,UAAN;AAkBP,oBAAkB,WAAW,OAAO;AAGpC,WAAS,eAAe,GAAW,GAAW,YAA8B,MAAc;AACxF,UAAM,OAAO,IAAI,MAAM,EAAE,YAAY;AACrC,aAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACpC,WAAK,CAAC,IAAI,KAAK,IAAI,EAAE,KAAK,CAAC,GAAG,CAAC;AAAA,IACjC;AACA,WAAO,IAAI;AAAA,MACT;AAAA,MACA,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,IAAM;AAAA,EAE3C;AAVS;AAWF,QAAM,UAAN,MAAM,gBAAe,UAAU;AAAA,IAC5B;AAAA,IACE,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AACvB,aAAK,IAAI;AAAA,MACX;AAEA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,eAAe,GAAG,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC3D;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,IAAI,KAAK;AACf,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAI,SAAS,GAAG,IAAI,CAAC,EAAE,IAAI,EAAE,IAAI,IAAI,CAAC,CAAC,CAAC;AAAA,IAC1C;AAAA,EACF;AAnBsC;AAA/B,MAAM,SAAN;AAoBP,oBAAkB,UAAU,MAAM;AAMlC,QAAM,cAAc,gCAAU,GAAa,QAAgB;AACzD,UAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAI,CAAC,IAAI,KAAK,IAAI,EAAE,CAAC,CAAC;AAAA,IACxB;AACA,WAAO;AAAA,EACT,GANoB;AAQpB,WAAS,YAAY,GAAW,YAA8B,MAAc;AAC1E,UAAM,SAAS;AACf,UAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,MAAM;AAAA,MACrB,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,IAAM;AAAA,EAE3C;AATS;AAWF,QAAM,OAAN,MAAM,aAAY,eAAe;AAAA,IAC5B,SAAS,GAAmB;AACpC,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,YAAY,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,IACrD;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAI,SAAS,IAAI,OAAO,CAAC,EAAE,IAAI,CAAC,CAAC;AAAA,IACnC;AAAA,EACF;AAfwC;AAAjC,MAAM,MAAN;AAgBP,oBAAkB,OAAO,GAAG;AAI5B,QAAM,eAAe,gCAAU,GAAa,QAAgB;AAC1D,UAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAI,CAAC,IAAI,KAAK,KAAK,EAAE,CAAC,CAAC;AAAA,IACzB;AACA,WAAO;AAAA,EACT,GANqB;AAQrB,WAAS,aAAa,GAAW,YAA8B,MAAc;AAC3E,UAAM,SAAS;AACf,UAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,MAAM;AAAA,MACrB,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,IAAM;AAAA,EAE3C;AATS;AAWF,QAAM,QAAN,MAAM,cAAa,eAAe;AAAA,IAC7B,SAAS,GAAmB;AACpC,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,aAAa,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,IACtD;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAI,SAAS,IAAI,OAAO,CAAC,EAAE,IAAI,EAAE,KAAA,CAAM,EAAE,IAAI,CAAC,CAAC;AAAA,IACjD;AAAA,EACF;AAfyC;AAAlC,MAAM,OAAN;AAgBP,oBAAkB,QAAQ,IAAI;AAI9B,QAAM,cAAc,gCAAU,GAAa,QAAgB;AACzD,UAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAI,CAAC,IAAI,KAAK,IAAI,EAAE,CAAC,CAAC;AAAA,IACxB;AACA,WAAO;AAAA,EACT,GANoB;AAQpB,WAAS,YAAY,GAAW,YAA8B,MAAc;AAC1E,UAAM,SAAS;AACf,UAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,MAAM;AAAA,MACrB,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,IAAM;AAAA,EAE3C;AATS;AAWF,QAAM,OAAN,MAAM,aAAY,eAAe;AAAA,IAC5B,SAAS,GAAmB;AACpC,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,YAAY,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,IACrD;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAI,SAAS,GAAG,IAAI,EAAE,IAAA,CAAK,CAAC;AAAA,IAC9B;AAAA,EACF;AAfwC;AAAjC,MAAM,MAAN;AAgBP,oBAAkB,OAAO,GAAG;AAI5B,QAAM,iBAAiB,gCAAU,GAAa,QAAgB;AAC5D,UAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAI,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC;AAAA,IACrB;AACA,WAAO;AAAA,EACT,GANuB;AAQvB,WAAS,eAAe,GAAW,YAA8B,MAAc;AAC7E,UAAM,SAAS;AACf,UAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,MAAM;AAAA,MACrB,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,IAAM;AAAA,EAE3C;AATS;AAWF,QAAM,UAAN,MAAM,gBAAe,eAAe;AAAA,IAC/B,SAAS,GAAmB;AACpC,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,eAAe,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,IACxD;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAI,SAAS,GAAG,IAAI,CAAC,EAAE,IAAI,IAAI,OAAO,CAAC,CAAC,CAAC;AAAA,IAC3C;AAAA,EACF;AAf2C;AAApC,MAAM,SAAN;AAgBP,oBAAkB,UAAU,MAAM;AAIlC,QAAM,cAAc,gCAAU,GAAa,QAAgB;AACzD,UAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAI,CAAC,IAAI,KAAK,IAAI,EAAE,CAAC,CAAC;AAAA,IACxB;AACA,WAAO;AAAA,EACT,GANoB;AAQpB,WAAS,YAAY,GAAW,YAA8B,MAAc;AAC1E,UAAM,SAAS;AACf,UAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,MAAM;AAAA,MACrB,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,IAAM;AAAA,EAE3C;AATS;AAWF,QAAM,OAAN,MAAM,aAAY,eAAe;AAAA,IAC5B,SAAS,GAAmB;AACpC,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,YAAY,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,IACrD;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAI,SAAS,GAAG,IAAIC,KAAgB,CAAC,CAAC,CAAC;AAAA,IACzC;AAAA,EACF;AAfwC;AAAjC,MAAM,MAAN;AAgBP,oBAAkB,OAAO,GAAG;AAI5B,QAAM,eAAe,gCAAU,GAAa,QAAgB;AAC1D,UAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAI,CAAC,IAAI,KAAK,KAAK,EAAE,CAAC,CAAC;AAAA,IACzB;AACA,WAAO;AAAA,EACT,GANqB;AAQrB,WAAS,aAAa,GAAW,YAA8B,MAAc;AAC3E,UAAM,SAAS;AACf,UAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,MAAM;AAAA,MACrB,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,IAAM;AAAA,EAE3C;AATS;AAWF,QAAM,QAAN,MAAM,cAAa,eAAe;AAAA,IAC7B,SAAS,GAAmB;AACpC,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,aAAa,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,IACtD;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAAA,IAIrB;AAAA,EACF;AAfyC;AAAlC,MAAM,OAAN;AAgBP,oBAAkB,QAAQ,IAAI;AAI9B,QAAM,cAAc,gCAAU,GAAa,QAAgB;AACzD,UAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAI,CAAC,IAAI,CAAC,EAAE,CAAC;AAAA,IACf;AACA,WAAO;AAAA,EACT,GANoB;AAQpB,WAAS,YAAY,GAAW,YAA8B,MAAc;AAC1E,UAAM,SAAS;AACf,UAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,MAAM;AAAA,MACrB,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,IAAM;AAAA,EAE3C;AATS;AAWF,QAAM,OAAN,MAAM,aAAY,eAAe;AAAA,IAC5B,SAAS,GAAmB;AACpC,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,YAAY,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,IACrD;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAI,SAAS,GAAG,IAAI,IAAI,OAAO,EAAE,CAAC,CAAC;AAAA,IACrC;AAAA,EACF;AAfwC;AAAjC,MAAM,MAAN;AAgBP,oBAAkB,OAAO,GAAG;AAI5B,QAAM,qBAAqB,gCAAU,GAAa,QAAgB;AAChE,UAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAI,CAAC,IAAI,IAAI,EAAE,CAAC;AAAA,IAClB;AACA,WAAO;AAAA,EACT,GAN2B;AAQ3B,WAAS,mBAAmB,GAAW,YAA8B,MAAc;AACjF,UAAM,SAAS;AACf,UAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,MAAM;AAAA,MACrB,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,IAAM;AAAA,EAE3C;AATS;AAWF,QAAM,cAAN,MAAM,oBAAmB,eAAe;AAAA,IACnC,SAAS,GAAmB;AACpC,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,mBAAmB,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC5D;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAI,SAAS,GAAG,IAAI,EAAE,IAAI,EAAE,CAAC,CAAC;AAAA,IAChC;AAAA,EACF;AAf+C;AAAxC,MAAM,aAAN;AAgBP,oBAAkB,cAAc,UAAU;AAEnC,QAAM,WAAN,MAAM,iBAAgB,UAAU;AAAA,IAC3B,SAAS,GAAW,OAAiB;AAC7C,YAAM,kBAAkB,EAAE,WAAA;AAC1B,YAAM,gBAAgB,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAE7D,UAAI,oBAAoB,eAAe;AACrC,cAAM,IAAI,MAAM,qBAAqB,EAAE,QAAQ,UAAU,KAAK;AAAA,MAChE;AAEA,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,UAAI,EAAE,SAAS;AACb,aAAK,eAAe,KAAK,EAAE,OAAO;AAAA,MACpC,WAAW,EAAE,eAAe;AAC1B,cAAM,MAAM,IAAI,eAAA;AAChB,YAAI,WAAW;AACf,aAAK,eAAe,KAAK,GAAG;AAAA,MAC9B,OAAO;AACL,aAAK,eAAe,KAAK,MAAM;AAAA,MACjC;AAEA,aAAO,IAAI;AAAA,QACT,EAAE;AAAA,QACF,EAAE,eAAe,EAAE,cAAA;AAAA,QACnB,EAAE,WAAW,EAAE,gBAAgB,OAAO,MAAM,MAAA;AAAA,MAAM;AAAA,IAEtD;AAAA,IACU,UAAU,IAAY;AAC9B,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAI,SAAS,GAAG,QAAQ,EAAE,KAAK,CAAC;AAAA,IAClC;AAAA,EACF;AAnCuC;AAAhC,MAAM,UAAN;AAoCP,oBAAkB,WAAW,OAAO;AAE7B,QAAM,aAAN,MAAM,mBAAkB,UAAU;AAAA,IAC7B,SAAS,GAAW,KAAa;AACzC,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,UAAI,EAAE,SAAS;AACb,aAAK,eAAe,KAAK,EAAE,OAAO;AAAA,MACpC,WAAW,EAAE,eAAe;AAC1B,cAAM,MAAM,IAAI,eAAA;AAChB,YAAI,WAAW;AACf,aAAK,eAAe,KAAK,GAAG;AAAA,MAC9B,OAAO;AACL,aAAK,eAAe,KAAK,MAAM;AAAA,MACjC;AAEA,UAAI,MAAM,GAAG;AACX,eAAO,EAAE,MAAM,SAAS;AAAA,MAC1B;AAEA,YAAM,QAAQ,CAAC,GAAG,EAAE,KAAK;AACzB,YAAM,OAAO,KAAK,GAAG,CAAC;AAEtB,aAAO,IAAI;AAAA,QACT,EAAE;AAAA,QACF,EAAE,eAAe,EAAE,cAAA;AAAA,QACnB,EAAE,WAAW,EAAE,gBAAgB,OAAO,MAAM,MAAA;AAAA,MAAM;AAAA,IAEtD;AAAA,IACU,UAAU,IAAY;AAC9B,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAI,SAAS,GAAG,QAAQ,EAAE,KAAK,CAAC;AAAA,IAClC;AAAA,EACF;AAnCyC;AAAlC,MAAM,YAAN;AAoCP,oBAAkB,aAAa,SAAS;AAMxC,QAAM,cAAc,gCAAU,GAAa,QAAgB;AACzD,UAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAI,CAAC,IAAI,KAAK,IAAI,EAAE,CAAC,CAAC;AAAA,IACxB;AACA,WAAO;AAAA,EACT,GANoB;AAQpB,WAAS,YAAY,GAAW,YAA8B,MAAc;AAC1E,UAAM,SAAS;AACf,UAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,MAAM;AAAA,MACrB,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,IAAM;AAAA,EAE3C;AATS;AAWF,QAAM,OAAN,MAAM,aAAY,eAAe;AAAA,IAC5B,SAAS,GAAmB;AACpC,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,YAAY,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,IACrD;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAI,SAAS,GAAG,IAAI,EAAE,IAAA,CAAK,CAAC;AAAA,IAC9B;AAAA,EACF;AAfwC;AAAjC,MAAM,MAAN;AAgBP,oBAAkB,OAAO,GAAG;AAI5B,QAAM,cAAc,gCAAU,GAAa,QAAgB;AACzD,UAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAI,CAAC,IAAI,KAAK,IAAI,EAAE,CAAC,CAAC;AAAA,IACxB;AACA,WAAO;AAAA,EACT,GANoB;AAQpB,WAAS,YAAY,GAAW,YAA8B,MAAc;AAC1E,UAAM,SAAS;AACf,UAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,MAAM;AAAA,MACrB,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,IAAM;AAAA,EAE3C;AATS;AAWF,QAAM,OAAN,MAAM,aAAY,eAAe;AAAA,IAC5B,SAAS,GAAmB;AACpC,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,YAAY,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,IACrD;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAI,SAAS,GAAG,IAAI,EAAE,MAAM,IAAA,CAAK,CAAC;AAAA,IACpC;AAAA,EACF;AAfwC;AAAjC,MAAM,MAAN;AAgBP,oBAAkB,OAAO,GAAG;AAI5B,QAAM,cAAc,gCAAU,GAAa,QAAgB;AACzD,UAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAI,CAAC,IAAI,KAAK,IAAI,EAAE,CAAC,CAAC;AAAA,IACxB;AACA,WAAO;AAAA,EACT,GANoB;AAQpB,WAAS,YAAY,GAAW,YAA8B,MAAc;AAC1E,UAAM,SAAS;AACf,UAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,MAAM;AAAA,MACrB,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,IAAM;AAAA,EAE3C;AATS;AAWF,QAAM,OAAN,MAAM,aAAY,eAAe;AAAA,IAC5B,SAAS,GAAmB;AACpC,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,YAAY,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,IACrD;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAI,SAAS,GAAG,IAAI,EAAE,MAAM,IAAI,EAAE,CAAC,CAAC;AAAA,IACtC;AAAA,EACF;AAfwC;AAAjC,MAAM,MAAN;AAgBP,oBAAkB,OAAO,GAAG;AAI5B,WAAS,YAAY,GAAW,YAA8B,MAAc;AAC1E,WAAO,IAAI;AAAA,MACT,EAAE,UAAU,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAAA,MAC7C,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,UAAA;AAAA,IAAqB;AAAA,EAE3B;AANS;AASF,QAAM,OAAN,MAAM,aAAY,eAAe;AAAA,IAC5B,SAAS,GAAmB;AACpC,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,YAAY,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,IACrD;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,YAAM,SAAS,IAAI,OAAO,MAAM,EAAE,WAAA,CAAY,EAAE,KAAK,GAAG,KAAA,CAAM,CAAC;AAC/D,UAAI,SAAS,MAAM;AAAA,IACrB;AAAA,EACF;AAhBwC;AAAjC,MAAM,MAAN;AAiBP,oBAAkB,OAAO,GAAG;AAE5B,WAAS,aAAa,GAAW,YAA8B,MAAc;AAC3E,WAAO,IAAI;AAAA,MACT,EAAE,QAAA,EAAU,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC,IAAI,EAAE,WAAA;AAAA,MACnD,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,UAAA;AAAA,IAAqB;AAAA,EAE3B;AANS;AASF,QAAM,QAAN,MAAM,cAAa,eAAe;AAAA,IAC7B,SAAS,GAAmB;AACpC,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,aAAa,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,IACtD;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,YAAM,SAAS,IAAI,OAAO,MAAM,EAAE,WAAA,CAAY,EAAE,KAAK,GAAG,KAAA,IAAS,EAAE,WAAA,CAAY,CAAC;AAChF,UAAI,SAAS,MAAM;AAAA,IACrB;AAAA,EACF;AAhByC;AAAlC,MAAM,OAAN;AAiBP,oBAAkB,QAAQ,IAAI;AAI9B,WAAS,kBACP,GACA,MACA,MACA,YAA8B,MACtB;AACR,UAAM,eAAe,CAAC,GAAG,EAAE,KAAK;AAChC,KAAC,aAAa,IAAI,GAAG,aAAa,IAAI,CAAC,IAAI,CAAC,aAAa,IAAI,GAAG,aAAa,IAAI,CAAC;AAClF,UAAM,OAAO,EAAE,WAAA;AACf,UAAM,OAAO,IAAI,MAAM,IAAI;AAE3B,UAAM,YAAY,IAAI,MAAM,EAAE,MAAM,MAAM;AAC1C,UAAM,cAAc,IAAI,MAAM,aAAa,MAAM;AACjD,aAAS,IAAI,EAAE,MAAM,SAAS,GAAG,IAAI,GAAG,KAAK,GAAG,KAAK;AACnD,gBAAU,CAAC,IAAI;AACf,WAAK,EAAE,MAAM,CAAC;AAAA,IAChB;AACA,aAAS,IAAI,aAAa,SAAS,GAAG,IAAI,GAAG,KAAK,GAAG,KAAK;AACxD,kBAAY,CAAC,IAAI;AACjB,WAAK,aAAa,CAAC;AAAA,IACrB;AAEA,aAAQ,IAAE,GAAG,IAAE,MAAM,KAAK;AACxB,UAAI,MAAM;AACV,UAAI,YAAY;AAChB,eAAS,IAAI,GAAG,IAAI,aAAa,QAAQ,KAAK;AAC5C,cAAM,SAAS,YAAY,CAAC;AAC5B,cAAM,QAAQ,KAAK,MAAM,MAAM,MAAM;AACrC,eAAO;AAEP,YAAI,UAAU;AACd,YAAI,MAAM,KAAM,WAAU;AAAA,iBACjB,MAAM,KAAM,WAAU;AAE/B,qBAAa,QAAQ,UAAU,OAAO;AAAA,MACxC;AACA,WAAK,CAAC,IAAI,EAAE,KAAK,SAAS;AAAA,IAC5B;AAEA,WAAO,IAAI;AAAA,MACT;AAAA,MACA,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAsB,OAAO,aAAA;AAAA,IAAa;AAAA,EAEhD;AA5CS;AA6CF,QAAM,aAAN,MAAM,mBAAkB,UAAU;AAAA,IAC/B;AAAA,IACA;AAAA,IACE,SAAS,GAAW,MAAc,MAAsB;AAChE,UAAI,EAAE,eAAe;AACjB,aAAK,gBAAgB,CAAC,CAAC;AACvB,aAAK,OAAO;AACZ,aAAK,OAAO;AAAA,MAChB;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,kBAAkB,GAAG,MAAM,MAAM,IAAI;AAAA,IAC9C;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,OAAO,KAAK;AAClB,YAAM,OAAO,KAAK;AAClB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAI,SAAS,GAAG,UAAU,MAAM,IAAI,CAAC;AAAA,IACvC;AAAA,EACF;AArByC;AAAlC,MAAM,YAAN;AAsBP,oBAAkB,aAAa,SAAS;AAExC,WAAS,eAAe,GAAW,GAAW,YAA8B,MAAc;AACxF,QAAI,EAAE,MAAM,UAAU,KAAK,EAAE,MAAM,UAAU,GAAG;AAC9C,aAAO,EAAE,IAAI,CAAC,EAAE,IAAA;AAAA,IAClB;AAEA,UAAM,OAAO,EAAE,MAAM,UAAU;AAC/B,UAAM,OAAO,EAAE,MAAM,UAAU;AAE/B,UAAM,UAAU,OAAO,CAAC,GAAG,EAAE,MAAM,CAAC,CAAC,IAAI,EAAE;AAC3C,UAAM,UAAU,OAAO,CAAC,EAAE,MAAM,CAAC,GAAG,CAAC,IAAI,EAAE;AAE3C,QAAI,QAAQ,QAAQ,SAAS,CAAC,KAAK,QAAQ,QAAQ,SAAS,CAAC,GAAG;AAC9D,YAAM,IAAI,MAAM,qBAAqB,EAAE,QAAQ,UAAU,EAAE,KAAK;AAAA,IAClE;AAEA,UAAM,kBAAkB,iBAAiB,QAAQ,MAAM,GAAG,EAAE,GAAG,QAAQ,MAAM,GAAG,EAAE,CAAC,EAAE,OAAO;AAAA,MAC1F,QAAQ,QAAQ,SAAS,CAAC;AAAA,MAC1B,QAAQ,QAAQ,SAAS,CAAC;AAAA,IAAA,CAC3B;AAED,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AACrE,UAAM,OAAO,IAAI,MAAM,WAAW,EAAE,KAAK,CAAC;AAE1C,UAAM,iBAAiB,WAAW,SAAS,eAAe;AAC1D,UAAM,iBAAiB,WAAW,SAAS,eAAe;AAE1D,UAAM,QAAQ,gBAAgB,gBAAgB,SAAS,CAAC;AACxD,UAAM,QAAQ,gBAAgB,gBAAgB,SAAS,CAAC;AACxD,UAAM,QAAQ,QAAQ,QAAQ,SAAS,CAAC;AAExC,aAAS,IAAI,GAAG,IAAI,aAAa,KAAK;AACpC,YAAM,SAAS,KAAK,QAAQ;AAC5B,YAAM,IAAI,KAAK,MAAM,SAAS,KAAK;AACnC,YAAM,IAAI,SAAS;AAEnB,UAAI,SAAS,oBAAoB,gBAAgB,iBAAiB,IAAI,CAAC;AACvE,UAAI,SAAS,oBAAoB,gBAAgB,iBAAiB,IAAI,IAAI,KAAK;AAE/E,UAAIC,OAAM;AACV,eAAQ,IAAE,GAAG,IAAI,OAAO,KAAK;AAC3B,QAAAA,QAAO,EAAE,KAAK,SAAS,CAAC,IAAI,EAAE,KAAK,SAAS,IAAI,KAAK;AAAA,MACvD;AACA,WAAK,CAAC,IAAIA;AAAA,IACZ;AAEA,QAAI,kCAAkC,CAAC,GAAG,eAAe;AAEzD,QAAI,MAAM;AACR,wCAAkC,gCAC/B,MAAM,GAAG,EAAE,EACX,OAAO,CAAC,gBAAgB,gBAAgB,SAAS,CAAC,CAAC,CAAC;AAAA,IACzD;AAEA,QAAI,MAAM;AACR,wCAAkC,gCAAgC,MAAM,GAAG,EAAE;AAAA,IAC/E;AAEA,WAAO,IAAI;AAAA,MACT;AAAA,MACA,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gCAAA;AAAA,IAAgC;AAAA,EAEnE;AA9DS;AAgEF,QAAM,UAAN,MAAM,gBAAe,gBAAgB;AAAA,IAChC,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,eAAe,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC9E;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,IAI1B;AAAA,EACF;AAhB4C;AAArC,MAAM,SAAN;AAiBP,oBAAkB,UAAU,MAAM;AAIlC,QAAM,aAAa,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACrH,UAAM,MAAM,MAAM,WAAW;AAC7B,aAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAI,CAAC,IAAK,EAAE,OAAO,IAAI,EAAE,OAAO,IAAK,IAAI;AAAA,IAC3C;AACA,WAAO;AAAA,EACT,GARmB;AAUnB,WAAS,WAAW,GAAW,GAAW,YAA8B,MAAc;AACpF,UAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,UAAM,SAAS;AACf,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,MACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,IAAgB;AAAA,EAEnD;AAbS;AAeF,QAAM,MAAN,MAAM,YAAW,gBAAgB;AAAA,IAC5B,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,WAAW,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC1E;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,IAI1B;AAAA,EACF;AAhBwC;AAAjC,MAAM,KAAN;AAiBP,oBAAkB,MAAM,EAAE;AAE1B,QAAM,aAAa,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACrH,UAAM,MAAM,MAAM,WAAW;AAC7B,aAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAI,CAAC,IAAK,EAAE,OAAO,IAAI,EAAE,OAAO,IAAK,IAAI;AAAA,IAC3C;AACA,WAAO;AAAA,EACT,GARmB;AAUnB,WAAS,WAAW,GAAW,GAAW,YAA8B,MAAc;AACpF,UAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,UAAM,SAAS;AACf,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,MACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,IAAgB;AAAA,EAEnD;AAbS;AAeF,QAAM,MAAN,MAAM,YAAW,gBAAgB;AAAA,IAC5B,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,WAAW,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC1E;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,IAI1B;AAAA,EACF;AAhBwC;AAAjC,MAAM,KAAN;AAiBP,oBAAkB,MAAM,EAAE;AAE1B,QAAM,aAAa,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACrH,UAAM,MAAM,MAAM,WAAW;AAC7B,aAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAI,CAAC,IAAK,EAAE,OAAO,KAAK,EAAE,OAAO,IAAK,IAAI;AAAA,IAC5C;AACA,WAAO;AAAA,EACT,GARmB;AAUnB,WAAS,WAAW,GAAW,GAAW,YAA8B,MAAc;AACpF,UAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,UAAM,SAAS;AACf,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,MACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,IAAgB;AAAA,EAEnD;AAbS;AAeF,QAAM,MAAN,MAAM,YAAW,gBAAgB;AAAA,IAC5B,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,WAAW,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC1E;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,IAI1B;AAAA,EACF;AAhBwC;AAAjC,MAAM,KAAN;AAiBP,oBAAkB,MAAM,EAAE;AAE1B,QAAM,aAAa,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACrH,UAAM,MAAM,MAAM,WAAW;AAC7B,aAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAI,CAAC,IAAK,EAAE,OAAO,KAAK,EAAE,OAAO,IAAK,IAAI;AAAA,IAC5C;AACA,WAAO;AAAA,EACT,GARmB;AAUnB,WAAS,WAAW,GAAW,GAAW,YAA8B,MAAc;AACpF,UAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,UAAM,SAAS;AACf,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,MACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,IAAgB;AAAA,EAEnD;AAbS;AAeF,QAAM,MAAN,MAAM,YAAW,gBAAgB;AAAA,IAC5B,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,WAAW,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC1E;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,IAI1B;AAAA,EACF;AAhBwC;AAAjC,MAAM,KAAN;AAiBP,oBAAkB,MAAM,EAAE;AAE1B,QAAM,aAAa,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACrH,UAAM,MAAM,MAAM,WAAW;AAC7B,aAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAI,CAAC,IAAK,EAAE,OAAO,KAAK,EAAE,OAAO,IAAK,IAAI;AAAA,IAC5C;AACA,WAAO;AAAA,EACT,GARmB;AAUnB,WAAS,WAAW,GAAW,GAAW,YAA8B,MAAc;AACpF,UAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,UAAM,SAAS;AACf,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,MACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,IAAgB;AAAA,EAEnD;AAbS;AAeF,QAAM,MAAN,MAAM,YAAW,gBAAgB;AAAA,IAC5B,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,WAAW,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC1E;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,IAI1B;AAAA,EACF;AAhBwC;AAAjC,MAAM,KAAN;AAiBP,oBAAkB,MAAM,EAAE;AAE1B,QAAM,aAAa,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACrH,UAAM,MAAM,MAAM,WAAW;AAC7B,aAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,YAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAI,CAAC,IAAK,EAAE,OAAO,KAAK,EAAE,OAAO,IAAK,IAAI;AAAA,IAC5C;AACA,WAAO;AAAA,EACT,GARmB;AAUnB,WAAS,WAAW,GAAW,GAAW,YAA8B,MAAc;AACpF,UAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,UAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,UAAM,SAAS;AACf,UAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,MACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,MACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,IAAgB;AAAA,EAEnD;AAbS;AAeF,QAAM,MAAN,MAAM,YAAW,gBAAgB;AAAA,IAC5B,SAAS,GAAW,GAAmB;AAC/C,UAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,aAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,MAC5B;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,WAAW,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,IAC1E;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,YAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,IAI1B;AAAA,EACF;AAhBwC;AAAjC,MAAM,KAAN;AAiBP,oBAAkB,MAAM,EAAE;AC38CnB,WAAS,oBAAoB,MAAuC;AACzE,QAAI,MAAM,QAAQ,KAAK,CAAC,CAAC,GAAG;AAC1B,aAAO,KAAK,CAAC;AAAA,IACf;AAEA,WAAO;AAAA,EACT;AANgB;ACKT,WAAS,SAAS,MAAqC;AAC5D,UAAM,QAAQ,oBAAoB,IAAI;AACtC,UAAM,SAAS,IAAI,OAAO,MAAM,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,KAAK,KAAK,OAAA,CAAQ,CAAC;AACrF,WAAO,QAAQ;AACf,WAAO;AAAA,EACT;AALgB;AAOT,WAAS,QAAQ,MAAqC;AAC3D,UAAM,QAAQ,oBAAoB,IAAI;AACtC,UAAM,SAAS,IAAI,OAAO,MAAM,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,KAAK,KAAK,OAAA,CAAQ,CAAC;AACrF,WAAO,QAAQ;AACf,WAAO;AAAA,EACT;AALgB;AAOT,WAAS,QAAQ,KAAa,MAAc,OAAyB;AAC1E,UAAM,SAAS,IAAI;AAAA,MACjB,MAAM,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,KAAK,KAAK,MAAM,KAAK,OAAA,KAAY,OAAO,OAAO,GAAG,CAAC;AAAA,IAAA;AAE7F,WAAO,QAAQ;AACf,WAAO;AAAA,EACT;AANgB;AChBT,WAAS,QAAQ,MAAqC;AAC3D,UAAM,QAAQ,oBAAoB,IAAI;AACtC,UAAM,SAAS,IAAI,OAAO,MAAM,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;AACzE,WAAO,QAAQ;AACf,WAAO;AAAA,EACT;AALgB;AAOT,WAAS,SAAS,MAAqC;AAC5D,UAAM,QAAQ,oBAAoB,IAAI;AACtC,UAAM,SAAS,IAAI,OAAO,MAAM,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;AACzE,WAAO,QAAQ;AACf,WAAO;AAAA,EACT;AALgB;AAOT,WAAS,UAAU,QAAwB;AAChD,WAAO,KAAK,OAAO,KAAK;AAAA,EAC1B;AAFgB;AAIT,WAAS,WAAW,QAAwB;AACjD,WAAO,MAAM,OAAO,KAAK;AAAA,EAC3B;AAFgB;ACnBT,WAAS,SAAS,OAAe,KAAa,OAAe;AAClE,UAAM,OAAO,CAAA;AACb,UAAM,QAAQ,MAAM,UAAU,QAAQ;AACtC,aAAS,IAAI,GAAG,IAAI,QAAQ,GAAG,KAAK;AAClC,WAAK,KAAK,QAAQ,IAAI,IAAI;AAAA,IAC5B;AACA,SAAK,KAAK,GAAG;AACb,WAAO,IAAI,OAAO,IAAI;AAAA,EACxB;AARgB;AAUT,WAAS,OAAO,OAAe,MAAc,QAAW,OAAe,GAAG;AAC/E,UAAM,OAAO,CAAA;AACb,aAAS,IAAI,OAAO,IAAI,KAAK,KAAK,MAAM;AACtC,WAAK,KAAK,CAAC;AAAA,IACb;AACA,WAAO,IAAI,OAAO,IAAI;AAAA,EACxB;AANgB;ACChB,QAAM,eAAe,gCAAU,GAAa,QAAgB;AAC1D,UAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAI,CAAC,IAAI,KAAK,IAAI,EAAE,CAAC,GAAG,CAAC;AAAA,IAC3B;AACA,WAAO;AAAA,EACT,GANqB;AAQrB,WAAS,aAAa,GAAW,YAA8B,MAAc;AAC3E,UAAM,SAAS;AACf,UAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,MAAM;AAAA,MACrB,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,IAAM;AAAA,EAE3C;AATS;AAWF,QAAM,QAAN,MAAM,cAAa,eAAe;AAAA,IAC7B,SAAS,GAAmB;AACpC,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,aAAa,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,IACtD;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAI,SAAS,GAAG,IAAI,EAAE,GAAG,CAAC,CAAC,CAAC;AAAA,IAC9B;AAAA,EACF;AAfyC;AAAlC,MAAM,OAAN;AAgBP,oBAAkB,QAAQ,IAAI;AAI9B,QAAM,kBAAkB,gCAAU,GAAa,QAAgB;AAC7D,UAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAI,CAAC,IAAI,KAAK,IAAI,KAAK,IAAI,CAAC,EAAE,CAAC,CAAC;AAAA,IAClC;AACA,WAAO;AAAA,EACT,GANwB;AAQxB,WAAS,gBAAgB,GAAW,YAA8B,MAAc;AAC9E,UAAM,SAAS;AACf,UAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,WAAO,IAAI;AAAA,MACT,OAAO,EAAE,MAAM,MAAM;AAAA,MACrB,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,IAAM;AAAA,EAE3C;AATS;mBAWF,mBAAsB,eAAe;AAAA,IAChC,SAAS,GAAmB;AACpC,UAAI,EAAE,eAAe;AACnB,aAAK,gBAAgB,CAAC,CAAC;AAAA,MACzB;AACA,WAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,aAAO,gBAAgB,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,IACzD;AAAA,IACU,UAAU,IAAkB;AACpC,YAAM,CAAC,CAAC,IAAI,KAAK;AACjB,YAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAI,SAAS,GAAG,IAAI,EAAE,MAAM,IAAI,CAAC,EAAE,IAAI,EAAE,EAAE,aAAa,IAAI,EAAE,IAAA,CAAK,EAAE,IAAI,EAAE,CAAC,CAAC;AAAA,IAC/E;AAAA,EACF,GAf4C,uBAArC;AAgBP,oBAAkB,WAAWC,SAAO;ACjF7B,QAAM,aAAN,MAAM,mBAAkB,OAAO;AAAA,IACpC,YACE,MAEA,UAAuC;AAAA,MACnC,eAAe;AAAA,IAAA,GAEnB,mBAAgE,CAAA,GAChE;AACA,UAAI,gBAAgB,QAAQ;AAC1B,cAAM,KAAK,MAAM,EAAE,eAAe,KAAA,GAAQ,EAAE,OAAO,KAAK,OAAO;AAAA,MACjE,WAAW,gBAAgB,YAAW;AACpC,cAAM,KAAK,MAAM,EAAE,eAAe,KAAA,GAAQ,EAAE,OAAO,KAAK,OAAO;AAAA,MACjE,OAAO;AACL,cAAM,MAAM,SAAS,gBAAgB;AAAA,MACvC;AAAA,IACF;AAAA,EACF;AAjBsC;AAA/B,MAAM,YAAN;AAmBA,QAAe,UAAf,MAAe,QAAO;AAAA,IACnB;AAAA,IACA;AAAA,IAER,cAAc;AACZ,WAAK,cAAc,CAAA;AACnB,WAAK,WAAW,CAAA;AAAA,IAClB;AAAA,IAEQ,mBAAmB,gBAAwB,WAAsB;AACvE,WAAK,YAAY,cAAc,IAAI;AAAA,IACrC;AAAA,IAEQ,gBAAgB,aAAqBC,SAAgB;AAC3D,WAAK,SAAS,WAAW,IAAIA;AAAA,IAC/B;AAAA,IAEU,SAAS,MAAc,OAA2B;AAC1D,UAAI,iBAAiB,WAAW;AAC9B,aAAK,mBAAmB,MAAM,KAAK;AAAA,MACrC,OAAO;AACL,aAAK,gBAAgB,MAAM,KAAK;AAAA,MAClC;AAAA,IACF;AAAA,IAIO,aAA0B;AAC/B,UAAI,SAAsB,OAAO,OAAO,KAAK,WAAW;AACxD,iBAAWA,WAAU,OAAO,OAAO,KAAK,QAAQ,GAAG;AACjD,iBAAS,OAAO,OAAOA,QAAO,WAAA,CAAY;AAAA,MAC5C;AACA,aAAO;AAAA,IACT;AAAA,EACF;AAlC6B;AAAtB,MAAe,SAAf;AAoCA,QAAM,UAAN,MAAM,gBAAe,OAAO;AAAA,IACzB;AAAA,IACA;AAAA,IAER,YAAY,aAAqB,cAAsB;AACrD,YAAA;AACA,YAAM,IAAI,KAAK,KAAK,IAAI,WAAW;AAEnC,WAAK,SAAS,IAAI,UAAU,KAAK,CAAC,cAAc,WAAW,CAAC,EAAE,IAAI,IAAI,CAAC,EAAE,IAAI,CAAC,CAAC;AAC/E,WAAK,OAAO,IAAI,UAAU,KAAK,CAAC,YAAY,CAAC,EAAE,IAAI,IAAI,CAAC,EAAE,IAAI,CAAC,CAAC;AAEhE,WAAK,SAAS,UAAU,KAAK,MAAM;AACnC,WAAK,SAAS,QAAQ,KAAK,IAAI;AAAA,IACjC;AAAA,IAEA,QAAQ,OAAe;AACrB,aAAO,MAAM,OAAO,KAAK,OAAO,UAAU,GAAG,CAAC,CAAC,EAAE,IAAI,KAAK,IAAI;AAAA,IAChE;AAAA,EACF;AAlBmC;AAA5B,MAAM,SAAN;AAoBA,QAAM,QAAN,MAAM,cAAa,OAAO;AAAA,IAC/B,cAAc;AACZ,YAAA;AAAA,IACF;AAAA,IAEA,QAAQ,OAAe;AACrB,aAAOC,KAAgB,KAAK;AAAA,IAC9B;AAAA,EACF;AARiC;AAA1B,MAAM,OAAN;AAUA,QAAM,WAAN,MAAM,iBAAgB,OAAO;AAAA,IAClC,cAAc;AACZ,YAAA;AAAA,IACF;AAAA,IAEA,QAAQ,OAAe;AACrB,aAAOC,QAAmB,KAAK;AAAA,IACjC;AAAA,EACF;AARoC;AAA7B,MAAM,UAAN;ACzFP,QAAe,QAAf,MAAe,MAAK;AAAA,EAEpB;AAFoB;AAApB,MAAe,OAAf;AAIO,QAAM,WAAN,MAAM,iBAAgB,KAAK;AAAA,IAChC,cAAc;AACZ,YAAA;AAAA,IACF;AAAA,IAEA,QAAQ,OAAe,QAAgB;AACrC,aAAO,MAAM,IAAI,MAAM,EAAE,IAAI,CAAC,EAAE,KAAA;AAAA,IAClC;AAAA,EACF;AARkC;AAA3B,MAAM,UAAN;AAUA,QAAM,UAAN,MAAM,gBAAe,KAAK;AAAA,IAC/B,cAAc;AACZ,YAAA;AAAA,IACF;AAAA,IAEA,QAAQ,OAAe,QAAgB;AACrC,aAAO,MAAM,IAAI,MAAM,EAAE,IAAA,EAAM,KAAA;AAAA,IACjC;AAAA,EACF;AARiC;AAA1B,MAAM,SAAN;AAUA,QAAM,WAAN,MAAM,iBAAgB,KAAK;AAAA,IACxB;AAAA,IAER,YAAY,SAAwB,MAAM;AACxC,YAAA;AACA,WAAK,SAAS;AAAA,IAChB;AAAA,IAEA,QAAQ,OAAe,QAAgB;AACrC,YAAM,OAAO,OAAO,IAAI,MAAM,KAAK;AACnC,YAAM,QAAQ,OAAO,IAAA,EAAM,IAAI,CAAC,EAAE,IAAI,MAAM,MAAM,IAAI,CAAC,EAAE,KAAK;AAC9D,YAAM,OAAO,KAAK,IAAI,KAAK,EAAE,IAAA,EAAM,KAAA;AACnC,UAAI,KAAK,QAAQ;AACf,eAAO,KAAK,IAAI,KAAK,MAAM;AAAA,MAC7B;AACA,aAAO;AAAA,IACT;AAAA,EACF;AAjBkC;AAA3B,MAAM,UAAN;ACvBP,WAAS,kBAAkB,QAAgB;AACzC,WAAO,IAAI,SAA8B;AACvC,YAAM,YAAY,KAAK,aAAa,MAAM,GAAA;AAC1C,aAAO,UAAU,QAAQ,GAAG,IAAI;AAAA,IAClC;AAAA,EACF;AALS;AAOT,WAAS,wBAAwB,QAAgB;AAC/C,WAAO,CAAC,MAAuB;AAC7B,UAAI,OAAO,KAAK,UAAU;AACxB,YAAI,IAAI,OAAO,CAAC;AAAA,MAClB;AAEA,YAAM,YAAY,KAAK,aAAa,MAAM,GAAA;AAC1C,aAAO,UAAU,QAAQ,CAAC;AAAA,IAC5B;AAAA,EACF;AATS;AAWT,WAAS,yBAAyB,QAAgB;AAChD,WAAO,CAAC,GAAoB,MAAuB;AACjD,UAAI,OAAO,KAAK,UAAU;AACxB,YAAI,IAAI,OAAO,CAAC;AAAA,MAClB;AAEA,UAAI,OAAO,KAAK,UAAU;AACxB,YAAI,IAAI,OAAO,CAAC;AAAA,MAClB;AAEA,YAAM,YAAY,KAAK,aAAa,MAAM,GAAA;AAC1C,aAAO,UAAU,QAAQ,GAAG,CAAC;AAAA,IAC/B;AAAA,EACF;AAbS;AAeF,QAAM,OAAO,wBAAwB,MAAM;AAC3C,QAAM,UAAU,wBAAwB,SAAS;;;;;;;;;;;;;;;;;;ACnCjD,QAAe,aAAf,MAAe,WAAU;AAAA,IAC9B;AAAA,IACA;AAAA,IAEA,YAAY,QAAqB,UAAkC;AACjE,WAAK,SAAS;AACd,WAAK,WAAW;AAAA,IAClB;AAAA,IAEO,YAAkB;AACvB,iBAAW,SAAS,KAAK,QAAQ;AAC/B,cAAM,OAAO;AAAA,MACf;AAAA,IACF;AAAA,EAGF;AAhBgC;AAAzB,MAAe,YAAf;ACGA,QAAM,OAAN,MAAM,aAAY,UAAU;AAAA,IACzB,4BAAkD,IAAA;AAAA,IAClD;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IAER,YACE,QACA,KAAa,MACb,WAAmB,GACnB,YAAoB,GACpB,eAAuB,GACvB,WAAoB,OACpB,WAAoB,OACpB;AACA,YAAM,QAAQ,EAAE;AAChB,WAAK,KAAK;AACV,WAAK,WAAW;AAChB,WAAK,YAAY;AACjB,WAAK,eAAe;AACpB,WAAK,WAAW;AAChB,WAAK,WAAW;AAAA,IAClB;AAAA,IAEA,OAAa;AACX,iBAAW,SAAS,KAAK,QAAQ;AAC/B,YAAI,IAAI,KAAK,WAAW,MAAM,KAAK,IAAI,EAAE,IAAI,MAAM;AACnD,YAAI,KAAK,iBAAiB,GAAG;AAC3B,cAAI,EAAE,IAAI,MAAM,IAAI,KAAK,YAAY,CAAC;AAAA,QACxC;AAEA,YAAI,KAAK,aAAa,GAAG;AACvB,cAAI,KAAK,MAAM,IAAI,KAAK,GAAG;AACzB,gBAAIC,OAAM,KAAK,MAAM,IAAI,KAAK,EAAG;AACjCA,mBAAMA,KAAI,IAAI,KAAK,QAAQ;AAC3BA,mBAAMA,KAAI,IAAI,EAAE,IAAI,IAAI,KAAK,SAAS,CAAC;AACvC,iBAAK,MAAM,IAAI,OAAO,EAAE,UAAUA,MAAK;AAAA,UACzC,OAAO;AACL,iBAAK,MAAM,IAAI,OAAO,EAAE,UAAU,GAAG;AAAA,UACvC;AAEA,cAAI,MAAM,KAAK,MAAM,IAAI,KAAK,EAAG;AAEjC,cAAI,KAAK,UAAU;AACjB,gBAAI,EAAE,IAAI,IAAI,IAAI,KAAK,QAAQ,CAAC;AAAA,UAClC,OAAO;AACL,gBAAI;AAAA,UACN;AAEA,eAAK,MAAM,IAAI,OAAO,EAAE,UAAU,KAAK;AAAA,QACzC;AAGA,cAAM,WAAW,MAAM,IAAI,EAAE,IAAI,KAAK,EAAE,CAAC;AACzC,cAAM,OAAO,SAAS;AAAA,MACxB;AAAA,IACF;AAAA,EACF;AA5DmC;AAA5B,MAAM,MAAN;AA8DA,QAAM,QAAN,MAAM,cAAa,UAAU;AAAA,IAC1B,4BAIC,IAAA;AAAA,IAED,aAAqB;AAAA,IACrB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IAER,YACE,QACA,KAAa,MACb,QAA0B,CAAC,KAAK,KAAK,GACrC,MAAc,MACd,eAAuB,GACvB,UAAmB,OACnB,WAAoB,OACpB;AACA,YAAM,QAAQ,EAAE;AAChB,WAAK,KAAK;AACV,WAAK,QAAQ,MAAM,CAAC;AACpB,WAAK,QAAQ,MAAM,CAAC;AACpB,WAAK,MAAM;AACX,WAAK,eAAe;AACpB,WAAK,UAAU;AACf,WAAK,WAAW;AAAA,IAClB;AAAA,IAEA,OAAa;AACX,WAAK,cAAc;AACnB,iBAAW,SAAS,KAAK,QAAQ;AAC/B,YAAI,OAAO,KAAK,WAAW,MAAM,KAAK,IAAI,EAAE,IAAI,MAAM;AAEtD,YAAI,KAAK,iBAAiB,GAAG;AAC3B,iBAAO,KAAK,IAAI,MAAM,IAAI,KAAK,YAAY,CAAC;AAAA,QAC9C;AAGA,YAAI,CAAC,KAAK,MAAM,IAAI,KAAK,GAAG;AAC1B,eAAK,MAAM,IAAI,OAAO;AAAA,YACpB,GAAG,WAAW,KAAK;AAAA,YACnB,GAAG,WAAW,KAAK;AAAA,YACnB,MAAM,WAAW,KAAK;AAAA,UAAA,CACvB;AAAA,QACH;AAEA,cAAM,QAAQ,KAAK,MAAM,IAAI,KAAK;AAElC,cAAM,IAAI,MAAM,EAAE,IAAI,KAAK,KAAK,EAAE,IAAI,KAAK,IAAI,IAAI,KAAK,KAAK,CAAC;AAC9D,cAAM,IAAI,MAAM,EAAE,IAAI,KAAK,KAAK,EAAE,IAAI,KAAK,IAAI,IAAI,EAAE,IAAI,IAAI,KAAK,KAAK,CAAC;AAExE,cAAM,kBAAkB,IAAI,KAAK,IAAI,KAAK,OAAO,KAAK,UAAU;AAChE,cAAM,kBAAkB,IAAI,KAAK,IAAI,KAAK,OAAO,KAAK,UAAU;AAEhE,YAAI;AACJ,cAAM,OAAO,MAAM,EAAE,IAAI,eAAe;AACxC,YAAI,KAAK,SAAS;AAChB,gBAAM,OAAO,MAAM,KAAK,QAAQ,MAAM,CAAC;AACvC,iBAAO,MAAM,KAAK,IAAI,eAAe;AAAA,QACvC,OAAO;AACL,iBAAO,MAAM,EAAE,IAAI,eAAe;AAAA,QACpC;AAEA,cAAM,SAAS,KAAK,IAAI,KAAK,KAAA,EAAO,IAAI,KAAK,GAAG,CAAC,EAAE,IAAI,KAAK,EAAE;AAE9D,cAAM,WAAW,MAAM,IAAI,MAAM;AACjC,cAAM,OAAO,SAAS;AAAA,MACxB;AAAA,IACF;AAAA,EACF;AA5EoC;AAA7B,MAAM,OAAN;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;"}