{"version":3,"file":"torch.browser.es.js","sources":["../../src/util.ts","../../src/operations/base.ts","../../src/operations/registry.ts","../../src/tensor.ts","../../src/broadcasting.ts","../../src/operations/functional.ts","../../src/operations/ops.gen.ts","../../src/creation/utils.ts","../../src/creation/rand.ts","../../src/creation/initializers.ts","../../src/creation/ranges.ts","../../src/nn/ops.gen.ts","../../src/nn/module.ts","../../src/nn/loss.ts","../../src/nn/functional.ts","../../src/optim/base.ts","../../src/optim/optimizers.ts"],"sourcesContent":["let globalId = 0;\n\nexport const getNextId = () => {\n  return globalId++;\n};\n\nexport const eventBus = new EventTarget();\nexport const events = {\n  TENSOR_BEFORE_BACKWARD: 'tensor.beforeBackward',\n  TENSOR_AFTER_BACKWARD: 'tensor.afterBackward',\n  OPERATION_BEFORE_FORWARD: 'operation.beforeForward',\n  OPERATION_AFTER_FORWARD: 'operation.afterForward',\n  OPERATION_BEFORE_BACKWARD: 'operation.beforeBackward',\n  OPERATION_AFTER_BACKWARD: 'operation.afterBackward',\n  OPERATION_ACCUMULATE_GRAD: 'operation.accumulateGrad',\n}","import { Tensor } from '../tensor';\nimport { eventBus, getNextId, events } from '../util';\n\nabstract class Operation {\n  public id: number = getNextId();\n  public next_functions: Operation[] = [];\n  public saved_tensors: Tensor[] = [];\n  public _retained_tensors: Tensor[] = [];\n\n  protected abstract _forward(...args: (Tensor | number | number[])[]): Tensor;\n  protected abstract _backward(dz: Tensor): void;\n\n  forward(...args: (Tensor | number | number[])[]): Tensor {\n    eventBus.dispatchEvent(new CustomEvent(events.OPERATION_BEFORE_FORWARD, {\n      detail: {\n        operation: this,\n        args\n      }\n    }));\n    const result = this._forward(...args);\n    eventBus.dispatchEvent(new CustomEvent(events.OPERATION_AFTER_FORWARD, {\n      detail: {\n        operation: this,\n        args,\n        result,\n        requires_grad: result.requires_grad\n      }\n    }));\n    return result;\n  }\n\n  backward(dz: Tensor): void {\n    eventBus.dispatchEvent(new CustomEvent(events.OPERATION_BEFORE_BACKWARD, { detail: { operation: this, dz } }));\n    for (const x of this._retained_tensors) {\n      if (!x.grad) {\n        x.grad = new Tensor(new Array(x.dataLength()).fill(0));\n      }\n      x.grad = x.grad.add(dz);\n    }\n    this._backward(dz);\n    eventBus.dispatchEvent(new CustomEvent(events.OPERATION_AFTER_BACKWARD, { detail: { operation: this, dz } }));\n  }\n}\n\nclass NullOp extends Operation {\n  protected _forward(...args: (Tensor | number | number[])[]): Tensor {\n    throw new Error('NullOp should not be called');\n  }\n  protected _backward(dz: Tensor): void {\n    return;\n  }\n}\n\nexport const nullOp = new NullOp();\n\nabstract class UnaryOperation extends Operation {\n  protected abstract _forward(a: Tensor): Tensor;\n  protected abstract _backward(dz: Tensor): void;\n}\n\nabstract class BinaryOperation extends Operation {\n  protected abstract _forward(a: Tensor, b: Tensor): Tensor;\n  protected abstract _backward(dz: Tensor): void;\n}\n\nexport type OperationConstructor = new () => Operation;\nexport type UnaryOperationConstructor = new () => UnaryOperation;\nexport type BinaryOperationConstructor = new () => BinaryOperation;\n\nexport { Operation, UnaryOperation, BinaryOperation };\n\nexport class AccumulateGrad extends UnaryOperation {\n  public variable: Tensor;\n\n  protected _forward(variable: Tensor): Tensor {\n    this.variable = variable;\n    return variable;\n  }\n\n  protected _backward(dz: Tensor): void {\n    if (!this.variable.grad) {\n      this.variable.grad = new Tensor(new Array(this.variable.dataLength()).fill(0));\n    }\n    eventBus.dispatchEvent(new CustomEvent(events.OPERATION_ACCUMULATE_GRAD, { detail: { operation: this, dz } }));\n    this.variable.grad = this.variable.grad.add(dz);\n  }\n}\n","import { Operation, OperationConstructor } from './base';\n\n// Only allow registering concrete, constructible Operation classes\nconst operations = new Map<string, OperationConstructor>();\nconst operations_cache = new Map<string, Operation>();\n\nexport function registerOperation(name: string, func: OperationConstructor) {\n  operations.set(name, func);\n}\n\nexport function getOperation(name: string): OperationConstructor {\n  const func = operations.get(name);\n  if (!func) {\n    throw new Error(`Operation '${name}' is not registered.`);\n  }\n  return func;\n}\n\nexport function getOperationCache(name: string): Operation {\n  const operation = operations_cache.get(name);\n  if (!operation) {\n    operations_cache.set(name, new (getOperation(name))());\n    return operations_cache.get(name)!;\n  }\n  return operation;\n}","import { _get_original_index } from './broadcasting';\nimport { AccumulateGrad, Operation } from './operations/base';\nimport { getOperation, getOperationCache } from './operations/registry';\nimport { getNextId, eventBus, events } from './util';\n\n/*\n * TODO:\n * - Add support for Textures to be stored in Tensors\n */\n\ntype TypedArray =\n  | Int8Array\n  | Uint8Array\n  | Uint8ClampedArray\n  | Int16Array\n  | Uint16Array\n  | Int32Array\n  | Uint32Array\n  | Float32Array\n  | Float64Array;\n\nexport type NestedNumberArray = number | TypedArray | NestedNumberArray[];\n\nfunction _get_shape(data: NestedNumberArray): number[] {\n  if (ArrayBuffer.isView(data)) {\n    return [data.length];\n  }\n\n  const shape = [];\n  while (Array.isArray(data)) {\n    shape.push(data.length);\n    data = data[0];\n  }\n  return shape;\n}\n\nfunction _flatten(data: NestedNumberArray): number[] {\n  if (Array.isArray(data)) {\n    return data.flatMap(item => _flatten(item));\n  } else if (ArrayBuffer.isView(data)) {\n    return Array.from(data);\n  } else {\n    return [data];\n  }\n}\n\nexport class Tensor {\n  public id: number = getNextId();\n  data: number[];\n  _shape: number[];\n  grad_fn: Operation | null = null;\n  public grad: Tensor | null = null;\n\n  requires_grad: boolean;\n\n  constructor(\n    data: NestedNumberArray,\n    options: { requires_grad?: boolean } = {},\n    internal_options: { operation?: Operation; shape?: number[] } = {}\n  ) {\n    this.data = _flatten(data);\n    this.requires_grad = options.requires_grad ?? false;\n\n    this._shape = internal_options.shape ?? _get_shape(data);\n    this.grad_fn = internal_options.operation ?? null;\n\n    if (this.requires_grad && !this.grad_fn) {\n      const acc = new AccumulateGrad();\n      acc.variable = this;\n      this.grad_fn = acc;\n    }\n  }\n\n  // TODO: Somehow having a shape of [] will have a weird error:\n  // TypeError: Cannot read properties of undefined (reading 'length')\n  // when running kernel (something to do with constants?)\n  // so a little hack to return [1] when the shape is []\n  get shape(): number[] {\n    return this._shape.length === 0 ? [1] : this._shape;\n    // return this._shape;\n  }\n\n  toArray_(): void {\n    return;\n  }\n\n  toArray(): number[] {\n    return this.data;\n  }\n\n  dataLength(): number {\n    return this.data.length;\n  }\n\n  set shape(shape: number[]) {\n    this._shape = shape;\n  }\n\n  private _executeUnaryOp(opName: string): Tensor {\n    const operation = this.requires_grad ? new (getOperation(opName))() : getOperationCache(opName);\n    return operation.forward(this);\n  }\n\n  private _executeBinaryOp(opName: string, other: Tensor | number): Tensor {\n    if (typeof other == 'number') {\n      other = new Tensor(other);\n    }\n    const operation = this.requires_grad || other.requires_grad ? new (getOperation(opName))() : getOperationCache(opName);\n    return operation.forward(this, other);\n  }\n\n  private _executeOpRaw(opName: string, ...args: any[]): Tensor {\n    const operation = new (getOperation(opName))();\n    return operation.forward(this, ...args);\n  }\n\n  item(): number {\n    if (this.dataLength() !== 1) {\n      throw new Error('Tensor.item() is only valid for scalars');\n    }\n    return this.toArray()[0];\n  }\n\n  detach(): Tensor {\n    return new Tensor(this.data, { requires_grad: false }, { shape: this.shape });\n  }\n\n  detach_(): void {\n    this.requires_grad = false;\n    this.grad = null;\n    this.grad_fn = null;\n  }\n\n  zero_(): void {\n    this.data = Array(this.dataLength()).fill(0);\n  }\n\n  private is_retain_grad: boolean = false;\n  retain_grad(): void {\n    // leaf node -> no-op\n    if (this.grad_fn instanceof AccumulateGrad) return;\n    if (this.is_retain_grad) return;\n    this.is_retain_grad = true;\n\n    this.grad_fn._retained_tensors.push(this);\n  }\n\n  backward(grad?: Tensor | null): void {\n    if (!this.requires_grad) {\n      // If this tensor does not require gradients, stop propagation.\n      // TODO: check pytorch behaviour\n      return;\n    }\n\n    if (!grad) {\n      if (this.dataLength() !== 1) {\n        throw new Error('Gradient is required for non-scalar tensors');\n      }\n      grad = new Tensor(1);\n    } else {\n      grad.toArray_();\n    }\n\n    if (this.grad_fn) {\n      eventBus.dispatchEvent(new CustomEvent(events.TENSOR_BEFORE_BACKWARD, { detail: { tensor: this } }));\n      this.grad_fn.backward(grad);\n      eventBus.dispatchEvent(new CustomEvent(events.TENSOR_AFTER_BACKWARD, { detail: { tensor: this } }));\n    }\n  }\n\n  // operations\n\n  // binary pointwise\n\n  add(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('add', other);\n  }\n\n  sub(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('sub', other);\n  }\n\n  mul(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('mul', other);\n  }\n\n  div(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('div', other);\n  }\n\n  pow(other: Tensor | number): Tensor {\n    if (typeof other == 'number' && other % 1 === 0) {\n      return this._executeOpRaw('powint', other);\n    }\n    return this._executeBinaryOp('pow', other);\n  }\n\n  fmod(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('fmod', other);\n  }\n\n  maximum(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('maximum', other);\n  }\n\n  minimum(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('minimum', other);\n  }\n\n  // unary pointwise\n\n  log(): Tensor {\n    return this._executeUnaryOp('log');\n  }\n\n  sqrt(): Tensor {\n    return this._executeUnaryOp('sqrt');\n  }\n\n  exp(): Tensor {\n    return this._executeUnaryOp('exp');\n  }\n\n  square(): Tensor {\n    return this._executeUnaryOp('square');\n  }\n\n  abs(): Tensor {\n    return this._executeUnaryOp('abs');\n  }\n\n  sign(): Tensor {\n    return this._executeUnaryOp('sign');\n  }\n\n  neg(): Tensor {\n    return this._executeUnaryOp('neg');\n  }\n\n  reciprocal(): Tensor {\n    return this._executeUnaryOp('reciprocal');\n  }\n\n  reshape(shape: number[]): Tensor {\n    return this._executeOpRaw('reshape', shape);\n  }\n\n  unsqueeze(dim: number): Tensor {\n    return this._executeOpRaw('unsqueeze', dim);\n  }\n\n  // trigonometric\n\n  sin(): Tensor {\n    return this._executeUnaryOp('sin');\n  }\n\n  cos(): Tensor {\n    return this._executeUnaryOp('cos');\n  }\n\n  tan(): Tensor {\n    return this._executeUnaryOp('tan');\n  }\n\n  // reduction\n\n  sum(): Tensor {\n    return this._executeUnaryOp('sum');\n  }\n\n  mean(): Tensor {\n    return this._executeUnaryOp('mean');\n  }\n\n  // linalg\n\n  transpose(dim0: number, dim1: number): Tensor {\n    return this._executeOpRaw('transpose', dim0, dim1);\n  }\n\n  matmul(other: Tensor): Tensor {\n    return this._executeBinaryOp('matmul', other);\n  }\n\n  // comparison\n\n  lt(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('lt', other);\n  }\n\n  gt(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('gt', other);\n  }\n\n  le(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('le', other);\n  }\n\n  ge(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('ge', other);\n  }\n\n  eq(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('eq', other);\n  }\n\n  ne(other: Tensor | number): Tensor {\n    return this._executeBinaryOp('ne', other);\n  }\n}\n","// https://docs.pytorch.org/docs/stable/notes/broadcasting.html\nexport function _broadcast_shape(a_shape: number[], b_shape: number[]): number[] {\n  const result_length = Math.max(a_shape.length, b_shape.length);\n  const padded_a_shape = [...Array(result_length - a_shape.length).fill(1), ...a_shape];\n  const padded_b_shape = [...Array(result_length - b_shape.length).fill(1), ...b_shape];\n\n  const result_shape: number[] = [];\n\n  for (let i = 0; i < result_length; i++) {\n    if (\n      padded_a_shape[i] !== padded_b_shape[i] &&\n      padded_a_shape[i] !== 1 &&\n      padded_b_shape[i] !== 1\n    ) {\n      throw new Error(`Shape mismatch: ${a_shape} and ${b_shape}`);\n    }\n\n    result_shape.push(Math.max(padded_a_shape[i], padded_b_shape[i]));\n  }\n\n  return result_shape;\n}\n\nexport function _pad_shape(shape: number[], broadcast_shape: number[]): number[] {\n  if (shape.length >= broadcast_shape.length) {\n    return shape;\n  }\n\n  return [...Array(broadcast_shape.length - shape.length).fill(1), ...shape];\n}\n\nexport function _get_original_index(\n  original_shape: number[],\n  new_shape: number[],\n  index: number\n): number {\n  let original_index = 0;\n  let cur_stride = 1;\n  let temp_index = index;\n\n  for (let i = original_shape.length - 1; i >= 0; i--) {\n    if (original_shape[i] > 1) {\n      const dim_index = temp_index % new_shape[i];\n      original_index = original_index + dim_index * cur_stride;\n    }\n    cur_stride *= original_shape[i];\n    temp_index = Math.floor(temp_index / new_shape[i]);\n  }\n  return original_index;\n}\n\nexport function _get_original_index_kernel(\n  original_shape: number[],\n  new_shape: number[],\n  index: number\n): number {\n  let original_index = 0;\n  let cur_stride = 1;\n  let temp_index = index;\n\n  for (let i = this.constants.shape_length - 1; i >= 0; i--) {\n    if (original_shape[i] > 1) {\n      const dim_index = temp_index % new_shape[i];\n      original_index = original_index + dim_index * cur_stride;\n    }\n    cur_stride = cur_stride * original_shape[i];\n    temp_index = Math.floor(temp_index / new_shape[i]);\n  }\n  return original_index;\n}\n\nexport function _get_original_index_from_transposed_index(\n  original_shape: number[],\n  dim0: number,\n  dim1: number,\n  transposed_index: number\n): number {\n  let original_index = 0;\n  let cur_stride = 1;\n  let temp_index = transposed_index;\n\n  let dim0_index = 0;\n  let dim1_index = 0;\n\n  for (let i = this.constants.shape_length - 1; i >= 0; i--) {\n    const dim_index = temp_index % original_shape[i];\n    if (i == dim0) {\n      dim0_index = dim_index;\n    }\n    if (i == dim1) {\n      dim1_index = dim_index;\n    }\n    temp_index = Math.floor(temp_index / original_shape[i]);\n  }\n\n  temp_index = transposed_index;\n\n  for (let j = this.constants.shape_length - 1; j >= 0; j--) {\n    const dim_index = temp_index % original_shape[j];\n    if (j == dim0) {\n      original_index = original_index + dim1_index * cur_stride;\n    } else if (j == dim1) {\n      original_index = original_index + dim0_index * cur_stride;\n    } else {\n      original_index = original_index + dim_index * cur_stride;\n    }\n    cur_stride = cur_stride * original_shape[j];\n    temp_index = Math.floor(temp_index / original_shape[j]);\n  }\n\n  return original_index;\n\n  // return transposed_index;\n}\n","import { Tensor } from '../tensor';\nimport { getOperation } from './registry';\n\nfunction generate_function(opname: string) {\n  return (...args: (Tensor | number)[]) => {\n    const operation = new (getOperation(opname))();\n    return operation.forward(...args);\n  };\n}\n\nfunction generate_unary_function(opname: string) {\n  return (a: Tensor | number) => {\n    if (typeof a == 'number') {\n      a = new Tensor(a);\n    }\n\n    const operation = new (getOperation(opname))();\n    return operation.forward(a);\n  };\n}\n\nfunction generate_binary_function(opname: string) {\n  return (a: Tensor | number, b: Tensor | number) => {\n    if (typeof a == 'number') {\n      a = new Tensor(a);\n    }\n\n    if (typeof b == 'number') {\n      b = new Tensor(b);\n    }\n\n    const operation = new (getOperation(opname))();\n    return operation.forward(a, b);\n  };\n}\n\n// debug operations\n\nexport const __left_index__ = generate_binary_function('__left_index__');\nexport const __right_index__ = generate_binary_function('__right_index__');\n\n// binary pointwise\n\nexport const add = generate_binary_function('add');\nexport const sub = generate_binary_function('sub');\nexport const mul = generate_binary_function('mul');\nexport const div = generate_binary_function('div');\nexport const pow = generate_binary_function('pow');\nexport const fmod = generate_binary_function('fmod');\nexport const maximum = generate_binary_function('maximum');\nexport const minimum = generate_binary_function('minimum');\n\n// unary pointwise\n\nexport const log = generate_unary_function('log');\nexport const sqrt = generate_unary_function('sqrt');\nexport const exp = generate_unary_function('exp');\nexport const square = generate_unary_function('square');\nexport const abs = generate_unary_function('abs');\nexport const sign = generate_unary_function('sign');\nexport const neg = generate_unary_function('neg');\nexport const reciprocal = generate_unary_function('reciprocal');\nexport const reshape = generate_function('reshape');\nexport const unsqueeze = generate_function('unsqueeze');\n\n// trigonometric\n\nexport const sin = generate_unary_function('sin');\nexport const cos = generate_unary_function('cos');\nexport const tan = generate_unary_function('tan');\n\n// reduction\n\nexport const sum = generate_unary_function('sum');\nexport const mean = generate_unary_function('mean');\n\n// linalg\n\nexport const transpose = generate_function('transpose');\nexport const matmul = generate_binary_function('matmul');\n\n// comparison\n\nexport const lt = generate_binary_function('lt');\nexport const gt = generate_binary_function('gt');\nexport const le = generate_binary_function('le');\nexport const ge = generate_binary_function('ge');\nexport const eq = generate_binary_function('eq');\nexport const ne = generate_binary_function('ne');","// This file is generated by scripts/generate_script.py from src/operations/ops.ts.j2\nimport { Tensor } from '../tensor';\nimport {\n  _broadcast_shape,\n  _get_original_index_from_transposed_index,\n  _get_original_index,\n  _get_original_index_kernel,\n  _pad_shape\n} from '../broadcasting';\nimport { Operation, BinaryOperation, UnaryOperation, nullOp, AccumulateGrad } from './base';\nimport * as functional from './functional';\nimport { registerOperation } from './registry';\n\n// debug operations\n\nconst ___left_index___kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = a_index;\n  }\n  return res;\n};\n\nfunction ___left_index___tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = ___left_index___kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"__Left_index__\", \"__left_index__\", backward_operations)\nexport class __Left_index__ extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return ___left_index___tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('__left_index__', __Left_index__);\n\nconst ___right_index___kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = b_index;\n  }\n  return res;\n};\n\nfunction ___right_index___tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = ___right_index___kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"__Right_index__\", \"__right_index__\", backward_operations)\nexport class __Right_index__ extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return ___right_index___tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('__right_index__', __Right_index__);\n\n// binary pointwise\n\nconst _add_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = a[a_index] + b[b_index];\n  }\n  return res;\n};\n\nfunction _add_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _add_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Add\", \"add\", backward_operations)\nexport class Add extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _add_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz);\n    bFn.backward(dz);\n  }\n}\nregisterOperation('add', Add);\n\nconst _sub_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = a[a_index] - b[b_index];\n  }\n  return res;\n};\n\nfunction _sub_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _sub_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Sub\", \"sub\", backward_operations)\nexport class Sub extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _sub_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz);\n    bFn.backward(dz.mul(new Tensor(-1)));\n  }\n}\nregisterOperation('sub', Sub);\n\nconst _mul_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = a[a_index] * b[b_index];\n  }\n  return res;\n};\n\nfunction _mul_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _mul_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Mul\", \"mul\", backward_operations)\nexport class Mul extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _mul_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(b));\n    bFn.backward(dz.mul(a));\n  }\n}\nregisterOperation('mul', Mul);\n\nconst _div_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = a[a_index] / b[b_index];\n  }\n  return res;\n};\n\nfunction _div_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _div_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Div\", \"div\", backward_operations)\nexport class Div extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _div_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.div(b));\n    bFn.backward(dz.mul(a).mul(new Tensor(-1)).div(b).div(b));\n  }\n}\nregisterOperation('div', Div);\n\nconst _pow_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = Math.pow(a[a_index], b[b_index]);\n  }\n  return res;\n};\n\nfunction _pow_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _pow_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Pow\", \"pow\", backward_operations)\nexport class Pow extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _pow_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(b).mul(a.pow(b.sub(new Tensor(1)))));\n    bFn.backward(dz.mul(a.pow(b)).mul(a.log()));\n  }\n}\nregisterOperation('pow', Pow);\n\nconst _fmod_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = a[a_index] % b[b_index];\n  }\n  return res;\n};\n\nfunction _fmod_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _fmod_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Fmod\", \"fmod\", backward_operations)\nexport class Fmod extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _fmod_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz);\n  }\n}\nregisterOperation('fmod', Fmod);\n\nconst _maximum_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = Math.max(a[a_index], b[b_index]);\n  }\n  return res;\n};\n\nfunction _maximum_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _maximum_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Maximum\", \"maximum\", backward_operations)\nexport class Maximum extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _maximum_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.ge(b)));\n    bFn.backward(dz.mul(b.gt(a)));\n  }\n}\nregisterOperation('maximum', Maximum);\n\nconst _minimum_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = Math.min(a[a_index], b[b_index]);\n  }\n  return res;\n};\n\nfunction _minimum_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _minimum_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Minimum\", \"minimum\", backward_operations)\nexport class Minimum extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _minimum_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.le(b)));\n    bFn.backward(dz.mul(b.lt(a)));\n  }\n}\nregisterOperation('minimum', Minimum);\n\n\nfunction _powint_tensor(a: Tensor, n: number, operation: Operation | null = null): Tensor {\n  const data = new Array(a.dataLength());\n  for (let i = 0; i < data.length; i++) {\n    data[i] = Math.pow(a.data[i], n);\n  }\n  return new Tensor(\n    data,\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\nexport class PowInt extends Operation {\n  private n: number;\n  protected _forward(a: Tensor, n: number): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n      this.n = n;\n    }\n\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _powint_tensor(a, n, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const n = this.n;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(n).mul(a.pow(n - 1)));\n  }\n}\nregisterOperation('powint', PowInt);\n\n// unary pointwise\n\n// function generated from unary_op_base(\"log\", \"Math.log(a[x])\")\n\nconst _log_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.log(a[x]);\n  }\n  return res;\n};\n\nfunction _log_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _log_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Log\", \"log\", backward_operations)\nexport class Log extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _log_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(new Tensor(1).div(a));\n  }\n}\nregisterOperation('log', Log);\n\n// function generated from unary_op_base(\"sqrt\", \"Math.sqrt(a[x])\")\n\nconst _sqrt_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.sqrt(a[x]);\n  }\n  return res;\n};\n\nfunction _sqrt_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _sqrt_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Sqrt\", \"sqrt\", backward_operations)\nexport class Sqrt extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _sqrt_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(new Tensor(1).div(a.sqrt()).div(2));\n  }\n}\nregisterOperation('sqrt', Sqrt);\n\n// function generated from unary_op_base(\"exp\", \"Math.exp(a[x])\")\n\nconst _exp_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.exp(a[x]);\n  }\n  return res;\n};\n\nfunction _exp_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _exp_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Exp\", \"exp\", backward_operations)\nexport class Exp extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _exp_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.exp()));\n  }\n}\nregisterOperation('exp', Exp);\n\n// function generated from unary_op_base(\"square\", \"a[x] * a[x]\")\n\nconst _square_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = a[x] * a[x];\n  }\n  return res;\n};\n\nfunction _square_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _square_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Square\", \"square\", backward_operations)\nexport class Square extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _square_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a).mul(new Tensor(2)));\n  }\n}\nregisterOperation('square', Square);\n\n// function generated from unary_op_base(\"abs\", \"Math.abs(a[x])\")\n\nconst _abs_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.abs(a[x]);\n  }\n  return res;\n};\n\nfunction _abs_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _abs_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Abs\", \"abs\", backward_operations)\nexport class Abs extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _abs_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(functional.sign(a)));\n  }\n}\nregisterOperation('abs', Abs);\n\n// function generated from unary_op_base(\"sign\", \"Math.sign(a[x])\")\n\nconst _sign_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.sign(a[x]);\n  }\n  return res;\n};\n\nfunction _sign_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _sign_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Sign\", \"sign\", backward_operations)\nexport class Sign extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _sign_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('sign', Sign);\n\n// function generated from unary_op_base(\"neg\", \"-a[x]\")\n\nconst _neg_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = -a[x];\n  }\n  return res;\n};\n\nfunction _neg_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _neg_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Neg\", \"neg\", backward_operations)\nexport class Neg extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _neg_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(new Tensor(-1)));\n  }\n}\nregisterOperation('neg', Neg);\n\n// function generated from unary_op_base(\"reciprocal\", \"1 / a[x]\")\n\nconst _reciprocal_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = 1 / a[x];\n  }\n  return res;\n};\n\nfunction _reciprocal_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _reciprocal_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Reciprocal\", \"reciprocal\", backward_operations)\nexport class Reciprocal extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _reciprocal_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.pow(-2)));\n  }\n}\nregisterOperation('reciprocal', Reciprocal);\n\nexport class Reshape extends Operation {\n  protected _forward(a: Tensor, shape: number[]) {\n    const previous_length = a.dataLength();\n    const target_length = shape.reduce((acc, val) => acc * val, 1);\n\n    if (previous_length !== target_length) {\n      throw new Error('Shape mismatch: ' + a.shape + ' and ' + shape);\n    }\n\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    if (a.grad_fn) {\n      this.next_functions.push(a.grad_fn);\n    } else if (a.requires_grad) {\n      const acc = new AccumulateGrad();\n      acc.variable = a;\n      this.next_functions.push(acc);\n    } else {\n      this.next_functions.push(nullOp);\n    }\n\n    return new Tensor(\n      a.data,\n      { requires_grad: a.requires_grad },\n      { operation: a.requires_grad ? this : null, shape }\n    );\n  }\n  protected _backward(dz: Tensor) {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.reshape(a.shape));\n  }\n}\nregisterOperation('reshape', Reshape);\n\nexport class Unsqueeze extends Operation {\n  protected _forward(a: Tensor, dim: number) {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    if (a.grad_fn) {\n      this.next_functions.push(a.grad_fn);\n    } else if (a.requires_grad) {\n      const acc = new AccumulateGrad();\n      acc.variable = a;\n      this.next_functions.push(acc);\n    } else {\n      this.next_functions.push(nullOp);\n    }\n\n    if (dim < 0) {\n      dim += a.shape.length + 1;\n    }\n\n    const shape = [...a.shape];\n    shape.splice(dim, 0, 1);\n\n    return new Tensor(\n      a.data,\n      { requires_grad: a.requires_grad },\n      { operation: a.requires_grad ? this : null, shape }\n    );\n  }\n  protected _backward(dz: Tensor) {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.reshape(a.shape));\n  }\n}\nregisterOperation('unsqueeze', Unsqueeze);\n\n// trigonometric\n\n// function generated from unary_op_base(\"sin\", \"Math.sin(a[x])\")\n\nconst _sin_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.sin(a[x]);\n  }\n  return res;\n};\n\nfunction _sin_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _sin_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Sin\", \"sin\", backward_operations)\nexport class Sin extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _sin_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.cos()));\n  }\n}\nregisterOperation('sin', Sin);\n\n// function generated from unary_op_base(\"cos\", \"Math.cos(a[x])\")\n\nconst _cos_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.cos(a[x]);\n  }\n  return res;\n};\n\nfunction _cos_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _cos_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Cos\", \"cos\", backward_operations)\nexport class Cos extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _cos_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.sin().neg()));\n  }\n}\nregisterOperation('cos', Cos);\n\n// function generated from unary_op_base(\"tan\", \"Math.tan(a[x])\")\n\nconst _tan_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.tan(a[x]);\n  }\n  return res;\n};\n\nfunction _tan_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _tan_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Tan\", \"tan\", backward_operations)\nexport class Tan extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _tan_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.cos().pow(-2)));\n  }\n}\nregisterOperation('tan', Tan);\n\n// reduction\n\nfunction _sum_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  return new Tensor(\n    a.toArray().reduce((acc, val) => acc + val, 0),\n    { requires_grad: a.requires_grad },\n    { operation: operation }\n  );\n}\n\n// class generated from unary_op_class(\"Sum\", \"sum\", backward_operations)\nexport class Sum extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _sum_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    const result = new Tensor(Array(a.dataLength()).fill(dz.item()));\n    aFn.backward(result);\n  }\n}\nregisterOperation('sum', Sum);\n\nfunction _mean_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  return new Tensor(\n    a.toArray().reduce((acc, val) => acc + val, 0) / a.dataLength(),\n    { requires_grad: a.requires_grad },\n    { operation: operation }\n  );\n}\n\n// class generated from unary_op_class(\"Mean\", \"mean\", backward_operations)\nexport class Mean extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _mean_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    const result = new Tensor(Array(a.dataLength()).fill(dz.item() / a.dataLength()));\n    aFn.backward(result);\n  }\n}\nregisterOperation('mean', Mean);\n\n// linalg\n\nfunction _transpose_tensor(\n  a: Tensor,\n  dim0: number,\n  dim1: number,\n  operation: Operation | null = null\n): Tensor {\n  const output_shape = [...a.shape];\n  [output_shape[dim0], output_shape[dim1]] = [output_shape[dim1], output_shape[dim0]];\n  const size = a.dataLength();\n  const data = new Array(size);\n\n  const a_strides = new Array(a.shape.length);\n  const out_strides = new Array(output_shape.length);\n  for (let i = a.shape.length - 1, s = 1; i >= 0; i--) {\n    a_strides[i] = s;\n    s *= a.shape[i];\n  }\n  for (let i = output_shape.length - 1, s = 1; i >= 0; i--) {\n    out_strides[i] = s;\n    s *= output_shape[i];\n  }\n\n  for(let i=0; i<size; i++) {\n    let idx = i;\n    let input_idx = 0;\n    for (let d = 0; d < output_shape.length; d++) {\n      const stride = out_strides[d];\n      const coord = Math.floor(idx / stride);\n      idx %= stride;\n\n      let input_d = d;\n      if (d === dim0) input_d = dim1;\n      else if (d === dim1) input_d = dim0;\n\n      input_idx += coord * a_strides[input_d];\n    }\n    data[i] = a.data[input_idx];\n  }\n\n  return new Tensor(\n    data,\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: output_shape }\n  );\n}\nexport class Transpose extends Operation {\n  private dim0: number;\n  private dim1: number;\n  protected _forward(a: Tensor, dim0: number, dim1: number): Tensor {\n    if (a.requires_grad) {\n        this.saved_tensors = [a];\n        this.dim0 = dim0;\n        this.dim1 = dim1;\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _transpose_tensor(a, dim0, dim1, this);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const dim0 = this.dim0;\n    const dim1 = this.dim1;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.transpose(dim0, dim1));\n  }\n}\nregisterOperation('transpose', Transpose);\n\nfunction _matmul_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  if (a.shape.length == 1 && b.shape.length == 1) {\n    return a.mul(b).sum();\n  }\n\n  const a_1d = a.shape.length == 1;\n  const b_1d = b.shape.length == 1;\n\n  const a_shape = a_1d ? [1, a.shape[0]] : a.shape;\n  const b_shape = b_1d ? [b.shape[0], 1] : b.shape;\n\n  if (a_shape[a_shape.length - 1] != b_shape[b_shape.length - 2]) {\n    throw new Error('Shape mismatch: ' + a.shape + ' and ' + b.shape);\n  }\n\n  const broadcast_shape = _broadcast_shape(a_shape.slice(0, -2), b_shape.slice(0, -2)).concat([\n    a_shape[a_shape.length - 2],\n    b_shape[b_shape.length - 1]\n  ]);\n\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n  const data = new Array(output_size).fill(0);\n\n  const padded_a_shape = _pad_shape(a_shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b_shape, broadcast_shape);\n\n  const dim_M = broadcast_shape[broadcast_shape.length - 2];\n  const dim_N = broadcast_shape[broadcast_shape.length - 1];\n  const dim_K = a_shape[a_shape.length - 1]; // or b_shape[b_shape.length - 2]\n\n  for (let i = 0; i < output_size; i++) {\n    const mn_idx = i % (dim_M * dim_N);\n    const m = Math.floor(mn_idx / dim_N);\n    const n = mn_idx % dim_N;\n\n    let base_a = _get_original_index(padded_a_shape, broadcast_shape, i - n);\n    let base_b = _get_original_index(padded_b_shape, broadcast_shape, i - m * dim_N);\n\n    let sum = 0;\n    for(let k=0; k < dim_K; k++) {\n      sum += a.data[base_a + k] * b.data[base_b + k * dim_N];\n    }\n    data[i] = sum;\n  }\n\n  let shape_after_removing_extra_dims = [...broadcast_shape];\n\n  if (a_1d) {\n    shape_after_removing_extra_dims = shape_after_removing_extra_dims\n      .slice(0, -2)\n      .concat([broadcast_shape[broadcast_shape.length - 1]]);\n  }\n\n  if (b_1d) {\n    shape_after_removing_extra_dims = shape_after_removing_extra_dims.slice(0, -1);\n  }\n\n  return new Tensor(\n    data,\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: shape_after_removing_extra_dims }\n  );\n}\n// class generated from binary_op_class(\"Matmul\", \"matmul\", backward_operations)\nexport class Matmul extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _matmul_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('matmul', Matmul);\n\n// comparison\n\nconst _lt_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = (a[a_index] < b[b_index]) ? 1 : 0;\n  }\n  return res;\n};\n\nfunction _lt_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _lt_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Lt\", \"lt\", backward_operations)\nexport class Lt extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _lt_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('lt', Lt);\n\nconst _gt_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = (a[a_index] > b[b_index]) ? 1 : 0;\n  }\n  return res;\n};\n\nfunction _gt_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _gt_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Gt\", \"gt\", backward_operations)\nexport class Gt extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _gt_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('gt', Gt);\n\nconst _le_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = (a[a_index] <= b[b_index]) ? 1 : 0;\n  }\n  return res;\n};\n\nfunction _le_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _le_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Le\", \"le\", backward_operations)\nexport class Le extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _le_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('le', Le);\n\nconst _ge_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = (a[a_index] >= b[b_index]) ? 1 : 0;\n  }\n  return res;\n};\n\nfunction _ge_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _ge_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Ge\", \"ge\", backward_operations)\nexport class Ge extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _ge_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('ge', Ge);\n\nconst _eq_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = (a[a_index] == b[b_index]) ? 1 : 0;\n  }\n  return res;\n};\n\nfunction _eq_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _eq_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Eq\", \"eq\", backward_operations)\nexport class Eq extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _eq_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('eq', Eq);\n\nconst _ne_kernel = function (a: number[], as: number[], b: number[], bs: number[], bcs: number[], output_size: number) {\n  const res = Array(output_size);\n  for(let x = 0; x < output_size; x++) {\n    const a_index = _get_original_index(as, bcs, x);\n    const b_index = _get_original_index(bs, bcs, x);\n    res[x] = (a[a_index] != b[b_index]) ? 1 : 0;\n  }\n  return res;\n};\n\nfunction _ne_tensor(a: Tensor, b: Tensor, operation: Operation | null = null): Tensor {\n  const broadcast_shape = _broadcast_shape(a.shape, b.shape);\n  const padded_a_shape = _pad_shape(a.shape, broadcast_shape);\n  const padded_b_shape = _pad_shape(b.shape, broadcast_shape);\n\n  const kernel = _ne_kernel;\n  const output_size = broadcast_shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, padded_a_shape, b.data, padded_b_shape, broadcast_shape, output_size) as number[],\n    { requires_grad: a.requires_grad || b.requires_grad },\n    { operation: operation, shape: broadcast_shape }\n  );\n}\n// class generated from binary_op_class(\"Ne\", \"ne\", backward_operations)\nexport class Ne extends BinaryOperation {\n  protected _forward(a: Tensor, b: Tensor): Tensor {\n    if (a.requires_grad || b.requires_grad) {\n      this.saved_tensors = [a, b];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    this.next_functions.push(b.grad_fn ? b.grad_fn : nullOp);\n    return _ne_tensor(a, b, a.requires_grad || b.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a, b] = this.saved_tensors;\n    const [aFn, bFn] = this.next_functions;\n\n    // backward_operations:\n    \n  }\n}\nregisterOperation('ne', Ne);","export function get_shape_from_args(args: number[] | number[][]): number[] {\n  if (Array.isArray(args[0])) {\n    return args[0];\n  }\n\n  return args as number[];\n}\n","import { Tensor } from '../tensor';\nimport { get_shape_from_args } from './utils';\n\n/* TODO: use the correct distributions */\n\nexport function randn(...args: number[] | number[][]): Tensor {\n  const shape = get_shape_from_args(args);\n  const tensor = new Tensor(Array(shape.reduce((a, b) => a * b, 1)).fill(Math.random()));\n  tensor.shape = shape;\n  return tensor;\n}\n\nexport function rand(...args: number[] | number[][]): Tensor {\n  const shape = get_shape_from_args(args);\n  const tensor = new Tensor(Array(shape.reduce((a, b) => a * b, 1)).fill(Math.random()));\n  tensor.shape = shape;\n  return tensor;\n}\n\nexport function randint(low: number, high: number, shape: number[]): Tensor {\n  const tensor = new Tensor(\n    Array(shape.reduce((a, b) => a * b, 1)).fill(Math.floor(Math.random() * (high - low) + low))\n  );\n  tensor.shape = shape;\n  return tensor;\n}\n","import { Tensor } from '../tensor';\nimport { get_shape_from_args } from './utils';\n\nexport function ones(...args: number[] | number[][]): Tensor {\n  const shape = get_shape_from_args(args);\n  const tensor = new Tensor(Array(shape.reduce((a, b) => a * b, 1)).fill(1));\n  tensor.shape = shape;\n  return tensor;\n}\n\nexport function zeros(...args: number[] | number[][]): Tensor {\n  const shape = get_shape_from_args(args);\n  const tensor = new Tensor(Array(shape.reduce((a, b) => a * b, 1)).fill(0));\n  tensor.shape = shape;\n  return tensor;\n}\n\nexport function ones_like(tensor: Tensor): Tensor {\n  return ones(tensor.shape);\n}\n\nexport function zeros_like(tensor: Tensor): Tensor {\n  return zeros(tensor.shape);\n}\n","import { Tensor } from '../tensor';\n\nexport function linspace(start: number, end: number, steps: number) {\n  const data = [];\n  const step = (end - start) / (steps - 1);\n  for (let i = 0; i < steps - 1; i++) {\n    data.push(start + i * step);\n  }\n  data.push(end);\n  return new Tensor(data);\n}\n\nexport function arange(start: number, end: number = undefined, step: number = 1) {\n  const data = [];\n  for (let i = start; i < end; i += step) {\n    data.push(i);\n  }\n  return new Tensor(data);\n}","// This file is generated by scripts/generate_script.py from src/nn/ops.ts.j2\nimport { Tensor } from '../tensor';\nimport {\n  _broadcast_shape,\n  _get_original_index_from_transposed_index,\n  _get_original_index_kernel,\n  _pad_shape\n} from '../broadcasting';\nimport { Operation, BinaryOperation, UnaryOperation, nullOp, AccumulateGrad } from '../operations/base';\nimport { registerOperation } from '../operations/registry';\n\n// function generated from unary_op_base(\"relu\", \"Math.max(a[x], 0)\")\n\nconst _relu_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = Math.max(a[x], 0);\n  }\n  return res;\n};\n\nfunction _relu_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _relu_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Relu\", \"relu\", backward_operations)\nexport class Relu extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _relu_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.gt(0)));\n  }\n}\nregisterOperation('relu', Relu);\n\n// function generated from unary_op_base(\"sigmoid\", \"1 / (1 + Math.exp(-a[x]))\")\n\nconst _sigmoid_kernel = function (a: number[], output: number) {\n  const res = new Array(output);\n  for (let x = 0; x < output; x++) {\n    res[x] = 1 / (1 + Math.exp(-a[x]));\n  }\n  return res;\n};\n\nfunction _sigmoid_tensor(a: Tensor, operation: Operation | null = null): Tensor {\n  const kernel = _sigmoid_kernel;\n  const output = a.shape.reduce((acc, val) => acc * val, 1);\n\n  return new Tensor(\n    kernel(a.data, output) as number[],\n    { requires_grad: a.requires_grad },\n    { operation: operation, shape: a.shape }\n  );\n}\n// class generated from unary_op_class(\"Sigmoid\", \"sigmoid\", backward_operations)\nexport class Sigmoid extends UnaryOperation {\n  protected _forward(a: Tensor): Tensor {\n    if (a.requires_grad) {\n      this.saved_tensors = [a];\n    }\n    this.next_functions.push(a.grad_fn ? a.grad_fn : nullOp);\n    return _sigmoid_tensor(a, a.requires_grad ? this : null);\n  }\n  protected _backward(dz: Tensor): void {\n    const [a] = this.saved_tensors;\n    const [aFn] = this.next_functions;\n\n    // backward_operations:\n    aFn.backward(dz.mul(a.exp().add(1).pow(-2).reciprocal().mul(a.exp()).mul(-1)));\n  }\n}\nregisterOperation('sigmoid', Sigmoid);","import { Tensor } from \"../tensor\";\nimport { NestedNumberArray } from \"../tensor\";\nimport { Operation } from \"../operations/base\";\nimport { rand } from \"../creation\";\nimport { functional } from \".\";\n\nexport class Parameter extends Tensor {\n  constructor(\n    data: NestedNumberArray | Tensor | Parameter,\n    // Default to requires_grad=true\n    options: { requires_grad?: boolean } = {\n        requires_grad: true,\n    },\n    internal_options: { operation?: Operation; shape?: number[] } = {}\n  ) {\n    if (data instanceof Tensor) {\n      super(data.data, { requires_grad: true }, { shape: data.shape });\n    } else if (data instanceof Parameter) {\n      super(data.data, { requires_grad: true }, { shape: data.shape });\n    } else {\n      super(data, options, internal_options);\n    }\n  }\n}\n\nexport abstract class Module {\n  private _modules: { [key: string]: Module };\n  private _parameters: { [key: string]: Parameter };\n\n  constructor() {\n    this._parameters = {};\n    this._modules = {};\n  }\n\n  private register_parameter(parameter_name: string, parameter: Parameter) {\n    this._parameters[parameter_name] = parameter;\n  }\n\n  private register_module(module_name: string, module: Module) {\n    this._modules[module_name] = module;\n  }\n\n  protected register(name: string, value: Parameter | Module) {\n    if (value instanceof Parameter) {\n      this.register_parameter(name, value);\n    } else {\n      this.register_module(name, value);\n    }\n  }\n\n  public abstract forward(...args: Tensor[]): Tensor;\n\n  public parameters(): Parameter[] {\n    let params: Parameter[] = Object.values(this._parameters);\n    for (const module of Object.values(this._modules)) {\n      params = params.concat(module.parameters());\n    }\n    return params;\n  }\n}\n\nexport class Linear extends Module {\n  private weight: Parameter;\n  private bias: Parameter;\n\n  constructor(in_features: number, out_features: number) {\n    super();\n    const k = Math.sqrt(1 / in_features);\n\n    this.weight = new Parameter(rand([out_features, in_features]).mul(2 * k).sub(k));\n    this.bias = new Parameter(rand([out_features]).mul(2 * k).sub(k));\n\n    this.register(\"weight\", this.weight);\n    this.register(\"bias\", this.bias);\n  }\n\n  forward(input: Tensor) {\n    return input.matmul(this.weight.transpose(0, 1)).add(this.bias);\n  }\n}\n\nexport class ReLU extends Module {\n  constructor() {\n    super();\n  }\n\n  forward(input: Tensor) {\n    return functional.relu(input);\n  }\n}\n\nexport class Sigmoid extends Module {\n  constructor() {\n    super();\n  }\n\n  forward(input: Tensor) {\n    return functional.sigmoid(input);\n  }\n}\n","import { Tensor } from \"../tensor\";\n\nabstract class Loss {\n  abstract forward(input: Tensor, target: Tensor): Tensor;\n}\n\nexport class MSELoss extends Loss {\n  constructor() {\n    super();\n  }\n\n  forward(input: Tensor, target: Tensor) {\n    return input.sub(target).pow(2).mean();\n  }\n}\n\nexport class L1Loss extends Loss {\n  constructor() {\n    super();\n  }\n\n  forward(input: Tensor, target: Tensor) {\n    return input.sub(target).abs().mean();\n  }\n}\n\nexport class BCELoss extends Loss {\n  private weight: Tensor | null;\n\n  constructor(weight: Tensor | null = null) {\n    super();\n    this.weight = weight;\n  }\n\n  forward(input: Tensor, target: Tensor) {\n    const left = target.mul(input.log());\n    const right = target.neg().add(1).mul(input.neg().add(1).log());\n    const loss = left.add(right).neg().mean();\n    if (this.weight) {\n      return loss.mul(this.weight);\n    }\n    return loss;\n  }\n}","import { Tensor } from \"../tensor\";\nimport { getOperation } from \"../operations/registry\";\n\nfunction generate_function(opname: string) {\n  return (...args: (Tensor | number)[]) => {\n    const operation = new (getOperation(opname))();\n    return operation.forward(...args);\n  };\n}\n\nfunction generate_unary_function(opname: string) {\n  return (a: Tensor | number) => {\n    if (typeof a == 'number') {\n      a = new Tensor(a);\n    }\n\n    const operation = new (getOperation(opname))();\n    return operation.forward(a);\n  };\n}\n\nfunction generate_binary_function(opname: string) {\n  return (a: Tensor | number, b: Tensor | number) => {\n    if (typeof a == 'number') {\n      a = new Tensor(a);\n    }\n\n    if (typeof b == 'number') {\n      b = new Tensor(b);\n    }\n\n    const operation = new (getOperation(opname))();\n    return operation.forward(a, b);\n  };\n}\n\nexport const relu = generate_unary_function('relu');\nexport const sigmoid = generate_unary_function('sigmoid');\n","import { Parameter } from \"../nn/module\";\n\nexport abstract class Optimizer {\n  params: Parameter[];\n  defaults: { [key: string]: any };\n\n  constructor(params: Parameter[], defaults: { [key: string]: any }) {\n    this.params = params;\n    this.defaults = defaults;\n  }\n\n  public zero_grad(): void {\n    for (const param of this.params) {\n      param.grad = null;\n    }\n  }\n\n  abstract step(): void;\n}\n","import { Optimizer } from \"./base\";\nimport { Parameter } from \"../nn/module\";\nimport { Tensor } from \"../tensor\";\nimport { zeros_like } from \"../creation\";\n\nexport class SGD extends Optimizer {\n  private state: Map<Parameter, { velocity: Tensor }> = new Map();\n  private lr: number;\n  private momentum: number;\n  private dampening: number;\n  private weight_decay: number;\n  private nesterov: boolean;\n  private maximize: boolean;\n\n  constructor(\n    params: Parameter[],\n    lr: number = 0.001,\n    momentum: number = 0.0,\n    dampening: number = 0.0,\n    weight_decay: number = 0.0,\n    nesterov: boolean = false,\n    maximize: boolean = false,\n  ) {\n    super(params, {});\n    this.lr = lr;\n    this.momentum = momentum;\n    this.dampening = dampening;\n    this.weight_decay = weight_decay;\n    this.nesterov = nesterov;\n    this.maximize = maximize;\n  }\n\n  step(): void {\n    for (const param of this.params) {\n      let g = this.maximize ? param.grad.mul(-1) : param.grad;\n      if (this.weight_decay !== 0) {\n        g = g.add(param.mul(this.weight_decay));\n      }\n\n      if (this.momentum !== 0) {\n        if (this.state.has(param)) {\n          let buf = this.state.get(param)!.velocity;\n          buf = buf.mul(this.momentum)\n          buf = buf.add(g.mul(1 - this.dampening));\n          this.state.set(param, { velocity: buf });\n        } else {\n          this.state.set(param, { velocity: g });\n        }\n\n        let buf = this.state.get(param)!.velocity;\n\n        if (this.nesterov) {\n          g = g.add(buf.mul(this.momentum));\n        } else {\n          g = buf;\n        }\n\n        this.state.set(param, { velocity: buf });\n      }\n\n      // potentially unsafe?\n      const newParam = param.sub(g.mul(this.lr));\n      param.data = newParam.data;\n    }\n  }\n}\n\nexport class Adam extends Optimizer {\n  private state: Map<Parameter, {\n    m: Tensor,\n    v: Tensor,\n    vmax: Tensor\n  }> = new Map();\n\n  private step_count: number = 0;\n  private lr: number;\n  private beta1: number;\n  private beta2: number;\n  private eps: number;\n  private weight_decay: number;\n  private amsgrad: boolean;\n  private maximize: boolean;\n\n  constructor(\n    params: Parameter[],\n    lr: number = 0.001,\n    betas: [number, number] = [0.9, 0.999],\n    eps: number = 1e-8,\n    weight_decay: number = 0.0,\n    amsgrad: boolean = false,\n    maximize: boolean = false,\n  ) {\n    super(params, {});\n    this.lr = lr;\n    this.beta1 = betas[0];\n    this.beta2 = betas[1];\n    this.eps = eps;\n    this.weight_decay = weight_decay;\n    this.amsgrad = amsgrad;\n    this.maximize = maximize;\n  }\n\n  step(): void {\n    this.step_count += 1;\n    for (const param of this.params) {\n      let grad = this.maximize ? param.grad.mul(-1) : param.grad;\n\n      if (this.weight_decay !== 0) {\n        grad = grad.add(param.mul(this.weight_decay));\n      }\n\n      // Initialize\n      if (!this.state.has(param)) {\n        this.state.set(param, {\n          m: zeros_like(param),\n          v: zeros_like(param),\n          vmax: zeros_like(param),\n        });\n      }\n\n      const state = this.state.get(param)!;\n\n      state.m = state.m.mul(this.beta1).add(grad.mul(1 - this.beta1));\n      state.v = state.v.mul(this.beta2).add(grad.mul(grad).mul(1 - this.beta2));\n\n      const biasCorrection1 = 1 - Math.pow(this.beta1, this.step_count);\n      const biasCorrection2 = 1 - Math.pow(this.beta2, this.step_count);\n\n      let vhat: Tensor;\n      const mhat = state.m.div(biasCorrection1);\n      if (this.amsgrad) {\n        state.vmax = state.vmax.maximum(state.v);\n        vhat = state.vmax.div(biasCorrection2);\n      } else {\n        vhat = state.v.div(biasCorrection2);\n      }\n\n      const update = mhat.div(vhat.sqrt().add(this.eps)).mul(this.lr);\n\n      const newParam = param.sub(update);\n      param.data = newParam.data;\n    }\n  }\n}"],"names":["index","generate_function","generate_unary_function","generate_binary_function","functional.sign","sum","Sigmoid","functional.relu","functional.sigmoid","buf"],"mappings":";;AAAA;AAAA,IAAI,WAAW;AAER,MAAM,YAAY,6BAAM;AAC7B,SAAO;AACT,GAFyB;AAIlB,MAAM,WAAW,IAAI,YAAA;AACrB,MAAM,SAAS;AAAA,EACpB,wBAAwB;AAAA,EACxB,uBAAuB;AAAA,EACvB,0BAA0B;AAAA,EAC1B,yBAAyB;AAAA,EACzB,2BAA2B;AAAA,EAC3B,0BAA0B;AAAA,EAC1B,2BAA2B;AAC7B;ACZA,MAAe,aAAf,MAAe,WAAU;AAAA,EAChB,KAAa,UAAA;AAAA,EACb,iBAA8B,CAAA;AAAA,EAC9B,gBAA0B,CAAA;AAAA,EAC1B,oBAA8B,CAAA;AAAA,EAKrC,WAAW,MAA8C;AACvD,aAAS,cAAc,IAAI,YAAY,OAAO,0BAA0B;AAAA,MACtE,QAAQ;AAAA,QACN,WAAW;AAAA,QACX;AAAA,MAAA;AAAA,IACF,CACD,CAAC;AACF,UAAM,SAAS,KAAK,SAAS,GAAG,IAAI;AACpC,aAAS,cAAc,IAAI,YAAY,OAAO,yBAAyB;AAAA,MACrE,QAAQ;AAAA,QACN,WAAW;AAAA,QACX;AAAA,QACA;AAAA,QACA,eAAe,OAAO;AAAA,MAAA;AAAA,IACxB,CACD,CAAC;AACF,WAAO;AAAA,EACT;AAAA,EAEA,SAAS,IAAkB;AACzB,aAAS,cAAc,IAAI,YAAY,OAAO,2BAA2B,EAAE,QAAQ,EAAE,WAAW,MAAM,GAAA,EAAG,CAAG,CAAC;AAC7G,eAAW,KAAK,KAAK,mBAAmB;AACtC,UAAI,CAAC,EAAE,MAAM;AACX,UAAE,OAAO,IAAI,OAAO,IAAI,MAAM,EAAE,YAAY,EAAE,KAAK,CAAC,CAAC;AAAA,MACvD;AACA,QAAE,OAAO,EAAE,KAAK,IAAI,EAAE;AAAA,IACxB;AACA,SAAK,UAAU,EAAE;AACjB,aAAS,cAAc,IAAI,YAAY,OAAO,0BAA0B,EAAE,QAAQ,EAAE,WAAW,MAAM,GAAA,EAAG,CAAG,CAAC;AAAA,EAC9G;AACF;AAvCyB;AAAzB,IAAe,YAAf;AAyCA,MAAM,UAAN,MAAM,gBAAe,UAAU;AAAA,EACnB,YAAY,MAA8C;AAClE,UAAM,IAAI,MAAM,6BAA6B;AAAA,EAC/C;AAAA,EACU,UAAU,IAAkB;AACpC;AAAA,EACF;AACF;AAP+B;AAA/B,IAAM,SAAN;AASO,MAAM,SAAS,IAAI,OAAA;AAE1B,MAAe,kBAAf,MAAe,wBAAuB,UAAU;AAGhD;AAHgD;AAAhD,IAAe,iBAAf;AAKA,MAAe,mBAAf,MAAe,yBAAwB,UAAU;AAGjD;AAHiD;AAAjD,IAAe,kBAAf;AAWO,MAAM,kBAAN,MAAM,wBAAuB,eAAe;AAAA,EAC1C;AAAA,EAEG,SAAS,UAA0B;AAC3C,SAAK,WAAW;AAChB,WAAO;AAAA,EACT;AAAA,EAEU,UAAU,IAAkB;AACpC,QAAI,CAAC,KAAK,SAAS,MAAM;AACvB,WAAK,SAAS,OAAO,IAAI,OAAO,IAAI,MAAM,KAAK,SAAS,WAAA,CAAY,EAAE,KAAK,CAAC,CAAC;AAAA,IAC/E;AACA,aAAS,cAAc,IAAI,YAAY,OAAO,2BAA2B,EAAE,QAAQ,EAAE,WAAW,MAAM,GAAA,EAAG,CAAG,CAAC;AAC7G,SAAK,SAAS,OAAO,KAAK,SAAS,KAAK,IAAI,EAAE;AAAA,EAChD;AACF;AAfmD;AAA5C,IAAM,iBAAN;ACpEP,MAAM,iCAAiB,IAAA;AACvB,MAAM,uCAAuB,IAAA;AAEtB,SAAS,kBAAkB,MAAc,MAA4B;AAC1E,aAAW,IAAI,MAAM,IAAI;AAC3B;AAFgB;AAIT,SAAS,aAAa,MAAoC;AAC/D,QAAM,OAAO,WAAW,IAAI,IAAI;AAChC,MAAI,CAAC,MAAM;AACT,UAAM,IAAI,MAAM,cAAc,IAAI,sBAAsB;AAAA,EAC1D;AACA,SAAO;AACT;AANgB;AAQT,SAAS,kBAAkB,MAAyB;AACzD,QAAM,YAAY,iBAAiB,IAAI,IAAI;AAC3C,MAAI,CAAC,WAAW;AACd,qBAAiB,IAAI,MAAM,KAAK,aAAa,IAAI,IAAI;AACrD,WAAO,iBAAiB,IAAI,IAAI;AAAA,EAClC;AACA,SAAO;AACT;AAPgB;ACKhB,SAAS,WAAW,MAAmC;AACrD,MAAI,YAAY,OAAO,IAAI,GAAG;AAC5B,WAAO,CAAC,KAAK,MAAM;AAAA,EACrB;AAEA,QAAM,QAAQ,CAAA;AACd,SAAO,MAAM,QAAQ,IAAI,GAAG;AAC1B,UAAM,KAAK,KAAK,MAAM;AACtB,WAAO,KAAK,CAAC;AAAA,EACf;AACA,SAAO;AACT;AAXS;AAaT,SAAS,SAAS,MAAmC;AACnD,MAAI,MAAM,QAAQ,IAAI,GAAG;AACvB,WAAO,KAAK,QAAQ,CAAA,SAAQ,SAAS,IAAI,CAAC;AAAA,EAC5C,WAAW,YAAY,OAAO,IAAI,GAAG;AACnC,WAAO,MAAM,KAAK,IAAI;AAAA,EACxB,OAAO;AACL,WAAO,CAAC,IAAI;AAAA,EACd;AACF;AARS;AAUF,MAAM,UAAN,MAAM,QAAO;AAAA,EACX,KAAa,UAAA;AAAA,EACpB;AAAA,EACA;AAAA,EACA,UAA4B;AAAA,EACrB,OAAsB;AAAA,EAE7B;AAAA,EAEA,YACE,MACA,UAAuC,CAAA,GACvC,mBAAgE,CAAA,GAChE;AACA,SAAK,OAAO,SAAS,IAAI;AACzB,SAAK,gBAAgB,QAAQ,iBAAiB;AAE9C,SAAK,SAAS,iBAAiB,SAAS,WAAW,IAAI;AACvD,SAAK,UAAU,iBAAiB,aAAa;AAE7C,QAAI,KAAK,iBAAiB,CAAC,KAAK,SAAS;AACvC,YAAM,MAAM,IAAI,eAAA;AAChB,UAAI,WAAW;AACf,WAAK,UAAU;AAAA,IACjB;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,IAAI,QAAkB;AACpB,WAAO,KAAK,OAAO,WAAW,IAAI,CAAC,CAAC,IAAI,KAAK;AAAA,EAE/C;AAAA,EAEA,WAAiB;AACf;AAAA,EACF;AAAA,EAEA,UAAoB;AAClB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,aAAqB;AACnB,WAAO,KAAK,KAAK;AAAA,EACnB;AAAA,EAEA,IAAI,MAAM,OAAiB;AACzB,SAAK,SAAS;AAAA,EAChB;AAAA,EAEQ,gBAAgB,QAAwB;AAC9C,UAAM,YAAY,KAAK,gBAAgB,KAAK,aAAa,MAAM,GAAA,IAAO,kBAAkB,MAAM;AAC9F,WAAO,UAAU,QAAQ,IAAI;AAAA,EAC/B;AAAA,EAEQ,iBAAiB,QAAgB,OAAgC;AACvE,QAAI,OAAO,SAAS,UAAU;AAC5B,cAAQ,IAAI,QAAO,KAAK;AAAA,IAC1B;AACA,UAAM,YAAY,KAAK,iBAAiB,MAAM,gBAAgB,KAAK,aAAa,MAAM,OAAO,kBAAkB,MAAM;AACrH,WAAO,UAAU,QAAQ,MAAM,KAAK;AAAA,EACtC;AAAA,EAEQ,cAAc,WAAmB,MAAqB;AAC5D,UAAM,YAAY,KAAK,aAAa,MAAM,GAAA;AAC1C,WAAO,UAAU,QAAQ,MAAM,GAAG,IAAI;AAAA,EACxC;AAAA,EAEA,OAAe;AACb,QAAI,KAAK,WAAA,MAAiB,GAAG;AAC3B,YAAM,IAAI,MAAM,yCAAyC;AAAA,IAC3D;AACA,WAAO,KAAK,QAAA,EAAU,CAAC;AAAA,EACzB;AAAA,EAEA,SAAiB;AACf,WAAO,IAAI,QAAO,KAAK,MAAM,EAAE,eAAe,MAAA,GAAS,EAAE,OAAO,KAAK,MAAA,CAAO;AAAA,EAC9E;AAAA,EAEA,UAAgB;AACd,SAAK,gBAAgB;AACrB,SAAK,OAAO;AACZ,SAAK,UAAU;AAAA,EACjB;AAAA,EAEA,QAAc;AACZ,SAAK,OAAO,MAAM,KAAK,YAAY,EAAE,KAAK,CAAC;AAAA,EAC7C;AAAA,EAEQ,iBAA0B;AAAA,EAClC,cAAoB;AAElB,QAAI,KAAK,mBAAmB,eAAgB;AAC5C,QAAI,KAAK,eAAgB;AACzB,SAAK,iBAAiB;AAEtB,SAAK,QAAQ,kBAAkB,KAAK,IAAI;AAAA,EAC1C;AAAA,EAEA,SAAS,MAA4B;AACnC,QAAI,CAAC,KAAK,eAAe;AAGvB;AAAA,IACF;AAEA,QAAI,CAAC,MAAM;AACT,UAAI,KAAK,WAAA,MAAiB,GAAG;AAC3B,cAAM,IAAI,MAAM,6CAA6C;AAAA,MAC/D;AACA,aAAO,IAAI,QAAO,CAAC;AAAA,IACrB,OAAO;AACL,WAAK,SAAA;AAAA,IACP;AAEA,QAAI,KAAK,SAAS;AAChB,eAAS,cAAc,IAAI,YAAY,OAAO,wBAAwB,EAAE,QAAQ,EAAE,QAAQ,KAAA,EAAK,CAAG,CAAC;AACnG,WAAK,QAAQ,SAAS,IAAI;AAC1B,eAAS,cAAc,IAAI,YAAY,OAAO,uBAAuB,EAAE,QAAQ,EAAE,QAAQ,KAAA,EAAK,CAAG,CAAC;AAAA,IACpG;AAAA,EACF;AAAA;AAAA;AAAA,EAMA,IAAI,OAAgC;AAClC,WAAO,KAAK,iBAAiB,OAAO,KAAK;AAAA,EAC3C;AAAA,EAEA,IAAI,OAAgC;AAClC,WAAO,KAAK,iBAAiB,OAAO,KAAK;AAAA,EAC3C;AAAA,EAEA,IAAI,OAAgC;AAClC,WAAO,KAAK,iBAAiB,OAAO,KAAK;AAAA,EAC3C;AAAA,EAEA,IAAI,OAAgC;AAClC,WAAO,KAAK,iBAAiB,OAAO,KAAK;AAAA,EAC3C;AAAA,EAEA,IAAI,OAAgC;AAClC,QAAI,OAAO,SAAS,YAAY,QAAQ,MAAM,GAAG;AAC/C,aAAO,KAAK,cAAc,UAAU,KAAK;AAAA,IAC3C;AACA,WAAO,KAAK,iBAAiB,OAAO,KAAK;AAAA,EAC3C;AAAA,EAEA,KAAK,OAAgC;AACnC,WAAO,KAAK,iBAAiB,QAAQ,KAAK;AAAA,EAC5C;AAAA,EAEA,QAAQ,OAAgC;AACtC,WAAO,KAAK,iBAAiB,WAAW,KAAK;AAAA,EAC/C;AAAA,EAEA,QAAQ,OAAgC;AACtC,WAAO,KAAK,iBAAiB,WAAW,KAAK;AAAA,EAC/C;AAAA;AAAA,EAIA,MAAc;AACZ,WAAO,KAAK,gBAAgB,KAAK;AAAA,EACnC;AAAA,EAEA,OAAe;AACb,WAAO,KAAK,gBAAgB,MAAM;AAAA,EACpC;AAAA,EAEA,MAAc;AACZ,WAAO,KAAK,gBAAgB,KAAK;AAAA,EACnC;AAAA,EAEA,SAAiB;AACf,WAAO,KAAK,gBAAgB,QAAQ;AAAA,EACtC;AAAA,EAEA,MAAc;AACZ,WAAO,KAAK,gBAAgB,KAAK;AAAA,EACnC;AAAA,EAEA,OAAe;AACb,WAAO,KAAK,gBAAgB,MAAM;AAAA,EACpC;AAAA,EAEA,MAAc;AACZ,WAAO,KAAK,gBAAgB,KAAK;AAAA,EACnC;AAAA,EAEA,aAAqB;AACnB,WAAO,KAAK,gBAAgB,YAAY;AAAA,EAC1C;AAAA,EAEA,QAAQ,OAAyB;AAC/B,WAAO,KAAK,cAAc,WAAW,KAAK;AAAA,EAC5C;AAAA,EAEA,UAAU,KAAqB;AAC7B,WAAO,KAAK,cAAc,aAAa,GAAG;AAAA,EAC5C;AAAA;AAAA,EAIA,MAAc;AACZ,WAAO,KAAK,gBAAgB,KAAK;AAAA,EACnC;AAAA,EAEA,MAAc;AACZ,WAAO,KAAK,gBAAgB,KAAK;AAAA,EACnC;AAAA,EAEA,MAAc;AACZ,WAAO,KAAK,gBAAgB,KAAK;AAAA,EACnC;AAAA;AAAA,EAIA,MAAc;AACZ,WAAO,KAAK,gBAAgB,KAAK;AAAA,EACnC;AAAA,EAEA,OAAe;AACb,WAAO,KAAK,gBAAgB,MAAM;AAAA,EACpC;AAAA;AAAA,EAIA,UAAU,MAAc,MAAsB;AAC5C,WAAO,KAAK,cAAc,aAAa,MAAM,IAAI;AAAA,EACnD;AAAA,EAEA,OAAO,OAAuB;AAC5B,WAAO,KAAK,iBAAiB,UAAU,KAAK;AAAA,EAC9C;AAAA;AAAA,EAIA,GAAG,OAAgC;AACjC,WAAO,KAAK,iBAAiB,MAAM,KAAK;AAAA,EAC1C;AAAA,EAEA,GAAG,OAAgC;AACjC,WAAO,KAAK,iBAAiB,MAAM,KAAK;AAAA,EAC1C;AAAA,EAEA,GAAG,OAAgC;AACjC,WAAO,KAAK,iBAAiB,MAAM,KAAK;AAAA,EAC1C;AAAA,EAEA,GAAG,OAAgC;AACjC,WAAO,KAAK,iBAAiB,MAAM,KAAK;AAAA,EAC1C;AAAA,EAEA,GAAG,OAAgC;AACjC,WAAO,KAAK,iBAAiB,MAAM,KAAK;AAAA,EAC1C;AAAA,EAEA,GAAG,OAAgC;AACjC,WAAO,KAAK,iBAAiB,MAAM,KAAK;AAAA,EAC1C;AACF;AAxQoB;AAAb,IAAM,SAAN;AC7CA,SAAS,iBAAiB,SAAmB,SAA6B;AAC/E,QAAM,gBAAgB,KAAK,IAAI,QAAQ,QAAQ,QAAQ,MAAM;AAC7D,QAAM,iBAAiB,CAAC,GAAG,MAAM,gBAAgB,QAAQ,MAAM,EAAE,KAAK,CAAC,GAAG,GAAG,OAAO;AACpF,QAAM,iBAAiB,CAAC,GAAG,MAAM,gBAAgB,QAAQ,MAAM,EAAE,KAAK,CAAC,GAAG,GAAG,OAAO;AAEpF,QAAM,eAAyB,CAAA;AAE/B,WAAS,IAAI,GAAG,IAAI,eAAe,KAAK;AACtC,QACE,eAAe,CAAC,MAAM,eAAe,CAAC,KACtC,eAAe,CAAC,MAAM,KACtB,eAAe,CAAC,MAAM,GACtB;AACA,YAAM,IAAI,MAAM,mBAAmB,OAAO,QAAQ,OAAO,EAAE;AAAA,IAC7D;AAEA,iBAAa,KAAK,KAAK,IAAI,eAAe,CAAC,GAAG,eAAe,CAAC,CAAC,CAAC;AAAA,EAClE;AAEA,SAAO;AACT;AApBgB;AAsBT,SAAS,WAAW,OAAiB,iBAAqC;AAC/E,MAAI,MAAM,UAAU,gBAAgB,QAAQ;AAC1C,WAAO;AAAA,EACT;AAEA,SAAO,CAAC,GAAG,MAAM,gBAAgB,SAAS,MAAM,MAAM,EAAE,KAAK,CAAC,GAAG,GAAG,KAAK;AAC3E;AANgB;AAQT,SAAS,oBACd,gBACA,WACAA,QACQ;AACR,MAAI,iBAAiB;AACrB,MAAI,aAAa;AACjB,MAAI,aAAaA;AAEjB,WAAS,IAAI,eAAe,SAAS,GAAG,KAAK,GAAG,KAAK;AACnD,QAAI,eAAe,CAAC,IAAI,GAAG;AACzB,YAAM,YAAY,aAAa,UAAU,CAAC;AAC1C,uBAAiB,iBAAiB,YAAY;AAAA,IAChD;AACA,kBAAc,eAAe,CAAC;AAC9B,iBAAa,KAAK,MAAM,aAAa,UAAU,CAAC,CAAC;AAAA,EACnD;AACA,SAAO;AACT;AAlBgB;AAoBT,SAAS,2BACd,gBACA,WACAA,QACQ;AACR,MAAI,iBAAiB;AACrB,MAAI,aAAa;AACjB,MAAI,aAAaA;AAEjB,WAAS,IAAI,KAAK,UAAU,eAAe,GAAG,KAAK,GAAG,KAAK;AACzD,QAAI,eAAe,CAAC,IAAI,GAAG;AACzB,YAAM,YAAY,aAAa,UAAU,CAAC;AAC1C,uBAAiB,iBAAiB,YAAY;AAAA,IAChD;AACA,iBAAa,aAAa,eAAe,CAAC;AAC1C,iBAAa,KAAK,MAAM,aAAa,UAAU,CAAC,CAAC;AAAA,EACnD;AACA,SAAO;AACT;AAlBgB;AAoBT,SAAS,0CACd,gBACA,MACA,MACA,kBACQ;AACR,MAAI,iBAAiB;AACrB,MAAI,aAAa;AACjB,MAAI,aAAa;AAEjB,MAAI,aAAa;AACjB,MAAI,aAAa;AAEjB,WAAS,IAAI,KAAK,UAAU,eAAe,GAAG,KAAK,GAAG,KAAK;AACzD,UAAM,YAAY,aAAa,eAAe,CAAC;AAC/C,QAAI,KAAK,MAAM;AACb,mBAAa;AAAA,IACf;AACA,QAAI,KAAK,MAAM;AACb,mBAAa;AAAA,IACf;AACA,iBAAa,KAAK,MAAM,aAAa,eAAe,CAAC,CAAC;AAAA,EACxD;AAEA,eAAa;AAEb,WAAS,IAAI,KAAK,UAAU,eAAe,GAAG,KAAK,GAAG,KAAK;AACzD,UAAM,YAAY,aAAa,eAAe,CAAC;AAC/C,QAAI,KAAK,MAAM;AACb,uBAAiB,iBAAiB,aAAa;AAAA,IACjD,WAAW,KAAK,MAAM;AACpB,uBAAiB,iBAAiB,aAAa;AAAA,IACjD,OAAO;AACL,uBAAiB,iBAAiB,YAAY;AAAA,IAChD;AACA,iBAAa,aAAa,eAAe,CAAC;AAC1C,iBAAa,KAAK,MAAM,aAAa,eAAe,CAAC,CAAC;AAAA,EACxD;AAEA,SAAO;AAGT;AA1CgB;ACpEhB,SAASC,oBAAkB,QAAgB;AACzC,SAAO,IAAI,SAA8B;AACvC,UAAM,YAAY,KAAK,aAAa,MAAM,GAAA;AAC1C,WAAO,UAAU,QAAQ,GAAG,IAAI;AAAA,EAClC;AACF;AALSA;AAOT,SAASC,0BAAwB,QAAgB;AAC/C,SAAO,CAAC,MAAuB;AAC7B,QAAI,OAAO,KAAK,UAAU;AACxB,UAAI,IAAI,OAAO,CAAC;AAAA,IAClB;AAEA,UAAM,YAAY,KAAK,aAAa,MAAM,GAAA;AAC1C,WAAO,UAAU,QAAQ,CAAC;AAAA,EAC5B;AACF;AATSA;AAWT,SAASC,2BAAyB,QAAgB;AAChD,SAAO,CAAC,GAAoB,MAAuB;AACjD,QAAI,OAAO,KAAK,UAAU;AACxB,UAAI,IAAI,OAAO,CAAC;AAAA,IAClB;AAEA,QAAI,OAAO,KAAK,UAAU;AACxB,UAAI,IAAI,OAAO,CAAC;AAAA,IAClB;AAEA,UAAM,YAAY,KAAK,aAAa,MAAM,GAAA;AAC1C,WAAO,UAAU,QAAQ,GAAG,CAAC;AAAA,EAC/B;AACF;AAbSA;AAiBF,MAAM,iBAAiBA,2BAAyB,gBAAgB;AAChE,MAAM,kBAAkBA,2BAAyB,iBAAiB;AAIlE,MAAM,MAAMA,2BAAyB,KAAK;AAC1C,MAAM,MAAMA,2BAAyB,KAAK;AAC1C,MAAM,MAAMA,2BAAyB,KAAK;AAC1C,MAAM,MAAMA,2BAAyB,KAAK;AAC1C,MAAM,MAAMA,2BAAyB,KAAK;AAC1C,MAAM,OAAOA,2BAAyB,MAAM;AAC5C,MAAM,UAAUA,2BAAyB,SAAS;AAClD,MAAM,UAAUA,2BAAyB,SAAS;AAIlD,MAAM,MAAMD,0BAAwB,KAAK;AACzC,MAAM,OAAOA,0BAAwB,MAAM;AAC3C,MAAM,MAAMA,0BAAwB,KAAK;AACzC,MAAM,SAASA,0BAAwB,QAAQ;AAC/C,MAAM,MAAMA,0BAAwB,KAAK;AACzC,MAAM,OAAOA,0BAAwB,MAAM;AAC3C,MAAM,MAAMA,0BAAwB,KAAK;AACzC,MAAM,aAAaA,0BAAwB,YAAY;AACvD,MAAM,UAAUD,oBAAkB,SAAS;AAC3C,MAAM,YAAYA,oBAAkB,WAAW;AAI/C,MAAM,MAAMC,0BAAwB,KAAK;AACzC,MAAM,MAAMA,0BAAwB,KAAK;AACzC,MAAM,MAAMA,0BAAwB,KAAK;AAIzC,MAAM,MAAMA,0BAAwB,KAAK;AACzC,MAAM,OAAOA,0BAAwB,MAAM;AAI3C,MAAM,YAAYD,oBAAkB,WAAW;AAC/C,MAAM,SAASE,2BAAyB,QAAQ;AAIhD,MAAM,KAAKA,2BAAyB,IAAI;AACxC,MAAM,KAAKA,2BAAyB,IAAI;AACxC,MAAM,KAAKA,2BAAyB,IAAI;AACxC,MAAM,KAAKA,2BAAyB,IAAI;AACxC,MAAM,KAAKA,2BAAyB,IAAI;AACxC,MAAM,KAAKA,2BAAyB,IAAI;ACzE/C,MAAM,yBAAyB,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACjI,QAAM,MAAM,MAAM,WAAW;AAC7B,WAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,QAAI,CAAC,IAAI;AAAA,EACX;AACA,SAAO;AACT,GAR+B;AAU/B,SAAS,uBAAuB,GAAW,GAAW,YAA8B,MAAc;AAChG,QAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,QAAM,SAAS;AACf,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,IACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,EAAgB;AAEnD;AAbS;AAeF,MAAM,kBAAN,MAAM,wBAAuB,gBAAgB;AAAA,EACxC,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,uBAAuB,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EACtF;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,EAI1B;AACF;AAhBoD;AAA7C,IAAM,iBAAN;AAiBP,kBAAkB,kBAAkB,cAAc;AAElD,MAAM,0BAA0B,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AAClI,QAAM,MAAM,MAAM,WAAW;AAC7B,WAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,QAAI,CAAC,IAAI;AAAA,EACX;AACA,SAAO;AACT,GARgC;AAUhC,SAAS,wBAAwB,GAAW,GAAW,YAA8B,MAAc;AACjG,QAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,QAAM,SAAS;AACf,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,IACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,EAAgB;AAEnD;AAbS;AAeF,MAAM,mBAAN,MAAM,yBAAwB,gBAAgB;AAAA,EACzC,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,wBAAwB,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EACvF;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,EAI1B;AACF;AAhBqD;AAA9C,IAAM,kBAAN;AAiBP,kBAAkB,mBAAmB,eAAe;AAIpD,MAAM,cAAc,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACtH,QAAM,MAAM,MAAM,WAAW;AAC7B,WAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,QAAI,CAAC,IAAI,EAAE,OAAO,IAAI,EAAE,OAAO;AAAA,EACjC;AACA,SAAO;AACT,GARoB;AAUpB,SAAS,YAAY,GAAW,GAAW,YAA8B,MAAc;AACrF,QAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,QAAM,SAAS;AACf,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,IACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,EAAgB;AAEnD;AAbS;AAeF,MAAM,OAAN,MAAM,aAAY,gBAAgB;AAAA,EAC7B,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,YAAY,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC3E;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAGxB,QAAI,SAAS,EAAE;AACf,QAAI,SAAS,EAAE;AAAA,EACjB;AACF;AAjByC;AAAlC,IAAM,MAAN;AAkBP,kBAAkB,OAAO,GAAG;AAE5B,MAAM,cAAc,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACtH,QAAM,MAAM,MAAM,WAAW;AAC7B,WAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,QAAI,CAAC,IAAI,EAAE,OAAO,IAAI,EAAE,OAAO;AAAA,EACjC;AACA,SAAO;AACT,GARoB;AAUpB,SAAS,YAAY,GAAW,GAAW,YAA8B,MAAc;AACrF,QAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,QAAM,SAAS;AACf,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,IACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,EAAgB;AAEnD;AAbS;AAeF,MAAM,OAAN,MAAM,aAAY,gBAAgB;AAAA,EAC7B,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,YAAY,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC3E;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAGxB,QAAI,SAAS,EAAE;AACf,QAAI,SAAS,GAAG,IAAI,IAAI,OAAO,EAAE,CAAC,CAAC;AAAA,EACrC;AACF;AAjByC;AAAlC,IAAM,MAAN;AAkBP,kBAAkB,OAAO,GAAG;AAE5B,MAAM,cAAc,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACtH,QAAM,MAAM,MAAM,WAAW;AAC7B,WAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,QAAI,CAAC,IAAI,EAAE,OAAO,IAAI,EAAE,OAAO;AAAA,EACjC;AACA,SAAO;AACT,GARoB;AAUpB,SAAS,YAAY,GAAW,GAAW,YAA8B,MAAc;AACrF,QAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,QAAM,SAAS;AACf,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,IACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,EAAgB;AAEnD;AAbS;AAeF,MAAM,OAAN,MAAM,aAAY,gBAAgB;AAAA,EAC7B,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,YAAY,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC3E;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAGxB,QAAI,SAAS,GAAG,IAAI,CAAC,CAAC;AACtB,QAAI,SAAS,GAAG,IAAI,CAAC,CAAC;AAAA,EACxB;AACF;AAjByC;AAAlC,IAAM,MAAN;AAkBP,kBAAkB,OAAO,GAAG;AAE5B,MAAM,cAAc,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACtH,QAAM,MAAM,MAAM,WAAW;AAC7B,WAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,QAAI,CAAC,IAAI,EAAE,OAAO,IAAI,EAAE,OAAO;AAAA,EACjC;AACA,SAAO;AACT,GARoB;AAUpB,SAAS,YAAY,GAAW,GAAW,YAA8B,MAAc;AACrF,QAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,QAAM,SAAS;AACf,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,IACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,EAAgB;AAEnD;AAbS;AAeF,MAAM,OAAN,MAAM,aAAY,gBAAgB;AAAA,EAC7B,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,YAAY,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC3E;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAGxB,QAAI,SAAS,GAAG,IAAI,CAAC,CAAC;AACtB,QAAI,SAAS,GAAG,IAAI,CAAC,EAAE,IAAI,IAAI,OAAO,EAAE,CAAC,EAAE,IAAI,CAAC,EAAE,IAAI,CAAC,CAAC;AAAA,EAC1D;AACF;AAjByC;AAAlC,IAAM,MAAN;AAkBP,kBAAkB,OAAO,GAAG;AAE5B,MAAM,cAAc,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACtH,QAAM,MAAM,MAAM,WAAW;AAC7B,WAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,QAAI,CAAC,IAAI,KAAK,IAAI,EAAE,OAAO,GAAG,EAAE,OAAO,CAAC;AAAA,EAC1C;AACA,SAAO;AACT,GARoB;AAUpB,SAAS,YAAY,GAAW,GAAW,YAA8B,MAAc;AACrF,QAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,QAAM,SAAS;AACf,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,IACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,EAAgB;AAEnD;AAbS;AAeF,MAAM,OAAN,MAAM,aAAY,gBAAgB;AAAA,EAC7B,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,YAAY,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC3E;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAGxB,QAAI,SAAS,GAAG,IAAI,CAAC,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,IAAI,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;AACvD,QAAI,SAAS,GAAG,IAAI,EAAE,IAAI,CAAC,CAAC,EAAE,IAAI,EAAE,IAAA,CAAK,CAAC;AAAA,EAC5C;AACF;AAjByC;AAAlC,IAAM,MAAN;AAkBP,kBAAkB,OAAO,GAAG;AAE5B,MAAM,eAAe,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACvH,QAAM,MAAM,MAAM,WAAW;AAC7B,WAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,QAAI,CAAC,IAAI,EAAE,OAAO,IAAI,EAAE,OAAO;AAAA,EACjC;AACA,SAAO;AACT,GARqB;AAUrB,SAAS,aAAa,GAAW,GAAW,YAA8B,MAAc;AACtF,QAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,QAAM,SAAS;AACf,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,IACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,EAAgB;AAEnD;AAbS;AAeF,MAAM,QAAN,MAAM,cAAa,gBAAgB;AAAA,EAC9B,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,aAAa,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC5E;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAGxB,QAAI,SAAS,EAAE;AAAA,EACjB;AACF;AAhB0C;AAAnC,IAAM,OAAN;AAiBP,kBAAkB,QAAQ,IAAI;AAE9B,MAAM,kBAAkB,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AAC1H,QAAM,MAAM,MAAM,WAAW;AAC7B,WAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,QAAI,CAAC,IAAI,KAAK,IAAI,EAAE,OAAO,GAAG,EAAE,OAAO,CAAC;AAAA,EAC1C;AACA,SAAO;AACT,GARwB;AAUxB,SAAS,gBAAgB,GAAW,GAAW,YAA8B,MAAc;AACzF,QAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,QAAM,SAAS;AACf,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,IACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,EAAgB;AAEnD;AAbS;AAeF,MAAM,WAAN,MAAM,iBAAgB,gBAAgB;AAAA,EACjC,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,gBAAgB,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC/E;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAGxB,QAAI,SAAS,GAAG,IAAI,EAAE,GAAG,CAAC,CAAC,CAAC;AAC5B,QAAI,SAAS,GAAG,IAAI,EAAE,GAAG,CAAC,CAAC,CAAC;AAAA,EAC9B;AACF;AAjB6C;AAAtC,IAAM,UAAN;AAkBP,kBAAkB,WAAW,OAAO;AAEpC,MAAM,kBAAkB,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AAC1H,QAAM,MAAM,MAAM,WAAW;AAC7B,WAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,QAAI,CAAC,IAAI,KAAK,IAAI,EAAE,OAAO,GAAG,EAAE,OAAO,CAAC;AAAA,EAC1C;AACA,SAAO;AACT,GARwB;AAUxB,SAAS,gBAAgB,GAAW,GAAW,YAA8B,MAAc;AACzF,QAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,QAAM,SAAS;AACf,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,IACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,EAAgB;AAEnD;AAbS;AAeF,MAAM,WAAN,MAAM,iBAAgB,gBAAgB;AAAA,EACjC,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,gBAAgB,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC/E;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAGxB,QAAI,SAAS,GAAG,IAAI,EAAE,GAAG,CAAC,CAAC,CAAC;AAC5B,QAAI,SAAS,GAAG,IAAI,EAAE,GAAG,CAAC,CAAC,CAAC;AAAA,EAC9B;AACF;AAjB6C;AAAtC,IAAM,UAAN;AAkBP,kBAAkB,WAAW,OAAO;AAGpC,SAAS,eAAe,GAAW,GAAW,YAA8B,MAAc;AACxF,QAAM,OAAO,IAAI,MAAM,EAAE,YAAY;AACrC,WAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACpC,SAAK,CAAC,IAAI,KAAK,IAAI,EAAE,KAAK,CAAC,GAAG,CAAC;AAAA,EACjC;AACA,SAAO,IAAI;AAAA,IACT;AAAA,IACA,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,EAAM;AAE3C;AAVS;AAWF,MAAM,UAAN,MAAM,gBAAe,UAAU;AAAA,EAC5B;AAAA,EACE,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AACvB,WAAK,IAAI;AAAA,IACX;AAEA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,eAAe,GAAG,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC3D;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,IAAI,KAAK;AACf,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,QAAI,SAAS,GAAG,IAAI,CAAC,EAAE,IAAI,EAAE,IAAI,IAAI,CAAC,CAAC,CAAC;AAAA,EAC1C;AACF;AAnBsC;AAA/B,IAAM,SAAN;AAoBP,kBAAkB,UAAU,MAAM;AAMlC,MAAM,cAAc,gCAAU,GAAa,QAAgB;AACzD,QAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,QAAI,CAAC,IAAI,KAAK,IAAI,EAAE,CAAC,CAAC;AAAA,EACxB;AACA,SAAO;AACT,GANoB;AAQpB,SAAS,YAAY,GAAW,YAA8B,MAAc;AAC1E,QAAM,SAAS;AACf,QAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,MAAM;AAAA,IACrB,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,EAAM;AAE3C;AATS;AAWF,MAAM,OAAN,MAAM,aAAY,eAAe;AAAA,EAC5B,SAAS,GAAmB;AACpC,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,YAAY,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,EACrD;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,QAAI,SAAS,IAAI,OAAO,CAAC,EAAE,IAAI,CAAC,CAAC;AAAA,EACnC;AACF;AAfwC;AAAjC,IAAM,MAAN;AAgBP,kBAAkB,OAAO,GAAG;AAI5B,MAAM,eAAe,gCAAU,GAAa,QAAgB;AAC1D,QAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,QAAI,CAAC,IAAI,KAAK,KAAK,EAAE,CAAC,CAAC;AAAA,EACzB;AACA,SAAO;AACT,GANqB;AAQrB,SAAS,aAAa,GAAW,YAA8B,MAAc;AAC3E,QAAM,SAAS;AACf,QAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,MAAM;AAAA,IACrB,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,EAAM;AAE3C;AATS;AAWF,MAAM,QAAN,MAAM,cAAa,eAAe;AAAA,EAC7B,SAAS,GAAmB;AACpC,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,aAAa,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,EACtD;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,QAAI,SAAS,IAAI,OAAO,CAAC,EAAE,IAAI,EAAE,KAAA,CAAM,EAAE,IAAI,CAAC,CAAC;AAAA,EACjD;AACF;AAfyC;AAAlC,IAAM,OAAN;AAgBP,kBAAkB,QAAQ,IAAI;AAI9B,MAAM,cAAc,gCAAU,GAAa,QAAgB;AACzD,QAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,QAAI,CAAC,IAAI,KAAK,IAAI,EAAE,CAAC,CAAC;AAAA,EACxB;AACA,SAAO;AACT,GANoB;AAQpB,SAAS,YAAY,GAAW,YAA8B,MAAc;AAC1E,QAAM,SAAS;AACf,QAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,MAAM;AAAA,IACrB,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,EAAM;AAE3C;AATS;AAWF,MAAM,OAAN,MAAM,aAAY,eAAe;AAAA,EAC5B,SAAS,GAAmB;AACpC,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,YAAY,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,EACrD;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,QAAI,SAAS,GAAG,IAAI,EAAE,IAAA,CAAK,CAAC;AAAA,EAC9B;AACF;AAfwC;AAAjC,IAAM,MAAN;AAgBP,kBAAkB,OAAO,GAAG;AAI5B,MAAM,iBAAiB,gCAAU,GAAa,QAAgB;AAC5D,QAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,QAAI,CAAC,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC;AAAA,EACrB;AACA,SAAO;AACT,GANuB;AAQvB,SAAS,eAAe,GAAW,YAA8B,MAAc;AAC7E,QAAM,SAAS;AACf,QAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,MAAM;AAAA,IACrB,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,EAAM;AAE3C;AATS;AAWF,MAAM,UAAN,MAAM,gBAAe,eAAe;AAAA,EAC/B,SAAS,GAAmB;AACpC,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,eAAe,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,EACxD;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,QAAI,SAAS,GAAG,IAAI,CAAC,EAAE,IAAI,IAAI,OAAO,CAAC,CAAC,CAAC;AAAA,EAC3C;AACF;AAf2C;AAApC,IAAM,SAAN;AAgBP,kBAAkB,UAAU,MAAM;AAIlC,MAAM,cAAc,gCAAU,GAAa,QAAgB;AACzD,QAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,QAAI,CAAC,IAAI,KAAK,IAAI,EAAE,CAAC,CAAC;AAAA,EACxB;AACA,SAAO;AACT,GANoB;AAQpB,SAAS,YAAY,GAAW,YAA8B,MAAc;AAC1E,QAAM,SAAS;AACf,QAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,MAAM;AAAA,IACrB,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,EAAM;AAE3C;AATS;AAWF,MAAM,OAAN,MAAM,aAAY,eAAe;AAAA,EAC5B,SAAS,GAAmB;AACpC,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,YAAY,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,EACrD;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,QAAI,SAAS,GAAG,IAAIC,KAAgB,CAAC,CAAC,CAAC;AAAA,EACzC;AACF;AAfwC;AAAjC,IAAM,MAAN;AAgBP,kBAAkB,OAAO,GAAG;AAI5B,MAAM,eAAe,gCAAU,GAAa,QAAgB;AAC1D,QAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,QAAI,CAAC,IAAI,KAAK,KAAK,EAAE,CAAC,CAAC;AAAA,EACzB;AACA,SAAO;AACT,GANqB;AAQrB,SAAS,aAAa,GAAW,YAA8B,MAAc;AAC3E,QAAM,SAAS;AACf,QAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,MAAM;AAAA,IACrB,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,EAAM;AAE3C;AATS;AAWF,MAAM,QAAN,MAAM,cAAa,eAAe;AAAA,EAC7B,SAAS,GAAmB;AACpC,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,aAAa,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,EACtD;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAAA,EAIrB;AACF;AAfyC;AAAlC,IAAM,OAAN;AAgBP,kBAAkB,QAAQ,IAAI;AAI9B,MAAM,cAAc,gCAAU,GAAa,QAAgB;AACzD,QAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,QAAI,CAAC,IAAI,CAAC,EAAE,CAAC;AAAA,EACf;AACA,SAAO;AACT,GANoB;AAQpB,SAAS,YAAY,GAAW,YAA8B,MAAc;AAC1E,QAAM,SAAS;AACf,QAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,MAAM;AAAA,IACrB,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,EAAM;AAE3C;AATS;AAWF,MAAM,OAAN,MAAM,aAAY,eAAe;AAAA,EAC5B,SAAS,GAAmB;AACpC,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,YAAY,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,EACrD;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,QAAI,SAAS,GAAG,IAAI,IAAI,OAAO,EAAE,CAAC,CAAC;AAAA,EACrC;AACF;AAfwC;AAAjC,IAAM,MAAN;AAgBP,kBAAkB,OAAO,GAAG;AAI5B,MAAM,qBAAqB,gCAAU,GAAa,QAAgB;AAChE,QAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,QAAI,CAAC,IAAI,IAAI,EAAE,CAAC;AAAA,EAClB;AACA,SAAO;AACT,GAN2B;AAQ3B,SAAS,mBAAmB,GAAW,YAA8B,MAAc;AACjF,QAAM,SAAS;AACf,QAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,MAAM;AAAA,IACrB,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,EAAM;AAE3C;AATS;AAWF,MAAM,cAAN,MAAM,oBAAmB,eAAe;AAAA,EACnC,SAAS,GAAmB;AACpC,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,mBAAmB,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC5D;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,QAAI,SAAS,GAAG,IAAI,EAAE,IAAI,EAAE,CAAC,CAAC;AAAA,EAChC;AACF;AAf+C;AAAxC,IAAM,aAAN;AAgBP,kBAAkB,cAAc,UAAU;AAEnC,MAAM,WAAN,MAAM,iBAAgB,UAAU;AAAA,EAC3B,SAAS,GAAW,OAAiB;AAC7C,UAAM,kBAAkB,EAAE,WAAA;AAC1B,UAAM,gBAAgB,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAE7D,QAAI,oBAAoB,eAAe;AACrC,YAAM,IAAI,MAAM,qBAAqB,EAAE,QAAQ,UAAU,KAAK;AAAA,IAChE;AAEA,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,QAAI,EAAE,SAAS;AACb,WAAK,eAAe,KAAK,EAAE,OAAO;AAAA,IACpC,WAAW,EAAE,eAAe;AAC1B,YAAM,MAAM,IAAI,eAAA;AAChB,UAAI,WAAW;AACf,WAAK,eAAe,KAAK,GAAG;AAAA,IAC9B,OAAO;AACL,WAAK,eAAe,KAAK,MAAM;AAAA,IACjC;AAEA,WAAO,IAAI;AAAA,MACT,EAAE;AAAA,MACF,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAW,EAAE,gBAAgB,OAAO,MAAM,MAAA;AAAA,IAAM;AAAA,EAEtD;AAAA,EACU,UAAU,IAAY;AAC9B,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,QAAI,SAAS,GAAG,QAAQ,EAAE,KAAK,CAAC;AAAA,EAClC;AACF;AAnCuC;AAAhC,IAAM,UAAN;AAoCP,kBAAkB,WAAW,OAAO;AAE7B,MAAM,aAAN,MAAM,mBAAkB,UAAU;AAAA,EAC7B,SAAS,GAAW,KAAa;AACzC,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,QAAI,EAAE,SAAS;AACb,WAAK,eAAe,KAAK,EAAE,OAAO;AAAA,IACpC,WAAW,EAAE,eAAe;AAC1B,YAAM,MAAM,IAAI,eAAA;AAChB,UAAI,WAAW;AACf,WAAK,eAAe,KAAK,GAAG;AAAA,IAC9B,OAAO;AACL,WAAK,eAAe,KAAK,MAAM;AAAA,IACjC;AAEA,QAAI,MAAM,GAAG;AACX,aAAO,EAAE,MAAM,SAAS;AAAA,IAC1B;AAEA,UAAM,QAAQ,CAAC,GAAG,EAAE,KAAK;AACzB,UAAM,OAAO,KAAK,GAAG,CAAC;AAEtB,WAAO,IAAI;AAAA,MACT,EAAE;AAAA,MACF,EAAE,eAAe,EAAE,cAAA;AAAA,MACnB,EAAE,WAAW,EAAE,gBAAgB,OAAO,MAAM,MAAA;AAAA,IAAM;AAAA,EAEtD;AAAA,EACU,UAAU,IAAY;AAC9B,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,QAAI,SAAS,GAAG,QAAQ,EAAE,KAAK,CAAC;AAAA,EAClC;AACF;AAnCyC;AAAlC,IAAM,YAAN;AAoCP,kBAAkB,aAAa,SAAS;AAMxC,MAAM,cAAc,gCAAU,GAAa,QAAgB;AACzD,QAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,QAAI,CAAC,IAAI,KAAK,IAAI,EAAE,CAAC,CAAC;AAAA,EACxB;AACA,SAAO;AACT,GANoB;AAQpB,SAAS,YAAY,GAAW,YAA8B,MAAc;AAC1E,QAAM,SAAS;AACf,QAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,MAAM;AAAA,IACrB,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,EAAM;AAE3C;AATS;AAWF,MAAM,OAAN,MAAM,aAAY,eAAe;AAAA,EAC5B,SAAS,GAAmB;AACpC,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,YAAY,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,EACrD;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,QAAI,SAAS,GAAG,IAAI,EAAE,IAAA,CAAK,CAAC;AAAA,EAC9B;AACF;AAfwC;AAAjC,IAAM,MAAN;AAgBP,kBAAkB,OAAO,GAAG;AAI5B,MAAM,cAAc,gCAAU,GAAa,QAAgB;AACzD,QAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,QAAI,CAAC,IAAI,KAAK,IAAI,EAAE,CAAC,CAAC;AAAA,EACxB;AACA,SAAO;AACT,GANoB;AAQpB,SAAS,YAAY,GAAW,YAA8B,MAAc;AAC1E,QAAM,SAAS;AACf,QAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,MAAM;AAAA,IACrB,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,EAAM;AAE3C;AATS;AAWF,MAAM,OAAN,MAAM,aAAY,eAAe;AAAA,EAC5B,SAAS,GAAmB;AACpC,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,YAAY,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,EACrD;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,QAAI,SAAS,GAAG,IAAI,EAAE,MAAM,IAAA,CAAK,CAAC;AAAA,EACpC;AACF;AAfwC;AAAjC,IAAM,MAAN;AAgBP,kBAAkB,OAAO,GAAG;AAI5B,MAAM,cAAc,gCAAU,GAAa,QAAgB;AACzD,QAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,QAAI,CAAC,IAAI,KAAK,IAAI,EAAE,CAAC,CAAC;AAAA,EACxB;AACA,SAAO;AACT,GANoB;AAQpB,SAAS,YAAY,GAAW,YAA8B,MAAc;AAC1E,QAAM,SAAS;AACf,QAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,MAAM;AAAA,IACrB,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,EAAM;AAE3C;AATS;AAWF,MAAM,OAAN,MAAM,aAAY,eAAe;AAAA,EAC5B,SAAS,GAAmB;AACpC,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,YAAY,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,EACrD;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,QAAI,SAAS,GAAG,IAAI,EAAE,MAAM,IAAI,EAAE,CAAC,CAAC;AAAA,EACtC;AACF;AAfwC;AAAjC,IAAM,MAAN;AAgBP,kBAAkB,OAAO,GAAG;AAI5B,SAAS,YAAY,GAAW,YAA8B,MAAc;AAC1E,SAAO,IAAI;AAAA,IACT,EAAE,UAAU,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAAA,IAC7C,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,UAAA;AAAA,EAAqB;AAE3B;AANS;AASF,MAAM,OAAN,MAAM,aAAY,eAAe;AAAA,EAC5B,SAAS,GAAmB;AACpC,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,YAAY,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,EACrD;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAM,SAAS,IAAI,OAAO,MAAM,EAAE,WAAA,CAAY,EAAE,KAAK,GAAG,KAAA,CAAM,CAAC;AAC/D,QAAI,SAAS,MAAM;AAAA,EACrB;AACF;AAhBwC;AAAjC,IAAM,MAAN;AAiBP,kBAAkB,OAAO,GAAG;AAE5B,SAAS,aAAa,GAAW,YAA8B,MAAc;AAC3E,SAAO,IAAI;AAAA,IACT,EAAE,QAAA,EAAU,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC,IAAI,EAAE,WAAA;AAAA,IACnD,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,UAAA;AAAA,EAAqB;AAE3B;AANS;AASF,MAAM,QAAN,MAAM,cAAa,eAAe;AAAA,EAC7B,SAAS,GAAmB;AACpC,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,aAAa,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,EACtD;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,UAAM,SAAS,IAAI,OAAO,MAAM,EAAE,WAAA,CAAY,EAAE,KAAK,GAAG,KAAA,IAAS,EAAE,WAAA,CAAY,CAAC;AAChF,QAAI,SAAS,MAAM;AAAA,EACrB;AACF;AAhByC;AAAlC,IAAM,OAAN;AAiBP,kBAAkB,QAAQ,IAAI;AAI9B,SAAS,kBACP,GACA,MACA,MACA,YAA8B,MACtB;AACR,QAAM,eAAe,CAAC,GAAG,EAAE,KAAK;AAChC,GAAC,aAAa,IAAI,GAAG,aAAa,IAAI,CAAC,IAAI,CAAC,aAAa,IAAI,GAAG,aAAa,IAAI,CAAC;AAClF,QAAM,OAAO,EAAE,WAAA;AACf,QAAM,OAAO,IAAI,MAAM,IAAI;AAE3B,QAAM,YAAY,IAAI,MAAM,EAAE,MAAM,MAAM;AAC1C,QAAM,cAAc,IAAI,MAAM,aAAa,MAAM;AACjD,WAAS,IAAI,EAAE,MAAM,SAAS,GAAG,IAAI,GAAG,KAAK,GAAG,KAAK;AACnD,cAAU,CAAC,IAAI;AACf,SAAK,EAAE,MAAM,CAAC;AAAA,EAChB;AACA,WAAS,IAAI,aAAa,SAAS,GAAG,IAAI,GAAG,KAAK,GAAG,KAAK;AACxD,gBAAY,CAAC,IAAI;AACjB,SAAK,aAAa,CAAC;AAAA,EACrB;AAEA,WAAQ,IAAE,GAAG,IAAE,MAAM,KAAK;AACxB,QAAI,MAAM;AACV,QAAI,YAAY;AAChB,aAAS,IAAI,GAAG,IAAI,aAAa,QAAQ,KAAK;AAC5C,YAAM,SAAS,YAAY,CAAC;AAC5B,YAAM,QAAQ,KAAK,MAAM,MAAM,MAAM;AACrC,aAAO;AAEP,UAAI,UAAU;AACd,UAAI,MAAM,KAAM,WAAU;AAAA,eACjB,MAAM,KAAM,WAAU;AAE/B,mBAAa,QAAQ,UAAU,OAAO;AAAA,IACxC;AACA,SAAK,CAAC,IAAI,EAAE,KAAK,SAAS;AAAA,EAC5B;AAEA,SAAO,IAAI;AAAA,IACT;AAAA,IACA,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,WAAsB,OAAO,aAAA;AAAA,EAAa;AAEhD;AA5CS;AA6CF,MAAM,aAAN,MAAM,mBAAkB,UAAU;AAAA,EAC/B;AAAA,EACA;AAAA,EACE,SAAS,GAAW,MAAc,MAAsB;AAChE,QAAI,EAAE,eAAe;AACjB,WAAK,gBAAgB,CAAC,CAAC;AACvB,WAAK,OAAO;AACZ,WAAK,OAAO;AAAA,IAChB;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,kBAAkB,GAAG,MAAM,MAAM,IAAI;AAAA,EAC9C;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,OAAO,KAAK;AAClB,UAAM,OAAO,KAAK;AAClB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,QAAI,SAAS,GAAG,UAAU,MAAM,IAAI,CAAC;AAAA,EACvC;AACF;AArByC;AAAlC,IAAM,YAAN;AAsBP,kBAAkB,aAAa,SAAS;AAExC,SAAS,eAAe,GAAW,GAAW,YAA8B,MAAc;AACxF,MAAI,EAAE,MAAM,UAAU,KAAK,EAAE,MAAM,UAAU,GAAG;AAC9C,WAAO,EAAE,IAAI,CAAC,EAAE,IAAA;AAAA,EAClB;AAEA,QAAM,OAAO,EAAE,MAAM,UAAU;AAC/B,QAAM,OAAO,EAAE,MAAM,UAAU;AAE/B,QAAM,UAAU,OAAO,CAAC,GAAG,EAAE,MAAM,CAAC,CAAC,IAAI,EAAE;AAC3C,QAAM,UAAU,OAAO,CAAC,EAAE,MAAM,CAAC,GAAG,CAAC,IAAI,EAAE;AAE3C,MAAI,QAAQ,QAAQ,SAAS,CAAC,KAAK,QAAQ,QAAQ,SAAS,CAAC,GAAG;AAC9D,UAAM,IAAI,MAAM,qBAAqB,EAAE,QAAQ,UAAU,EAAE,KAAK;AAAA,EAClE;AAEA,QAAM,kBAAkB,iBAAiB,QAAQ,MAAM,GAAG,EAAE,GAAG,QAAQ,MAAM,GAAG,EAAE,CAAC,EAAE,OAAO;AAAA,IAC1F,QAAQ,QAAQ,SAAS,CAAC;AAAA,IAC1B,QAAQ,QAAQ,SAAS,CAAC;AAAA,EAAA,CAC3B;AAED,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AACrE,QAAM,OAAO,IAAI,MAAM,WAAW,EAAE,KAAK,CAAC;AAE1C,QAAM,iBAAiB,WAAW,SAAS,eAAe;AAC1D,QAAM,iBAAiB,WAAW,SAAS,eAAe;AAE1D,QAAM,QAAQ,gBAAgB,gBAAgB,SAAS,CAAC;AACxD,QAAM,QAAQ,gBAAgB,gBAAgB,SAAS,CAAC;AACxD,QAAM,QAAQ,QAAQ,QAAQ,SAAS,CAAC;AAExC,WAAS,IAAI,GAAG,IAAI,aAAa,KAAK;AACpC,UAAM,SAAS,KAAK,QAAQ;AAC5B,UAAM,IAAI,KAAK,MAAM,SAAS,KAAK;AACnC,UAAM,IAAI,SAAS;AAEnB,QAAI,SAAS,oBAAoB,gBAAgB,iBAAiB,IAAI,CAAC;AACvE,QAAI,SAAS,oBAAoB,gBAAgB,iBAAiB,IAAI,IAAI,KAAK;AAE/E,QAAIC,OAAM;AACV,aAAQ,IAAE,GAAG,IAAI,OAAO,KAAK;AAC3B,MAAAA,QAAO,EAAE,KAAK,SAAS,CAAC,IAAI,EAAE,KAAK,SAAS,IAAI,KAAK;AAAA,IACvD;AACA,SAAK,CAAC,IAAIA;AAAA,EACZ;AAEA,MAAI,kCAAkC,CAAC,GAAG,eAAe;AAEzD,MAAI,MAAM;AACR,sCAAkC,gCAC/B,MAAM,GAAG,EAAE,EACX,OAAO,CAAC,gBAAgB,gBAAgB,SAAS,CAAC,CAAC,CAAC;AAAA,EACzD;AAEA,MAAI,MAAM;AACR,sCAAkC,gCAAgC,MAAM,GAAG,EAAE;AAAA,EAC/E;AAEA,SAAO,IAAI;AAAA,IACT;AAAA,IACA,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gCAAA;AAAA,EAAgC;AAEnE;AA9DS;AAgEF,MAAM,UAAN,MAAM,gBAAe,gBAAgB;AAAA,EAChC,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,eAAe,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC9E;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,EAI1B;AACF;AAhB4C;AAArC,IAAM,SAAN;AAiBP,kBAAkB,UAAU,MAAM;AAIlC,MAAM,aAAa,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACrH,QAAM,MAAM,MAAM,WAAW;AAC7B,WAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,QAAI,CAAC,IAAK,EAAE,OAAO,IAAI,EAAE,OAAO,IAAK,IAAI;AAAA,EAC3C;AACA,SAAO;AACT,GARmB;AAUnB,SAAS,WAAW,GAAW,GAAW,YAA8B,MAAc;AACpF,QAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,QAAM,SAAS;AACf,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,IACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,EAAgB;AAEnD;AAbS;AAeF,MAAM,MAAN,MAAM,YAAW,gBAAgB;AAAA,EAC5B,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,WAAW,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC1E;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,EAI1B;AACF;AAhBwC;AAAjC,IAAM,KAAN;AAiBP,kBAAkB,MAAM,EAAE;AAE1B,MAAM,aAAa,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACrH,QAAM,MAAM,MAAM,WAAW;AAC7B,WAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,QAAI,CAAC,IAAK,EAAE,OAAO,IAAI,EAAE,OAAO,IAAK,IAAI;AAAA,EAC3C;AACA,SAAO;AACT,GARmB;AAUnB,SAAS,WAAW,GAAW,GAAW,YAA8B,MAAc;AACpF,QAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,QAAM,SAAS;AACf,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,IACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,EAAgB;AAEnD;AAbS;AAeF,MAAM,MAAN,MAAM,YAAW,gBAAgB;AAAA,EAC5B,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,WAAW,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC1E;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,EAI1B;AACF;AAhBwC;AAAjC,IAAM,KAAN;AAiBP,kBAAkB,MAAM,EAAE;AAE1B,MAAM,aAAa,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACrH,QAAM,MAAM,MAAM,WAAW;AAC7B,WAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,QAAI,CAAC,IAAK,EAAE,OAAO,KAAK,EAAE,OAAO,IAAK,IAAI;AAAA,EAC5C;AACA,SAAO;AACT,GARmB;AAUnB,SAAS,WAAW,GAAW,GAAW,YAA8B,MAAc;AACpF,QAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,QAAM,SAAS;AACf,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,IACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,EAAgB;AAEnD;AAbS;AAeF,MAAM,MAAN,MAAM,YAAW,gBAAgB;AAAA,EAC5B,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,WAAW,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC1E;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,EAI1B;AACF;AAhBwC;AAAjC,IAAM,KAAN;AAiBP,kBAAkB,MAAM,EAAE;AAE1B,MAAM,aAAa,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACrH,QAAM,MAAM,MAAM,WAAW;AAC7B,WAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,QAAI,CAAC,IAAK,EAAE,OAAO,KAAK,EAAE,OAAO,IAAK,IAAI;AAAA,EAC5C;AACA,SAAO;AACT,GARmB;AAUnB,SAAS,WAAW,GAAW,GAAW,YAA8B,MAAc;AACpF,QAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,QAAM,SAAS;AACf,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,IACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,EAAgB;AAEnD;AAbS;AAeF,MAAM,MAAN,MAAM,YAAW,gBAAgB;AAAA,EAC5B,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,WAAW,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC1E;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,EAI1B;AACF;AAhBwC;AAAjC,IAAM,KAAN;AAiBP,kBAAkB,MAAM,EAAE;AAE1B,MAAM,aAAa,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACrH,QAAM,MAAM,MAAM,WAAW;AAC7B,WAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,QAAI,CAAC,IAAK,EAAE,OAAO,KAAK,EAAE,OAAO,IAAK,IAAI;AAAA,EAC5C;AACA,SAAO;AACT,GARmB;AAUnB,SAAS,WAAW,GAAW,GAAW,YAA8B,MAAc;AACpF,QAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,QAAM,SAAS;AACf,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,IACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,EAAgB;AAEnD;AAbS;AAeF,MAAM,MAAN,MAAM,YAAW,gBAAgB;AAAA,EAC5B,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,WAAW,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC1E;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,EAI1B;AACF;AAhBwC;AAAjC,IAAM,KAAN;AAiBP,kBAAkB,MAAM,EAAE;AAE1B,MAAM,aAAa,gCAAU,GAAa,IAAc,GAAa,IAAc,KAAe,aAAqB;AACrH,QAAM,MAAM,MAAM,WAAW;AAC7B,WAAQ,IAAI,GAAG,IAAI,aAAa,KAAK;AACnC,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,UAAM,UAAU,oBAAoB,IAAI,KAAK,CAAC;AAC9C,QAAI,CAAC,IAAK,EAAE,OAAO,KAAK,EAAE,OAAO,IAAK,IAAI;AAAA,EAC5C;AACA,SAAO;AACT,GARmB;AAUnB,SAAS,WAAW,GAAW,GAAW,YAA8B,MAAc;AACpF,QAAM,kBAAkB,iBAAiB,EAAE,OAAO,EAAE,KAAK;AACzD,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAC1D,QAAM,iBAAiB,WAAW,EAAE,OAAO,eAAe;AAE1D,QAAM,SAAS;AACf,QAAM,cAAc,gBAAgB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAErE,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,gBAAgB,EAAE,MAAM,gBAAgB,iBAAiB,WAAW;AAAA,IACnF,EAAE,eAAe,EAAE,iBAAiB,EAAE,cAAA;AAAA,IACtC,EAAE,WAAsB,OAAO,gBAAA;AAAA,EAAgB;AAEnD;AAbS;AAeF,MAAM,MAAN,MAAM,YAAW,gBAAgB;AAAA,EAC5B,SAAS,GAAW,GAAmB;AAC/C,QAAI,EAAE,iBAAiB,EAAE,eAAe;AACtC,WAAK,gBAAgB,CAAC,GAAG,CAAC;AAAA,IAC5B;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,WAAW,GAAG,GAAG,EAAE,iBAAiB,EAAE,gBAAgB,OAAO,IAAI;AAAA,EAC1E;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,GAAG,CAAC,IAAI,KAAK;AACpB,UAAM,CAAC,KAAK,GAAG,IAAI,KAAK;AAAA,EAI1B;AACF;AAhBwC;AAAjC,IAAM,KAAN;AAiBP,kBAAkB,MAAM,EAAE;AC38CnB,SAAS,oBAAoB,MAAuC;AACzE,MAAI,MAAM,QAAQ,KAAK,CAAC,CAAC,GAAG;AAC1B,WAAO,KAAK,CAAC;AAAA,EACf;AAEA,SAAO;AACT;AANgB;ACKT,SAAS,SAAS,MAAqC;AAC5D,QAAM,QAAQ,oBAAoB,IAAI;AACtC,QAAM,SAAS,IAAI,OAAO,MAAM,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,KAAK,KAAK,OAAA,CAAQ,CAAC;AACrF,SAAO,QAAQ;AACf,SAAO;AACT;AALgB;AAOT,SAAS,QAAQ,MAAqC;AAC3D,QAAM,QAAQ,oBAAoB,IAAI;AACtC,QAAM,SAAS,IAAI,OAAO,MAAM,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,KAAK,KAAK,OAAA,CAAQ,CAAC;AACrF,SAAO,QAAQ;AACf,SAAO;AACT;AALgB;AAOT,SAAS,QAAQ,KAAa,MAAc,OAAyB;AAC1E,QAAM,SAAS,IAAI;AAAA,IACjB,MAAM,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,KAAK,KAAK,MAAM,KAAK,OAAA,KAAY,OAAO,OAAO,GAAG,CAAC;AAAA,EAAA;AAE7F,SAAO,QAAQ;AACf,SAAO;AACT;AANgB;AChBT,SAAS,QAAQ,MAAqC;AAC3D,QAAM,QAAQ,oBAAoB,IAAI;AACtC,QAAM,SAAS,IAAI,OAAO,MAAM,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;AACzE,SAAO,QAAQ;AACf,SAAO;AACT;AALgB;AAOT,SAAS,SAAS,MAAqC;AAC5D,QAAM,QAAQ,oBAAoB,IAAI;AACtC,QAAM,SAAS,IAAI,OAAO,MAAM,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;AACzE,SAAO,QAAQ;AACf,SAAO;AACT;AALgB;AAOT,SAAS,UAAU,QAAwB;AAChD,SAAO,KAAK,OAAO,KAAK;AAC1B;AAFgB;AAIT,SAAS,WAAW,QAAwB;AACjD,SAAO,MAAM,OAAO,KAAK;AAC3B;AAFgB;ACnBT,SAAS,SAAS,OAAe,KAAa,OAAe;AAClE,QAAM,OAAO,CAAA;AACb,QAAM,QAAQ,MAAM,UAAU,QAAQ;AACtC,WAAS,IAAI,GAAG,IAAI,QAAQ,GAAG,KAAK;AAClC,SAAK,KAAK,QAAQ,IAAI,IAAI;AAAA,EAC5B;AACA,OAAK,KAAK,GAAG;AACb,SAAO,IAAI,OAAO,IAAI;AACxB;AARgB;AAUT,SAAS,OAAO,OAAe,MAAc,QAAW,OAAe,GAAG;AAC/E,QAAM,OAAO,CAAA;AACb,WAAS,IAAI,OAAO,IAAI,KAAK,KAAK,MAAM;AACtC,SAAK,KAAK,CAAC;AAAA,EACb;AACA,SAAO,IAAI,OAAO,IAAI;AACxB;AANgB;ACChB,MAAM,eAAe,gCAAU,GAAa,QAAgB;AAC1D,QAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,QAAI,CAAC,IAAI,KAAK,IAAI,EAAE,CAAC,GAAG,CAAC;AAAA,EAC3B;AACA,SAAO;AACT,GANqB;AAQrB,SAAS,aAAa,GAAW,YAA8B,MAAc;AAC3E,QAAM,SAAS;AACf,QAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,MAAM;AAAA,IACrB,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,EAAM;AAE3C;AATS;AAWF,MAAM,QAAN,MAAM,cAAa,eAAe;AAAA,EAC7B,SAAS,GAAmB;AACpC,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,aAAa,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,EACtD;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,QAAI,SAAS,GAAG,IAAI,EAAE,GAAG,CAAC,CAAC,CAAC;AAAA,EAC9B;AACF;AAfyC;AAAlC,IAAM,OAAN;AAgBP,kBAAkB,QAAQ,IAAI;AAI9B,MAAM,kBAAkB,gCAAU,GAAa,QAAgB;AAC7D,QAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,QAAI,CAAC,IAAI,KAAK,IAAI,KAAK,IAAI,CAAC,EAAE,CAAC,CAAC;AAAA,EAClC;AACA,SAAO;AACT,GANwB;AAQxB,SAAS,gBAAgB,GAAW,YAA8B,MAAc;AAC9E,QAAM,SAAS;AACf,QAAM,SAAS,EAAE,MAAM,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC;AAExD,SAAO,IAAI;AAAA,IACT,OAAO,EAAE,MAAM,MAAM;AAAA,IACrB,EAAE,eAAe,EAAE,cAAA;AAAA,IACnB,EAAE,WAAsB,OAAO,EAAE,MAAA;AAAA,EAAM;AAE3C;AATS;iBAWF,mBAAsB,eAAe;AAAA,EAChC,SAAS,GAAmB;AACpC,QAAI,EAAE,eAAe;AACnB,WAAK,gBAAgB,CAAC,CAAC;AAAA,IACzB;AACA,SAAK,eAAe,KAAK,EAAE,UAAU,EAAE,UAAU,MAAM;AACvD,WAAO,gBAAgB,GAAG,EAAE,gBAAgB,OAAO,IAAI;AAAA,EACzD;AAAA,EACU,UAAU,IAAkB;AACpC,UAAM,CAAC,CAAC,IAAI,KAAK;AACjB,UAAM,CAAC,GAAG,IAAI,KAAK;AAGnB,QAAI,SAAS,GAAG,IAAI,EAAE,MAAM,IAAI,CAAC,EAAE,IAAI,EAAE,EAAE,aAAa,IAAI,EAAE,IAAA,CAAK,EAAE,IAAI,EAAE,CAAC,CAAC;AAAA,EAC/E;AACF,GAf4C,uBAArC;AAgBP,kBAAkB,WAAWC,SAAO;ACjF7B,MAAM,aAAN,MAAM,mBAAkB,OAAO;AAAA,EACpC,YACE,MAEA,UAAuC;AAAA,IACnC,eAAe;AAAA,EAAA,GAEnB,mBAAgE,CAAA,GAChE;AACA,QAAI,gBAAgB,QAAQ;AAC1B,YAAM,KAAK,MAAM,EAAE,eAAe,KAAA,GAAQ,EAAE,OAAO,KAAK,OAAO;AAAA,IACjE,WAAW,gBAAgB,YAAW;AACpC,YAAM,KAAK,MAAM,EAAE,eAAe,KAAA,GAAQ,EAAE,OAAO,KAAK,OAAO;AAAA,IACjE,OAAO;AACL,YAAM,MAAM,SAAS,gBAAgB;AAAA,IACvC;AAAA,EACF;AACF;AAjBsC;AAA/B,IAAM,YAAN;AAmBA,MAAe,UAAf,MAAe,QAAO;AAAA,EACnB;AAAA,EACA;AAAA,EAER,cAAc;AACZ,SAAK,cAAc,CAAA;AACnB,SAAK,WAAW,CAAA;AAAA,EAClB;AAAA,EAEQ,mBAAmB,gBAAwB,WAAsB;AACvE,SAAK,YAAY,cAAc,IAAI;AAAA,EACrC;AAAA,EAEQ,gBAAgB,aAAqB,QAAgB;AAC3D,SAAK,SAAS,WAAW,IAAI;AAAA,EAC/B;AAAA,EAEU,SAAS,MAAc,OAA2B;AAC1D,QAAI,iBAAiB,WAAW;AAC9B,WAAK,mBAAmB,MAAM,KAAK;AAAA,IACrC,OAAO;AACL,WAAK,gBAAgB,MAAM,KAAK;AAAA,IAClC;AAAA,EACF;AAAA,EAIO,aAA0B;AAC/B,QAAI,SAAsB,OAAO,OAAO,KAAK,WAAW;AACxD,eAAW,UAAU,OAAO,OAAO,KAAK,QAAQ,GAAG;AACjD,eAAS,OAAO,OAAO,OAAO,WAAA,CAAY;AAAA,IAC5C;AACA,WAAO;AAAA,EACT;AACF;AAlC6B;AAAtB,IAAe,SAAf;AAoCA,MAAM,UAAN,MAAM,gBAAe,OAAO;AAAA,EACzB;AAAA,EACA;AAAA,EAER,YAAY,aAAqB,cAAsB;AACrD,UAAA;AACA,UAAM,IAAI,KAAK,KAAK,IAAI,WAAW;AAEnC,SAAK,SAAS,IAAI,UAAU,KAAK,CAAC,cAAc,WAAW,CAAC,EAAE,IAAI,IAAI,CAAC,EAAE,IAAI,CAAC,CAAC;AAC/E,SAAK,OAAO,IAAI,UAAU,KAAK,CAAC,YAAY,CAAC,EAAE,IAAI,IAAI,CAAC,EAAE,IAAI,CAAC,CAAC;AAEhE,SAAK,SAAS,UAAU,KAAK,MAAM;AACnC,SAAK,SAAS,QAAQ,KAAK,IAAI;AAAA,EACjC;AAAA,EAEA,QAAQ,OAAe;AACrB,WAAO,MAAM,OAAO,KAAK,OAAO,UAAU,GAAG,CAAC,CAAC,EAAE,IAAI,KAAK,IAAI;AAAA,EAChE;AACF;AAlBmC;AAA5B,IAAM,SAAN;AAoBA,MAAM,QAAN,MAAM,cAAa,OAAO;AAAA,EAC/B,cAAc;AACZ,UAAA;AAAA,EACF;AAAA,EAEA,QAAQ,OAAe;AACrB,WAAOC,KAAgB,KAAK;AAAA,EAC9B;AACF;AARiC;AAA1B,IAAM,OAAN;AAUA,MAAM,WAAN,MAAM,iBAAgB,OAAO;AAAA,EAClC,cAAc;AACZ,UAAA;AAAA,EACF;AAAA,EAEA,QAAQ,OAAe;AACrB,WAAOC,QAAmB,KAAK;AAAA,EACjC;AACF;AARoC;AAA7B,IAAM,UAAN;ACzFP,MAAe,QAAf,MAAe,MAAK;AAEpB;AAFoB;AAApB,IAAe,OAAf;AAIO,MAAM,WAAN,MAAM,iBAAgB,KAAK;AAAA,EAChC,cAAc;AACZ,UAAA;AAAA,EACF;AAAA,EAEA,QAAQ,OAAe,QAAgB;AACrC,WAAO,MAAM,IAAI,MAAM,EAAE,IAAI,CAAC,EAAE,KAAA;AAAA,EAClC;AACF;AARkC;AAA3B,IAAM,UAAN;AAUA,MAAM,UAAN,MAAM,gBAAe,KAAK;AAAA,EAC/B,cAAc;AACZ,UAAA;AAAA,EACF;AAAA,EAEA,QAAQ,OAAe,QAAgB;AACrC,WAAO,MAAM,IAAI,MAAM,EAAE,IAAA,EAAM,KAAA;AAAA,EACjC;AACF;AARiC;AAA1B,IAAM,SAAN;AAUA,MAAM,WAAN,MAAM,iBAAgB,KAAK;AAAA,EACxB;AAAA,EAER,YAAY,SAAwB,MAAM;AACxC,UAAA;AACA,SAAK,SAAS;AAAA,EAChB;AAAA,EAEA,QAAQ,OAAe,QAAgB;AACrC,UAAM,OAAO,OAAO,IAAI,MAAM,KAAK;AACnC,UAAM,QAAQ,OAAO,IAAA,EAAM,IAAI,CAAC,EAAE,IAAI,MAAM,MAAM,IAAI,CAAC,EAAE,KAAK;AAC9D,UAAM,OAAO,KAAK,IAAI,KAAK,EAAE,IAAA,EAAM,KAAA;AACnC,QAAI,KAAK,QAAQ;AACf,aAAO,KAAK,IAAI,KAAK,MAAM;AAAA,IAC7B;AACA,WAAO;AAAA,EACT;AACF;AAjBkC;AAA3B,IAAM,UAAN;ACvBP,SAAS,kBAAkB,QAAgB;AACzC,SAAO,IAAI,SAA8B;AACvC,UAAM,YAAY,KAAK,aAAa,MAAM,GAAA;AAC1C,WAAO,UAAU,QAAQ,GAAG,IAAI;AAAA,EAClC;AACF;AALS;AAOT,SAAS,wBAAwB,QAAgB;AAC/C,SAAO,CAAC,MAAuB;AAC7B,QAAI,OAAO,KAAK,UAAU;AACxB,UAAI,IAAI,OAAO,CAAC;AAAA,IAClB;AAEA,UAAM,YAAY,KAAK,aAAa,MAAM,GAAA;AAC1C,WAAO,UAAU,QAAQ,CAAC;AAAA,EAC5B;AACF;AATS;AAWT,SAAS,yBAAyB,QAAgB;AAChD,SAAO,CAAC,GAAoB,MAAuB;AACjD,QAAI,OAAO,KAAK,UAAU;AACxB,UAAI,IAAI,OAAO,CAAC;AAAA,IAClB;AAEA,QAAI,OAAO,KAAK,UAAU;AACxB,UAAI,IAAI,OAAO,CAAC;AAAA,IAClB;AAEA,UAAM,YAAY,KAAK,aAAa,MAAM,GAAA;AAC1C,WAAO,UAAU,QAAQ,GAAG,CAAC;AAAA,EAC/B;AACF;AAbS;AAeF,MAAM,OAAO,wBAAwB,MAAM;AAC3C,MAAM,UAAU,wBAAwB,SAAS;;;;;;;;;;;;;;;;;;ACnCjD,MAAe,aAAf,MAAe,WAAU;AAAA,EAC9B;AAAA,EACA;AAAA,EAEA,YAAY,QAAqB,UAAkC;AACjE,SAAK,SAAS;AACd,SAAK,WAAW;AAAA,EAClB;AAAA,EAEO,YAAkB;AACvB,eAAW,SAAS,KAAK,QAAQ;AAC/B,YAAM,OAAO;AAAA,IACf;AAAA,EACF;AAGF;AAhBgC;AAAzB,IAAe,YAAf;ACGA,MAAM,OAAN,MAAM,aAAY,UAAU;AAAA,EACzB,4BAAkD,IAAA;AAAA,EAClD;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EAER,YACE,QACA,KAAa,MACb,WAAmB,GACnB,YAAoB,GACpB,eAAuB,GACvB,WAAoB,OACpB,WAAoB,OACpB;AACA,UAAM,QAAQ,EAAE;AAChB,SAAK,KAAK;AACV,SAAK,WAAW;AAChB,SAAK,YAAY;AACjB,SAAK,eAAe;AACpB,SAAK,WAAW;AAChB,SAAK,WAAW;AAAA,EAClB;AAAA,EAEA,OAAa;AACX,eAAW,SAAS,KAAK,QAAQ;AAC/B,UAAI,IAAI,KAAK,WAAW,MAAM,KAAK,IAAI,EAAE,IAAI,MAAM;AACnD,UAAI,KAAK,iBAAiB,GAAG;AAC3B,YAAI,EAAE,IAAI,MAAM,IAAI,KAAK,YAAY,CAAC;AAAA,MACxC;AAEA,UAAI,KAAK,aAAa,GAAG;AACvB,YAAI,KAAK,MAAM,IAAI,KAAK,GAAG;AACzB,cAAIC,OAAM,KAAK,MAAM,IAAI,KAAK,EAAG;AACjCA,iBAAMA,KAAI,IAAI,KAAK,QAAQ;AAC3BA,iBAAMA,KAAI,IAAI,EAAE,IAAI,IAAI,KAAK,SAAS,CAAC;AACvC,eAAK,MAAM,IAAI,OAAO,EAAE,UAAUA,MAAK;AAAA,QACzC,OAAO;AACL,eAAK,MAAM,IAAI,OAAO,EAAE,UAAU,GAAG;AAAA,QACvC;AAEA,YAAI,MAAM,KAAK,MAAM,IAAI,KAAK,EAAG;AAEjC,YAAI,KAAK,UAAU;AACjB,cAAI,EAAE,IAAI,IAAI,IAAI,KAAK,QAAQ,CAAC;AAAA,QAClC,OAAO;AACL,cAAI;AAAA,QACN;AAEA,aAAK,MAAM,IAAI,OAAO,EAAE,UAAU,KAAK;AAAA,MACzC;AAGA,YAAM,WAAW,MAAM,IAAI,EAAE,IAAI,KAAK,EAAE,CAAC;AACzC,YAAM,OAAO,SAAS;AAAA,IACxB;AAAA,EACF;AACF;AA5DmC;AAA5B,IAAM,MAAN;AA8DA,MAAM,QAAN,MAAM,cAAa,UAAU;AAAA,EAC1B,4BAIC,IAAA;AAAA,EAED,aAAqB;AAAA,EACrB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EAER,YACE,QACA,KAAa,MACb,QAA0B,CAAC,KAAK,KAAK,GACrC,MAAc,MACd,eAAuB,GACvB,UAAmB,OACnB,WAAoB,OACpB;AACA,UAAM,QAAQ,EAAE;AAChB,SAAK,KAAK;AACV,SAAK,QAAQ,MAAM,CAAC;AACpB,SAAK,QAAQ,MAAM,CAAC;AACpB,SAAK,MAAM;AACX,SAAK,eAAe;AACpB,SAAK,UAAU;AACf,SAAK,WAAW;AAAA,EAClB;AAAA,EAEA,OAAa;AACX,SAAK,cAAc;AACnB,eAAW,SAAS,KAAK,QAAQ;AAC/B,UAAI,OAAO,KAAK,WAAW,MAAM,KAAK,IAAI,EAAE,IAAI,MAAM;AAEtD,UAAI,KAAK,iBAAiB,GAAG;AAC3B,eAAO,KAAK,IAAI,MAAM,IAAI,KAAK,YAAY,CAAC;AAAA,MAC9C;AAGA,UAAI,CAAC,KAAK,MAAM,IAAI,KAAK,GAAG;AAC1B,aAAK,MAAM,IAAI,OAAO;AAAA,UACpB,GAAG,WAAW,KAAK;AAAA,UACnB,GAAG,WAAW,KAAK;AAAA,UACnB,MAAM,WAAW,KAAK;AAAA,QAAA,CACvB;AAAA,MACH;AAEA,YAAM,QAAQ,KAAK,MAAM,IAAI,KAAK;AAElC,YAAM,IAAI,MAAM,EAAE,IAAI,KAAK,KAAK,EAAE,IAAI,KAAK,IAAI,IAAI,KAAK,KAAK,CAAC;AAC9D,YAAM,IAAI,MAAM,EAAE,IAAI,KAAK,KAAK,EAAE,IAAI,KAAK,IAAI,IAAI,EAAE,IAAI,IAAI,KAAK,KAAK,CAAC;AAExE,YAAM,kBAAkB,IAAI,KAAK,IAAI,KAAK,OAAO,KAAK,UAAU;AAChE,YAAM,kBAAkB,IAAI,KAAK,IAAI,KAAK,OAAO,KAAK,UAAU;AAEhE,UAAI;AACJ,YAAM,OAAO,MAAM,EAAE,IAAI,eAAe;AACxC,UAAI,KAAK,SAAS;AAChB,cAAM,OAAO,MAAM,KAAK,QAAQ,MAAM,CAAC;AACvC,eAAO,MAAM,KAAK,IAAI,eAAe;AAAA,MACvC,OAAO;AACL,eAAO,MAAM,EAAE,IAAI,eAAe;AAAA,MACpC;AAEA,YAAM,SAAS,KAAK,IAAI,KAAK,KAAA,EAAO,IAAI,KAAK,GAAG,CAAC,EAAE,IAAI,KAAK,EAAE;AAE9D,YAAM,WAAW,MAAM,IAAI,MAAM;AACjC,YAAM,OAAO,SAAS;AAAA,IACxB;AAAA,EACF;AACF;AA5EoC;AAA7B,IAAM,OAAN;;;;;;;"}